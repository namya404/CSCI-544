{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWE3S8yL3hpf"
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMxCUGNC3sCW"
   },
   "source": [
    "## Importing Important libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of all the versions of the libraries used:\n",
    "\n",
    "python 3.11.5\n",
    "\n",
    "pandas 2.0.3\n",
    "\n",
    "numpy 1.24.3\n",
    "\n",
    "nltk 3.8.1\n",
    "\n",
    "matplotlib 3.7.2\n",
    "\n",
    "contractions 0.1.73\n",
    "\n",
    "scikit-learn 1.2.2\n",
    "\n",
    "tabulate 0.8.10\n",
    "\n",
    "gensim 4.3.0\n",
    "\n",
    "tensorflown 2.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17243,
     "status": "ok",
     "timestamp": 1707179292765,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "Z2u_xLAy32wP",
    "outputId": "b619b1d3-c153-496e-ee59-556854d9b9f2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in /Users/namyashah/anaconda3/lib/python3.11/site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /Users/namyashah/anaconda3/lib/python3.11/site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in /Users/namyashah/anaconda3/lib/python3.11/site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Requirement already satisfied: pyahocorasick in /Users/namyashah/anaconda3/lib/python3.11/site-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4140,
     "status": "ok",
     "timestamp": 1707179308072,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "T1Yz5wom3bAv",
    "outputId": "c1822e7b-2e9a-492c-d764-ef84ff6c0e34"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/75/80lf4_793vn5xdm8_9jjr63h0000gn/T/ipykernel_7334/2486081064.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/namyashah/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/namyashah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import contractions\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1707179308073,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "BghFwqzkF_v-"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1707179308073,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "rOnvIpXQGCYT",
    "outputId": "d9d5cbe9-64db-42e0-84d5-d88226cc335e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/namyashah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1707179308073,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "RrwlTGE8GaQz"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /Users/namyashah/anaconda3/lib/python3.11/site-packages (0.8.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpRMvf2w4MPD"
   },
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8883,
     "status": "ok",
     "timestamp": 1707179316953,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "RTXxImv74Cro",
    "outputId": "a7421a58-07bf-4b98-a68f-d7baa3884f8a"
   },
   "outputs": [],
   "source": [
    "path = '/Users/namyashah/Documents/USC Schooling/NLP/HW2/data/amazon_reviews_us_Office_Products_v1_00.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 999
    },
    "executionInfo": {
     "elapsed": 42750,
     "status": "ok",
     "timestamp": 1707179359700,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "B89K_Qhv4V_K",
    "outputId": "e66a33d9-907d-4def-dcb2-3d4b26cd86bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/75/80lf4_793vn5xdm8_9jjr63h0000gn/T/ipykernel_7334/1113296747.py:1: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  my_df = pd.read_csv(path,  sep='\\t', header=0, on_bad_lines='skip')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>43081963</td>\n",
       "      <td>R18RVCKGH1SSI9</td>\n",
       "      <td>B001BM2MAC</td>\n",
       "      <td>307809868</td>\n",
       "      <td>Scotch Cushion Wrap 7961, 12 Inches x 100 Feet</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Great product.</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>10951564</td>\n",
       "      <td>R3L4L6LW1PUOFY</td>\n",
       "      <td>B00DZYEXPQ</td>\n",
       "      <td>75004341</td>\n",
       "      <td>Dust-Off Compressed Gas Duster, Pack of 4</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Phffffffft, Phfffffft. Lots of air, and it's C...</td>\n",
       "      <td>What's to say about this commodity item except...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>21143145</td>\n",
       "      <td>R2J8AWXWTDX2TF</td>\n",
       "      <td>B00RTMUHDW</td>\n",
       "      <td>529689027</td>\n",
       "      <td>Amram Tagger Standard Tag Attaching Tagging Gu...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>but I am sure I will like it.</td>\n",
       "      <td>Haven't used yet, but I am sure I will like it.</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>52782374</td>\n",
       "      <td>R1PR37BR7G3M6A</td>\n",
       "      <td>B00D7H8XB6</td>\n",
       "      <td>868449945</td>\n",
       "      <td>AmazonBasics 12-Sheet High-Security Micro-Cut ...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and the shredder was dirty and the bin was par...</td>\n",
       "      <td>Although this was labeled as &amp;#34;new&amp;#34; the...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>24045652</td>\n",
       "      <td>R3BDDDZMZBZDPU</td>\n",
       "      <td>B001XCWP34</td>\n",
       "      <td>33521401</td>\n",
       "      <td>Derwent Colored Pencils, Inktense Ink Pencils,...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>Gorgeous colors and easy to use</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640249</th>\n",
       "      <td>US</td>\n",
       "      <td>53005790</td>\n",
       "      <td>RLI7EI10S7SN0</td>\n",
       "      <td>B00000DM9M</td>\n",
       "      <td>223408988</td>\n",
       "      <td>PalmOne III Leather Belt Clip Case</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>4</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Great value! A must if you hate to carry thing...</td>\n",
       "      <td>I can't live anymore whithout my Palm III. But...</td>\n",
       "      <td>1998-12-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640250</th>\n",
       "      <td>US</td>\n",
       "      <td>52188548</td>\n",
       "      <td>R1F3SRK9MHE6A3</td>\n",
       "      <td>B00000DM9M</td>\n",
       "      <td>223408988</td>\n",
       "      <td>PalmOne III Leather Belt Clip Case</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Attaches the Palm Pilot like an appendage</td>\n",
       "      <td>Although the Palm Pilot is thin and compact it...</td>\n",
       "      <td>1998-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640251</th>\n",
       "      <td>US</td>\n",
       "      <td>52090046</td>\n",
       "      <td>R23V0C4NRJL8EM</td>\n",
       "      <td>0807865001</td>\n",
       "      <td>307284585</td>\n",
       "      <td>Gods and Heroes of Ancient Greece</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Excellent information, pictures and stories, I...</td>\n",
       "      <td>This book had a lot of great content without b...</td>\n",
       "      <td>1998-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640252</th>\n",
       "      <td>US</td>\n",
       "      <td>52503173</td>\n",
       "      <td>R13ZAE1ATEUC1T</td>\n",
       "      <td>1572313188</td>\n",
       "      <td>870359649</td>\n",
       "      <td>Microsoft EXCEL 97/ Visual Basic Step-by-Step ...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>class text</td>\n",
       "      <td>I am teaching a course in Excel and am using t...</td>\n",
       "      <td>1998-08-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640253</th>\n",
       "      <td>US</td>\n",
       "      <td>52585611</td>\n",
       "      <td>RE8J5O2GY04NN</td>\n",
       "      <td>1572313188</td>\n",
       "      <td>870359649</td>\n",
       "      <td>Microsoft EXCEL 97/ Visual Basic Step-by-Step ...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Microsoft's Finest</td>\n",
       "      <td>A very comprehensive layout of exactly how Vis...</td>\n",
       "      <td>1998-07-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2640254 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0                US     43081963  R18RVCKGH1SSI9  B001BM2MAC       307809868   \n",
       "1                US     10951564  R3L4L6LW1PUOFY  B00DZYEXPQ        75004341   \n",
       "2                US     21143145  R2J8AWXWTDX2TF  B00RTMUHDW       529689027   \n",
       "3                US     52782374  R1PR37BR7G3M6A  B00D7H8XB6       868449945   \n",
       "4                US     24045652  R3BDDDZMZBZDPU  B001XCWP34        33521401   \n",
       "...             ...          ...             ...         ...             ...   \n",
       "2640249          US     53005790   RLI7EI10S7SN0  B00000DM9M       223408988   \n",
       "2640250          US     52188548  R1F3SRK9MHE6A3  B00000DM9M       223408988   \n",
       "2640251          US     52090046  R23V0C4NRJL8EM  0807865001       307284585   \n",
       "2640252          US     52503173  R13ZAE1ATEUC1T  1572313188       870359649   \n",
       "2640253          US     52585611   RE8J5O2GY04NN  1572313188       870359649   \n",
       "\n",
       "                                             product_title product_category  \\\n",
       "0           Scotch Cushion Wrap 7961, 12 Inches x 100 Feet  Office Products   \n",
       "1                Dust-Off Compressed Gas Duster, Pack of 4  Office Products   \n",
       "2        Amram Tagger Standard Tag Attaching Tagging Gu...  Office Products   \n",
       "3        AmazonBasics 12-Sheet High-Security Micro-Cut ...  Office Products   \n",
       "4        Derwent Colored Pencils, Inktense Ink Pencils,...  Office Products   \n",
       "...                                                    ...              ...   \n",
       "2640249                 PalmOne III Leather Belt Clip Case  Office Products   \n",
       "2640250                 PalmOne III Leather Belt Clip Case  Office Products   \n",
       "2640251                  Gods and Heroes of Ancient Greece  Office Products   \n",
       "2640252  Microsoft EXCEL 97/ Visual Basic Step-by-Step ...  Office Products   \n",
       "2640253  Microsoft EXCEL 97/ Visual Basic Step-by-Step ...  Office Products   \n",
       "\n",
       "        star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0                 5            0.0          0.0    N                 Y   \n",
       "1                 5            0.0          1.0    N                 Y   \n",
       "2                 5            0.0          0.0    N                 Y   \n",
       "3                 1            2.0          3.0    N                 Y   \n",
       "4                 4            0.0          0.0    N                 Y   \n",
       "...             ...            ...          ...  ...               ...   \n",
       "2640249           4           26.0         26.0    N                 N   \n",
       "2640250           4           18.0         18.0    N                 N   \n",
       "2640251           4            9.0         16.0    N                 N   \n",
       "2640252           5            0.0          0.0    N                 N   \n",
       "2640253           5            0.0          0.0    N                 N   \n",
       "\n",
       "                                           review_headline  \\\n",
       "0                                               Five Stars   \n",
       "1        Phffffffft, Phfffffft. Lots of air, and it's C...   \n",
       "2                            but I am sure I will like it.   \n",
       "3        and the shredder was dirty and the bin was par...   \n",
       "4                                               Four Stars   \n",
       "...                                                    ...   \n",
       "2640249  Great value! A must if you hate to carry thing...   \n",
       "2640250          Attaches the Palm Pilot like an appendage   \n",
       "2640251  Excellent information, pictures and stories, I...   \n",
       "2640252                                         class text   \n",
       "2640253                                 Microsoft's Finest   \n",
       "\n",
       "                                               review_body review_date  \n",
       "0                                           Great product.  2015-08-31  \n",
       "1        What's to say about this commodity item except...  2015-08-31  \n",
       "2          Haven't used yet, but I am sure I will like it.  2015-08-31  \n",
       "3        Although this was labeled as &#34;new&#34; the...  2015-08-31  \n",
       "4                          Gorgeous colors and easy to use  2015-08-31  \n",
       "...                                                    ...         ...  \n",
       "2640249  I can't live anymore whithout my Palm III. But...  1998-12-07  \n",
       "2640250  Although the Palm Pilot is thin and compact it...  1998-11-30  \n",
       "2640251  This book had a lot of great content without b...  1998-10-15  \n",
       "2640252  I am teaching a course in Excel and am using t...  1998-08-22  \n",
       "2640253  A very comprehensive layout of exactly how Vis...  1998-07-15  \n",
       "\n",
       "[2640254 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df = pd.read_csv(path,  sep='\\t', header=0, on_bad_lines='skip')\n",
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGD9i2nF4zuv"
   },
   "source": [
    "## Making Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40770,
     "status": "ok",
     "timestamp": 1707179400467,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "rpO51JV34g48",
    "outputId": "69cf586b-c0d0-4943-d505-01537034844b"
   },
   "outputs": [],
   "source": [
    "review=my_df['review_body'].tolist()\n",
    "# print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1707179411852,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "2DXipQZp46rN",
    "outputId": "fd4c00b9-1d18-4c7a-e184-9394e7fc94e3"
   },
   "outputs": [],
   "source": [
    "rating=my_df['star_rating'].tolist()\n",
    "#because these values have misread data of dates instead of ratings\n",
    "rating[286835]=-1\n",
    "rating[671556]=-1\n",
    "rating[1523317]=-1\n",
    "#print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1707179411852,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "mz1A9-Ux5--w",
    "outputId": "80509929-3c80-4f6a-bce0-41ef6804633e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Haven't used yet, but I am sure I will like it.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Although this was labeled as &amp;#34;new&amp;#34; the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gorgeous colors and easy to use</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews ratings\n",
       "2    Haven't used yet, but I am sure I will like it.       5\n",
       "3  Although this was labeled as &#34;new&#34; the...       1\n",
       "4                    Gorgeous colors and easy to use       4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf = pd.DataFrame({'reviews': review})\n",
    "ndf['ratings'] = rating\n",
    "sample = ndf.iloc[2:5]\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1707179411852,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "ySPMd2C56Iiy"
   },
   "outputs": [],
   "source": [
    "#making sure all values of ratings are numeric values\n",
    "ndf[\"ratings\"]=pd.to_numeric(ndf[\"ratings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1707179412119,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "iufyzjWV6MqL",
    "outputId": "8facf203-6033-4064-a0f7-cfae593bd12a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "#identifying that not all values of reviews are non string values\n",
    "for a in ndf['reviews'].map(type):\n",
    "  if a != str:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1707179412119,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "wOw6CsZp6QC-"
   },
   "outputs": [],
   "source": [
    "#making sure all values of reviews are string values\n",
    "ndf['reviews'] = ndf['reviews'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1707179412119,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "n-119ZAL6Y9x",
    "outputId": "919350b8-7782-475d-e3f6-1b741ce5bd08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         reviews\n",
      "ratings         \n",
      "-1.0           3\n",
      " 1.0      306979\n",
      " 2.0      138384\n",
      " 3.0      193691\n",
      " 4.0      418371\n",
      " 5.0     1582812\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAawAAAGVCAYAAACivcXJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABNCUlEQVR4nO3deXwU5eEG8Gf2yH3fF0cggXAkJKBCQA4FuaISbS2CFrWo1R9UrPUoKpZWLSDFgrWCaMulEYXKISAhcooJQkhCEu4jJ+SCkPve3d8flGgKgWSzu+/M7vP9fPgoy+zOkxD22Zl5530lg8FgABERkcypRAcgIiLqCBYWEREpAguLiIgUgYVFRESKwMIiIiJFYGEREZEisLCIiEgRWFhERKQILCwiIlIEFhYRESkCC4uIiBSBhUVERIrAwiIiIkVgYRERkSKwsIiISBFYWEREpAgsLCIiUgQWFhERKQILi4iIFIGFRUREisDCIiIiRWBhERGRIrCwiIhIEVhYRESkCCwsIiJSBBYWEREpAguLiIgUgYVFRESKwMIiIiJFYGEREZEisLCIiEgRWFhERKQILCwiIlIEFhYRddry5csRFRUFNzc3uLm5ITY2Ft9+++0tn7NhwwZERETAwcEBkZGR2LFjh4XSkrVgYRFRp4WEhGDhwoU4evQoUlNTce+992LKlCk4fvz4TbdPTk7GtGnTMHPmTKSnpyM+Ph7x8fHIzs62cHJSMslgMBhEhyAi5fPy8sLixYsxc+bMG/5s6tSpqK2txbZt21ofGzZsGKKjo7FixQpLxiQF4xEWEXWJTqfD+vXrUVtbi9jY2Jtuk5KSgnHjxrV5bMKECUhJSbFERLISGtEBiEiZsrKyEBsbi4aGBri4uGDTpk3o37//TbctLi6Gv79/m8f8/f1RXFxsiahkJXiERURG6du3LzIyMvDjjz/i+eefxxNPPIETJ06IjkVWjEdYRGQUOzs7hIWFAQCGDBmCI0eOYNmyZfj4449v2DYgIAAlJSVtHispKUFAQIBFspJ14BEWEZmEXq9HY2PjTf8sNjYWu3fvbvNYUlJSu9e8iG6GR1hE1Glz587FpEmT0L17d1RXVyMhIQH79u1DYmIiAGDGjBkIDg7GggULAABz5szB6NGjsWTJEsTFxWH9+vVITU3FypUrRX4ZpDAsLCLqtNLSUsyYMQNFRUVwd3dHVFQUEhMTcd999wEA8vPzoVL9dAJn+PDhSEhIwJtvvonXX38d4eHh2Lx5MwYOHCjqSyAF4n1Y1MbChQsxd+5czJkzB0uXLm13uw0bNmDevHnIzc1FeHg4Fi1ahMmTJ1suKBHZHF7DolZHjhzBxx9/jKioqFtux1kLiEgEHmERAKCmpgaDBw/GRx99hHfeeQfR0dHtHmFx1gIiEoFHWAQAmDVrFuLi4m6YjeBmOGsBEYnAQReE9evXIy0tDUeOHOnQ9py14EY6nR4NNc1oqG1GY20zGmpa0FjfAr1OD4MBMOgN0OsNMOgNMOgBg8EAvc4Ag8EASSVBa6eGxk4FjZ0aTtpmeDUUQOXqBrWrC1SurlC7u0PS8J8r2Tb+C7BxBQUFmDNnDpKSkuDg4CA6jiw11DSjsqwelZfrUFlaj6rL9airbEJD7bWCaqhpRlODzmT7Cw4C+ibMavugSgW1txe0/gHQ+PtD6+8PTUAAtP5+0PgHQBvgD21QECQ7O5PlIJIbFpaNO3r0KEpLSzF48ODWx3Q6HQ4cOIAPP/wQjY2NUKvVbZ5jjbMW6HR6lF+sRVlBNSrL6lFVVn/tv5fr0VjXYtEsGtyk/PR66MouQ1d2GWhvcItGA7vu3WHfuzfsw8NgHxYGu95hsA/tySIjq8BBFzauuroaeXl5bR576qmnEBERgddee+2m98lMnToVdXV1+Oabb1ofGz58OKKiohQx6EKv0+PKpVqU5VWjNL8aZXlVuHKxFroWvehoAIDeQQ3okfAH073g9SILC4ND5EA4xcTAITISKnt70+2DyAJ4hGXjXF1dbyglZ2dneHt7tz6u9FkL6qqaUHi6HEXnKlGaV40rF2uga5ZHOd2MRt9k2hdsaUHThQtounAB1bt2XXtMq4VDv35wiomGY0wMHGMGQ+vvZ9r9EpkYC4tuS2mzFjQ36XDpTAUKTpWj8ORVXLlUAyjoPIJaf/P5+EyquRkNmZloyMwE1qwFAGiCAuE05A44jxgOlxEjoPH1NX8Ook7gKUFSPL3egNLcKhSeKkfByasozqmEvkW5P9aRXoXw/XqB2BCSBPu+feEy8m64jBoFx8GDIf3PtUwiS2NhkSLp9QZcPH0V546W4kJGGRpqmkVHMplot7Pw2rpUdIw21O7ucB45Ei73jIHL6DFQuziLjkQ2iIVFiqHXG3DxzLWSyskoQ3219ZTUzw1xOAb3nfK8HggAkoMDXEaPhvsD98Nl1CiOQCSLYWGRrBn0Blw8W3HtSCq91GpL6ufukpLhsvdz0TE6ROXmBtfx98H9/vvhdNddkFScPIfMh4VFslRztQHHD17CyR+KUFthgUEIMjKsMRFOKVtFx+g0jZ8f3CZNgvtD8XCIiBAdh6wQC4tkw6A3IO/4FRz//hLysq/AoLfNH83hFRvhkLFXdIwucYyJgef06XCbMJ6nDMlkWFgkXF1VE078cAknDl5C9ZUG0XGEu/vSKtidSRUdwyTU3t7weOSX8Jw6FdrAQNFxSOFYWCTMpbNXkbn3InKOlUGv44/hdaPO/h2ai+dExzAttRou94yB1/TpcB4+XHQaUigWFlmUwWBAzrHLSN+Vh+ILVaLjyNKYtLegqroiOobZ2IX1hs+zz8ItLo73dlGnsLDIIvQ6Pc4cLkFaYh6uFteJjiNr9xx4AZLedLO/y5W2R3f4PPMM3KdMgaTVio5DCsAxqGRWOp0eJw5ewud/OoTda06yrG5DY6eyibICgOa8fBS9OQ/nJ0zE1S++gL7JxHMomsiCBQtw5513wtXVFX5+foiPj8fp06dv+7wNGzYgIiICDg4OiIyMxI4dOyyQ1rqxsMgsdDo9sg9cxOfzDmHvZ6dQdZmDKTpCa2d7/ySbL11C8Z//gvPj7kP5mjXQN8jrZ2X//v2YNWsWDh06hKSkJDQ3N2P8+PGora1t9znJycmYNm0aZs6cifT0dMTHxyM+Ph7Z7S0NQx3CU4JkchfSy5C86RwqS+tFR1EcN08t7tj0rOgYQql9feA7azY8HvmlLK9xlZWVwc/PD/v378eoUaNuus3UqVNRW1uLbdu2tT42bNgwREdHK2IJHrmyvY9zZDaleVXYtCQN336cxbIyklbDz4+6sssonj8fFx6cguo9e0THuUFlZSUAwMvLq91tUlJSMG7cuDaPTZgwASkpKWbNZu24vAh1WXV5Aw5tOY8zh0sUtYyHHGnU/AZe13T+PApn/w473p2I+0c/i75efUVHgl6vx4svvogRI0bccjmd4uJi+Pv7t3nM398fxcXF5o5o1VhYZLSmhhakJebh2HcFaJHxgohKopFsY8BFR1WMjcHqql1Yt203Hg5/GL+L+R08HTyF5Zk1axays7Nx8OBBYRlsGQuLjHIyuQgpm8+jvkqeI7uUioX1E8nJCYuiCwAAOoMOG85swM7cnXh+0POYFjENGpVl375mz56Nbdu24cCBAwgJCbnltgEBASgpKWnzWElJCQICAswZ0erxGhZ1SmVZPbYsTceetSdZVmaggfXPRt9R5+IG4rymvM1j1U3VeO/Ie/jF1l8gozTDIjkMBgNmz56NTZs2Yc+ePQgNDb3tc2JjY7F79+42jyUlJSE2NtZcMW0Cj7CoQ/R6A47tLsDhby6gpYmn/8xFo+eHAACQ/H2xsPeJdv/8QuUFPLHzCczoPwO/i/kd7NTmm2B31qxZSEhIwJYtW+Dq6tp6Hcrd3R2Ojo4AgBkzZiA4OBgLFlxbKXrOnDkYPXo0lixZgri4OKxfvx6pqalYuVK+65wpAY+w6LYuF9bgP4tSkfyfcywrM1PrbWsplfYcjOuOSunW92PpDXqsPr4aj3zzCLIvm+/+puXLl6OyshJjxoxBYGBg668vv/yydZv8/HwUFRW1/n748OFISEjAypUrMWjQIGzcuBGbN2++5UANuj3eh0Xt0jXrcWRHDtJ35XNyWguJ9CqE79cLRMcQytC3Fx59KB8GqePPUUtq/Gbgb/D8oOehVXOaJ2vFIyy6qeILlfjy3cM4+m0ey8qC1C28f239fQ6dKivg2qCMT7I+waPbH8Wp8lPmCUbCsbCoDYPegNQdudj0tzTO+yeAusm2v+f1sVHY5HrG6OefuXoG07ZPw/KM5WjRt5gwGckBC4ta1VY2YusHGfhx6wXobXS1X9HUje3PT2f1NBp8MPxql1+mRd+Cj459hOnbp+Ps1bMmCEZywcIiAED+iSv48p3DKDzV9TcMMp6qoVp0BGFKJsTgqF3R7TfsoJPlJzF121SsOb7GZK9JYrGwbJxep0fKpnP45h/HUF/Ne4BEU9XbZmFJbm746wDTr7LcrG/G31L/hpf2vYTaZhs+erUSLCwbVnWlHl//LQ1pifmcA1AmVLW2uQpz9v0RKFKbr6yT8pLw6LZHcb7ivNn2QebHwrJRuVmX8dW7R1CSY5tvkHKlqqsUHcHipG5BWNQ90+z7ya3KxbTt07AzZ6fZ90XmwcKyQRnf5WPHR5lorOMoKrlRVdveNcTESX5okCzzs1jfUo9XDryCxUcWQ2cjKztbExaWDdHp9Nj72Sn8sPEceLu4PEk1FaIjWJQuqi8+9bb8KrxrT6zFrD2zUN1km9cMlYqFZSMaaprxzbIMnDh4SXQUaofGTgXJlj71SxL+dY+4qb5+uPgDpm+fjtzKXGEZqHNYWDagvKgWGxal4uKZCtFR6Ba0drb1z7F6dDS+c8oRmiG3KhfTd0xH8sVkoTmoY2zrX4gNyj9+Bf957yiqyjjlj9xptZ2cj0jBJAcHLL7DdPdcdUV1UzX+b/f/4avTX4mOQrfBwrJi2QcuYts/M9FUz8EVSqDV2M6FxbxJUTilvSw6RiudQYe3D72NVdmrREehW2BhWam0xDzsTzgNA6dYUgyN2jb+riRvL7zb56ToGDf1/tH38UHaB6JjUDtYWFbo0ObzSNnEGySVRqOyjQEXh+N64apKvqeoP8n6BIsOLwJXXpIfFpYVMRgM+P6rMzi6M090FDKCBjZw6rZXD/w9yPw3CXfVZyc/w5+S/wS9gQuWygkLy0oY9AbsXXcKmXsKRUchI9lCYX090RUtkjJKYNO5TXj1wKto1nOOTblgYVkBnU6PXf86jpPJ8hh1RcbR6JtERzCrpjsHYr27shZXTMxNxJw9c9CoaxQdhcDCUryWZh12rsjCuaOloqNQF6n1VvymqFbjo7uVOVv69xe/x/PfPY+6ZtteXFMOWFgKptPp8e2KbORmXREdhUxA3WK9hXVlXAySHQpExzDakeIjeGbXM6hstL3JieWEhaVQBr0B3/37BPKPs6yshbpZviPnukJydsbCqFzRMbos83Imnk16lutqCcTCUqh9X5zmaUAro7bSU05n7h+APE2F6BgmceLKCbyw5wU06az7eqNcsbAUKGXTOZz4npPYWht1o/V9cpcC/LAg1PKzsZvT4eLDePXAq1yeRAAWlsKkJeZdWyGYrI6qwfqWutgXF4IayfqORnbn78ZfDv1FdAybw8JSkOPfX+QMFlZMVW9dhWXoF4aPfOV/k7Cxvj77Nf6V9qHoGDaFhaUQZ1NLsD/htOgYZEaq2irREUxq3TgNDFY8AX2Eaw9M2fsBcPgT0VFsBgtLAS6dq8B3q09wlWArp6qzniHTdXcPwjaXc6JjmM0wj75YfToDPtUlwLevAad3io5kE1hYMldd3oCdH2dB38K2snaq6quiI5iGVov3h8pn6RBTm+w5EB8d2wfnxv+ewjXogI2/AS6liw1mA1hYMtbcqMP2jzJRX825zGyBVFMhOoJJFE2MRqZdiegYZjHDIxIL076F9n/nF2yuBRKmAhXKvTlaCVhYMmUwGLB7zQlcKawRHYUsQGOngmQFw6QlD3e82/+M6BgmJ0HCy64D8Er6dkho52xHTQnw+SNAg/Wc2pUbFpZMHdmei/NpZaJjkIXY2VnHP8VjcX1QqrKu+8m0Ki0W2vfCE5nf3n7jspPA18+CF5zNwzr+lViZ8+mlOLI9R3QMsiCNVnSCrpO6B2NxN+saxu6idcZyvRcmn9rb8Sed2QmkcLi7ObCwZOZyYTW+W30S7Z11IOuk1YhO0HXbJ3mjUVL+ac3rfOy9sKpawtCcI51/8nd/BgqPmj6UjWNhyUhDbTN2fJSFlkbr+UdPHaNRK/sTSkt0P6z2OiE6hsn0dA7CZ6XliCgy8mvSNwMbnwTqK0wZy+axsGRk95qTqC5vEB2DBNCoFPwhRaXCJ2OsZyRrlFtvrLtwBsHlXZwCrSIf2Po704QiACws2Ti2uwC5mdZ77wrdmgYtoiMYrfKeaOx1zBUdwyRGe/TDpyd/hEdduWle8ORWzoRhQiwsGSjNq0LyJuudFYBuT2NQZmFJjg54b/BF0TFM4mHPSCzL+A6OTSZe5iXxDaDIugajiMLCEqypoR6Ht+zkTBY2TmNQ5ozmOZOjcFaj/EVEf+seiT+nbYfaYIZTs7pGYMOTQKN1TW4sAgtLsL2rV+L0D2vh5XcAdg7K/JRNXafWN4qO0GkqH2+8G6bsgRZqSY15Tn0xO2O7eXdUfh745kXz7sMGsLAEOvtjMrL3JgEALp1Oha4hAZ7+FWJDkRDqFuUVVsr9oahUKXeQkIPaHu+rQ/Cr40mW2WH2RuDoGsvsy0qxsASpKb+CXSv/0eax2quXUXxmNfy6nQAkniK0JermetEROie8J5YGHhOdwmhudq5Y2eiCe89+b9kdf/saUHrSsvu0IiwsQZI++RANNTee0zbo9cjP3AkXl21wclXep24yjtrUF/rNbMN4Z+gUend7oKMv1l1tQkyBgNnVW+qvzeyus57bACyJhSXAqeQDuJB267vnL+efRU3ZKviGFFkoFYmkblLO/HuNQyOxwU2Zi4mGu3THuotF6FV6VlyI0hOcuslILCwLa6ipwd7VKzu0bVN9HQqyvoBP4CGotQq+sZRuS9WgkBFkGg3+MUKZKyPf4R6ONWez4F95SXQUYP9iLkViBBaWhe3/7F+oq6zo1HMKTyRDg6/g7qOQNzXqNFW9Mv5uy+6LxmF75d13Nd5zAD7OOghXuSz90Vx77XoWdQoLy4IKjme2jgrsrMrSIlzOWQW/budgUOi1A2qfqlYmb6S3ILm6YMFA5a0iMN0zCovTE2Gnk9k14dPbgdM7RadQFBaWhbQ0NSHpk66dt9a1tCA/cys8PJPg4KzMG03p5pRQWCfj+qNQI/+c10mQ8KLrAMxN2waVQS86zs19+yqgtBGiArGwLOTQ1+txtcg0585LLmSjsXItvIO4wKO1UNVUiI5wS1JQABb2yBIdo8M0kgbvOIRhZkcWXRSpIg848DfRKRSDhWUBl/NzcWTr1yZ9zfrqKlw8vg6+welQqWX66ZE6TJJ5Ye2eHIg6lTKGYjtpnPAh/PDgyd2io3RM8gfAZYGjFhWEhWUBe9d+Cr3OPNMuFWTvhb32a7h4Kus+HvqJxk4FSS/fUaD6AeFY4auMoysve0/8u06LERcOiY7ScbomYPsfRKdQBBaWmV1IP4L8rAyz7uNqUT4qCv8Nv255Zt0PmYednbz/Ga4ZK+9813VzCsBnZZUYcFEZ5dpGzn4ga6PoFLKnjJ9EhdLrdTjw2SqL7KulqQn5mf+Bp+9+aB2VceqGrtFoRSdoX+2oGHzrfF50jNsa4BaKdXk56HYlV3QU4yW+DjQo8x43S2FhmVH2niRcKeziqqWdVHTmKPT1CfD0v2rR/ZLxtBrRCW5OsrPDkrtKRce4rREeEfj3qaPwrlH4IKSaEmDPO6JTyBoLy0yaGurxw1efCdl37dUrKD69Bn4hxyFxEl3Z06jl+XdUOGkQsrUlomPc0oOekfjHsb1waqwRHcU0jnwKlJ4SnUK2WFhmcmTLxk7PaGFKBoMe+VmJcHb+Bs7uyl0CwhZoVPIbcCF5euDdiDOiY9zSTI9IvJu2HVq9FZ0CN+iAA++JTiFbLCwzqC6/jNTtm0XHAABcLjiH6pLVnERXxjSQ38KdafeH47JKnhPyqiQV/ujSDy+mm3nRRVGOb+Iw93awsMwg+avP0dIon2lgrk+i6x2QAg0n0ZUduRWW1LMbFgfLc60rO5Ud3tP2wGNZiaKjmI9Bz5uJ28HCMrHK0mKcOLBHdIybungyBSrDl3D3VcZEq7ZCo5fXNFtbJ3qgRZLfzeiuWhesaPHAhNP7RUcxv6wNQPkF0Slkh4VlYoe3bIReJ9+jmKqyYpSdXwW/bmc5ia5MqPXyORpvHtIf6zzltyKun4MPVlfqcWdequgolmHQAQeWiE4hOywsE6opv4Lj++U/HYxe14L8zG/g7pnISXRlQN0ik8JSqbBilPwG6PRyCcHnRaXoU2Jjo+cy1wNXORnAz7GwTOjIN19D16ycEUulF06goWItfDiJrlBqmczWXTE2Bt87WPa+wduJcQ/D2vMnEVBRKDqK5elbgIPvi04hKywsE6mrqkTmbuWtbdNQU4XC4+vgG5wGlUZ+1y1sgbpJ/Gg8yckJi6LltQLuvZ79sfJ4MtzrbPgm+IwEoNL0ZX3gwAE88MADCAoKgiRJ2Lx5822fs2/fPgwePBj29vYICwvD6tWrTZ7rdlhYJpK2Y4usRgZ2VkH2Pthrvoarl/g3T1ujbhT/PT8XNxDnNeWiY7T6lWck3k9PgkOz/E5RWpSuCTj4d5O/bG1tLQYNGoR//vOfHdo+JycHcXFxuOeee5CRkYEXX3wRTz/9NBITLTtaUzIYDLzy3kWNdbX4ZNZv0Fgn/o2nqzR2dgiKeAClBT1ER7EZwxoT4ZSyVdj+JX9fPP1UPSoleZTDLLeBeO7YDtEx5ENtD8w5BrgFmuXlJUnCpk2bEB8f3+42r732GrZv347s7OzWxx599FFUVFRg507LnVniEZYJpO/cZhVlBfxsEl2fvbBzkNf9QdZKVS/2NoODcd1lUVZqSY0/O/ZhWf0vXSPww1KhEVJSUjBu3Lg2j02YMAEpKSkWzcHC6iK9Todju6zvjvuis+nQ1X8GrwD5nCayVqpaccvOG/r2wgd+4m8SdlQ7YJkqCA+f+E50FHk6ugaoFjevY3FxMfz9/ds85u/vj6qqKtTXW27QEAuri86lHkLNVet8U6+tKEfRqbXw65bNSXTNSFVbIWzf6+9zgEEStnsAgKedOz5tcMTocz+IDSJnLfXAUcssVSRnLKwussajq58zGPTIz9wFJ+etcHaXx/Bra6OqrhCy3/rYKGxyFTvBbbCTP9aW1yGqUPxRnuylrQMErUwdEBCAkpK2R3glJSVwc3ODo6OjxXKwsLqg/FIh8rMzRcewiCsF51Fdsga+IZdER7E6kohTghoNPhgudrh4hGsPrCsoQM8y+S8QKQtVhcDZJCG7jo2Nxe7dbSdFSEpKQmxsrEVzsLC64FjSt6IjWNS1SXTXwzsgGRo7+U4/pSQaOxUkAZ+aSybE4KiduBn8h3r0waozx+BbVSwsgyIdXW2Sl6mpqUFGRgYyMjIAXBu2npGRgfz8azeOz507FzNmzGjd/rnnnsOFCxfw6quv4tSpU/joo4/w1Vdf4fe//71J8nQUC8tIzU2NOKGAaZjM4eLJQ5B06+Hhx+W8u8rOzvL/BCU3N/x1wDmL7/e6SZ4DsTzzAFy4HHznnd0FVF7s8sukpqYiJiYGMTExAICXXnoJMTExeOuttwAARUVFreUFAKGhodi+fTuSkpIwaNAgLFmyBJ9++ikmTJjQ5SydwfuwjJS1dxd2rfhAdAyhVGo1QgZMQmlBOADBV+4Vys1Tizs2PWvRfR6ffif+3CPdovu8boZHFF5O3w6JEy8bb8xcYMwfRacQgkdYRjq2y7ZOB96MXqdDfuY2uHkkwtFZubN8iKTVWPaNWwoJwqLuWRbdJwBIkPCya3+8kr6NZdVVaesAvW1Oo8bCMkJZXg5KLnBF0OtKc06gvmItfIJLRUdRHI3asm/euyb5oUGy7A3hWpUWC+x74YlM5c21KUtVhUDuAdEphGBhGeHUDzawgFwnNdRUozD7M/gGpXIS3U7QqCw34EIX1Ref+GTffkMTctY44SO9N+JO7bXofq3esS9FJxCChWWE0ynfi44gWwXHD8BOvZGT6HaQBhY62pEkrBpj2aM5H3svrK5RYVjOYYvu1yac3Ao01YlOYXEsrE4qOncalaXipkhRgoriQpTnr4JftxzRUWTPUoVVPSYau5wtt+R6T+cgrCstR0TRCYvt06Y01QCntolOYXEsrE46nWyb5447S9fchPzMTfDw2QM7R+UsamlpGr35V3yWHByweIjl7rmKcuuFtTlnEVIur8Ugrc6xL0QnsDgWVicYDAacTjkoOoaiFJ/NQEvd5/AKtM75FrtKrTf/6Mr8SVE4pb1s9v0AwCiPfvj05GF41l6xyP5s2oX9QLVt3XjNwuqEiyePo6ac/xA7q66iHEUn18IvJAuSigMyfk7dYt7Ckry98Nc+p8y6j+se8ozEsmO74WiD11aEMOiAk9+ITmFRLKxOOMXTgUYzGPTIz0qCkyMn0f05dbN5vxdH7u+FKyrzF8iz7pH4S9p2aPRcQ82iztnWciwsrA7S63U4ezhZdAzFu1J4AVXFq+DbrevTy1gDdZMZR1P26oH3A807ObNKUmGecwR+l2HdqxbIVs73QIv5r4PKBQurg4rPnUFdZYXoGFahuaEBBZlfwtv/B2jtbPsTubrRfIW1aaIbWiTznYK1V9vjfXU3/Cp7l9n2QbfRXAvk284HaRZWB+VkpImOYHUunvoRaFkPDz9xK+6KpmqoMcvrNt05AF+4nzTLawOAm50rPml0wdizvCdROBs6LcjC6qC8Yywsc6i+UorSc6vh1+00YINzzKkaqk3/omo1PrrbfNetAhx9sfZqM2IKxEygS//jnO2sGsHC6oD6mmoUn+fcgeZybRLd7XBz3wlHV9uaRFdlhsUbr4yLRrJDgclfFwDCXLrhs4tF6F0qdqVi+pnSE0CVbSysysLqgLzMdBgMHI5tbqW5J1F3ZY1NTaKrqq0w6etJzs5YGJVn0te87g73cKw9mw3/Stt4c1QUGzktyMLqgFxev7KYxtoaFGZ/Bp+gVKg11r+qsaq6wqSvdyZuAPI0pn1NALjPcwA+zjoI1wbbvd4oaywsui4vk4VlaYXHD0Cr+g/cvK14El0JkEx4SlAK8MOCXqafjX2aRxT+lp4IO51tna5VlAv7AL0NfMATHUDuyvJyUHOV0wqJUFFSiCt5/4ZfN8tN2mpJGq0KkgnfZPbHhaBGMu09OXPcBuL19G1Q8ZS4vDVUAoWpolOYHQvrNvIyORJKJF1zM/IzN8PDezfsnaxrEl07O9P98zP0641/+pruJmGNpMG7DuF4+tgOk70mmZkNnBZkYd3GpbOWmYeNbq343DE0V6+DV6D1zOWo0Uome63Px9nBYKKXc9Q44h+SPx48aTvDpa0CC4uKzp4WHYH+q66qApdOroVvyDGrmERXqzHNfWd1dw/CVhfT3HbhZe+JVXV2uPt8iklejyyoKAOos+7LFyysW6guv8zZ2eXGYEBB1m44OmyBs4eyJ9HVqE1Qulotlg41zc9oN6cArCurxICLWSZ5PbIwg/5aaVkxFtYt8OhKvsov5qCqaBV8Q8xzg6wlaExwlFg0MRoZdl1fE6m/a0+sy8tB9yu5XX4tEqjY9KNE5YSFdQssLHlrbmhAQdYGePl/D6298ob0atC1iX8lD3e827/rM06M8IjAqtNp8K4p6/JrkWAlLCybxcJShkunjsDQnKC4SXS7WliZ9/dFqapr96k94BmJfxzbC6dG80zCSxbGIyzbpNfpUJJzTnQM6qCaK2UoObsKft1OApIyJtHV6I2/Z0rqHoz3Qo51af+/8YjEu2k7oNVb1+0CNu3yGcDMq1iLxMJqx+WCPLQ0Wu9fvDUy6PXIz/wWrq47FDGJrroLM0fsmOSDRsm406AqSYU/uvTD79O3Q7LBGfKtmr4ZKLPeW3FYWO3g7OzKVZZ3GnVX1sA3uER0lFsytrBaovthlddxo55rp7LDe9oeeCwr0ajnkwJY8WlBFlY7rhSYZ8ZrsozG2hoUZH8On8DDUGvlOSBD3WzEsHxJwqejjTuF56p1wQqdJyac3m/U80khiq33tgQWVjsuF+aLjkAmUHjiIDTSBrj5yG9Qgbqp8wMmKu+JwR6n3E4/z8/BG6sr9bgz90inn0sKY8UjBVlY7ShnYVmNypJLuJK7Cn7dLsAgo2s26sbOFZbk6ID3hlzs9H56uYTgs+LL6FNivdc26Gd4hGVbGutqOUO7lbk+ia6n927YO5l2RnNjqRqqO7V9zuQonNV0blaLaLfeWHv+JAKvKvcGa+qkhgqgslB0CrMwqrDq6+tRV1fX+vu8vDwsXboUu3btMlkwkcovWedfNgHF5zLRVP0ZvGUwia6qvuOFpfLxxrthJzr1+vd49scnJw7Bve5qZ6OR0lnpUZZRhTVlyhSsXbsWAFBRUYGhQ4diyZIlmDJlCpYvX27SgCJUFHEJcGtWX1WBiyfXwi/kGCRTzOdnJFVdVYe3Tbk/FJWqhg5v/4hnJP6engQHYwZ2kPJZ6UhBoworLS0NI0eOBABs3LgR/v7+yMvLw9q1a/HBBx+YNKAI5Sws62cwID9rNxztt8DFU8ybuqq2omMbhvfE0sCO3yQ8y20g3krbDrVBnqMjyQJKO3c0rhRGFVZdXR1cXV0BALt27cLDDz8MlUqFYcOGIS9P+cPBK4pZWLai/GIOKi+ugl83y1/jUVVXdGi7DeOdoevAYBG1pMafHfvgOS66SNVdnxBZjowqrLCwMGzevBkFBQVITEzE+PHjAQClpaVwc3MzaUARKkus8y+bbq65sQH5mRvg5XcAdg5dm9+vwyRAqrn9taXGoZHY4Hb7OS0d1Q5YpgrCwyesfxE/6oDaUtEJzMKownrrrbfw8ssvo2fPnhg6dChiY2MBXDvaiomJMWlAEThC0DZdOp0KfeMX8LTAJLoarQqS4TZHTRoN/jHi9te5POzc8UmjI0af+8FE6UjxaqyzsDTGPOmXv/wl7r77bhQVFWHQoEGtj48dOxYPPfSQycKJUlfJUVW2qqa8DLUVq9BtwHiUXuwHk607/z/s7G7/WbHsvmgcts+45TbBTv5YXlqO0LLzJkpGVqGxCmhuALQOopOYlFFHWHv27IGHhwdiYmKgUv30EnfddRciIiJMFk6E+uoq6FosdFqIZMmg1yM/aydcXbfD0bXjI/M6Q6O9dRFKri5YMDDnlttEuPbAuoIClhXdXI2859I0hlGF9eCDD8LDwwMjR47EvHnz8N1336G+3jqGz9ZW8OiKrinLO4O6y2vgE2z6a5paza1PB56M649CTfunJoe698GqM8fgW8XrrdSOWutbkNOowrp69Sp2796NSZMm4fDhw3jooYfg4eGBESNG4M033zR1RouqvcrCop801tWiMDsBPoE/mnQSXc0t7v+SggKwsEf7N35O8hyI5VkH4NLQ8fu4yAbxCOsarVaLESNG4PXXX0diYiIOHTqEadOm4fDhw1iwYIGpM1pULa9f0U0UnvgBGmyAm0/nplNqj0Zqv7B2Tw5EnermM7LP8IjCorRvodXJY3opkjErHHhhVGGdOXMGK1euxPTp0xEcHIzRo0ejsrISf/vb35CWlmbqjBZVyxGC1I7K0ku4krMKft3Pd3kSXY108+uk+gHhWOF749GVBAkvu/bHK+nbuOgidYwVFpZRowQjIiLg6+uLOXPm4I9//CMiIyMhSeYZTWVpvIZFt6JraUH+sS3w7x2JhsYxaKzVGvU6Gty8sNaMvfEzpEalwTvaHojL3GnUvshGWeG9WEYdYb3wwgsIDg7GX/7yFzz33HN44403sGvXrjYT4ipVfZX578Eh5Ss5n4WmyrXwDrxs1PM1+htP6dWOisG3zm1H/DlrnPCR3gdxp/YatR+yYbyGdc3SpUuRlpaG4uJizJ07F01NTXjjjTfg4+ODESNGmDqjRTU3GrdsOdme+upKXDy5Dr7BGZ2eRFeta/tzJtnZYcldbT8R+9h7YVWNCrE5h7uclWxQDUcJtqHT6dDc3IzGxkY0NDSgsbERp0/ffhoZOWtpYmFRJxgMKMjeAwe7TXD17PgZBrWu7f1dhZOika396RNxT+cgrCstR78i65zElCyAR1jXvPDCC4iKioK/vz9++9vf4tKlS3jmmWeQnp6OsjJlt3pLE0dfUeddvZSHq4Wr4NetYytVq5t/KizJ0wML+p5p/X2kWy+szTmLkHKuek1dUCd+zTdTM6qwioqK8OyzzyIjIwNlZWX4z3/+01piSh98wcIiY7U0NSI/cyO8fPffdhJddVNt6/+n3R+OUnUNAGCURz/86+RheNZa35sNWZju5rdGdNXXX3+N8ePHw9vbG5IkISMjo0PP27BhAyIiIuDg4IDIyEjs2NH5VQWMKqwNGzZg9uzZGDhwoDFPl7VmnhKkLrp05ih0DQnw9K9odxt147XCknp2w5LgTADAQ56RWHZsNxyblD94iWRAb54p5mpra3H33Xdj0aJFHX5OcnIypk2bhpkzZyI9PR3x8fGIj49HdnbnFpo0+hrWunXrMGLECAQFBbWugbV06VJs2bLF2JeUBV7DIlOovXoZxWdWw6/bCUC68b4pVcO1G5C3TvJEk6TDM+6R+EvadmjM9CZDNshMP0u//vWv8dZbb2HcuHEdfs6yZcswceJEvPLKK+jXrx/efvttDB48GB9++GGn9m1UYS1fvhwvvfQSJk+ejIqKCuh016as8fDwwNKlS415SdngKUEyFYNej/zMnXBx2QYnt7aDLFT11Wge0h+fe57Cm84ReCFju6CUZL0MgL5zo1fNJSUl5YaCmzBhAlJSUjr1OkYV1j/+8Q988skneOONN6BWq1sfv+OOO5CV1f4caErQwmHtZGKX88+ipnQ1fEOKWh9TNdRg1Wgd3ld3w9TsXQLTkVWTyRF7cXEx/P392zzm7++P4uLOTd5sVGHl5OTcdKFGe3t71NbW3uQZysGlRcgcmurrUJD1BbwDDkGj1aE60g+/1lRi7NnvRUcja9bFwvr888/h4uLS+uv778X+vBo1NVNoaCgyMjLQo0ePNo/v3LkT/fr1M0kwUVQ/O2IkMrWLJ5Ph5puDBg8PqC5HINlJ2evHkbwN1RvQlXe0Bx98EEOHDm39fXBwsFGvExAQgJKStveFlZSUICAgoFOvY1RhvfTSS5g1axYaGhpgMBhw+PBhfPHFF1iwYAE+/fRTY15SNlhYZG5VZUU4VlZ0+w2JuuhOqLtUWK6urnB1de1yjtjYWOzevRsvvvhi62NJSUmIjY3t1OsYVVhPP/00HB0d8eabb6Kurg7Tp09HUFAQli1bhkcffdSYl5QNtcaobwkRkexIqi5NZnRT5eXlyM/Px6VLlwCgdXajgICA1iOmGTNmIDg4uHW5qTlz5mD06NFYsmQJ4uLisH79eqSmpmLlypWd2rfRX81jjz2Gs2fPoqamBsXFxSgsLMTMmTONfTnZUGmMm32biEhuJJXpJ3LYunUrYmJiEBcXBwB49NFHERMTgxUrVrRuk5+fj6Kin84iDB8+HAkJCVi5ciUGDRqEjRs3YvPmzZ2+l1cyGAxcXOdn/v3is7hadEl0DCKiLvt9wharuszR4fNfgwcPxu7du+Hp6YmYmJhbTsGk5EUcVWqeEiQi5VOp1VZVVkAnCmvKlCmwt7dv/X+lzxnYHjVPCRKRFbBzchYdweQ6XFh/+tOfWv9//vz55sgiCyqNdX0iISLbZO/kJDqCyRk16OLpp5/Gvn37TBxFHjR2dqIjEBF1mb2j9R1hGVVYZWVlmDhxIrp164ZXXnkFx44dM3UuYRycu37PARGRaDzC+q8tW7agqKgI8+bNw5EjRzB48GAMGDAAf/3rX5Gbm2viiJbl5OYuOgIRUZdZ4zUso+/D8vT0xLPPPot9+/YhLy8PTz75JNatW4ewsDBT5rM4RxYWEVkBHmHdRHNzM1JTU/Hjjz8iNzf3hhl5lcbJzU10BCKiLrN35hFWq7179+KZZ56Bv78/nnzySbi5uWHbtm0oLCw0ZT6L4xEWEVkDeys8JWjUXbLBwcEoLy/HxIkTsXLlSjzwwAOt92gpHQuLiKyBo6v1nS0yqrDmz5+PRx55BB4eHiaOIx4HXRCRNXDz8RMdweSMOiX4zDPPwMPDA+fOnUNiYiLq6+sBANYwLaE1fiohItvj6uMrOoLJGVVYV65cwdixY9GnTx9Mnjy5dVbemTNn4g9/+INJA1qak7s7YKXTThGR7XBjYV3z+9//HlqtFvn5+XD62dDJqVOnYufOnSYLJ4Jao4WLl7foGERERtPaO1jl2SKjrmHt2rULiYmJCAkJafN4eHg48vLyTBJMJE//QNRcuSw6BhGRUazxdCBg5BFWbW1tmyOr68rLy61itKBHQKDoCERERrPG04GAkYU1cuRIrF27tvX3kiRBr9fjvffewz333GOycKJ4BASJjkBEZDRrHCEIGHlKcPHixbj33nuRmpqKpqYmvPrqqzh+/DjKy8vxww8/mDqjxfEIi4iUzFpPCXa6sJqbm/HCCy/gm2++QVJSElxdXVFTU4OHH34Ys2bNQmCg8t/sPfyV/zUQke3yDLTOs0SdLiytVovMzEx4enrijTfeMEcm4Tx5SpCIFMynW0/REczCqGtYjz/+OP71r3+ZOotsaB0c4OzpJToGEVGnabR28Ayyzg/dRl3Damlpwb///W989913GDJkCJz/Z1bg999/3yThRPIKDEbt1XLRMYiIOsUrpBtUKrXoGGZhVGFlZ2dj8ODBAIAzZ860+TPJSmaJ8AvthYITWaJjEBF1im/3nqIjmI1RhbV3715T55Ad/17hoiMQEXWajxUXVpcXcLRW/r2UvXIyEdkm3+6hoiOYDQurHZ6BwbBztL4lponIuvn26Ck6gtmwsNohSRL8QnuJjkFE1GFO7h5wcvcQHcNsWFi3wOtYRKQkAb2t+z2LhXULvI5FREoSHDFAdASzYmHdQgALi4gUJKTfQNERzIqFdQseAUFwcHEVHYOI6LY09vZWf1aIhXULkiSh24BI0TGIiG4rMKwv1Bqjbq1VDBbWbfSIjBYdgYjotkL6Wff1K4CFdVvdBw4SHYGI6LasfcAFwMK6Lc/AYKtdDI2IrINKrUFQnwjRMcyOhdUBPMoiIjnzD+0Nrb2D6Bhmx8LqAF7HIiI56xk9WHQEi2BhdQCPsIhIznoPGSo6gkWwsDrA2cMT3iHdRccgIrqBi7eP1d9/dR0Lq4NCY+4QHYGI6Aa9B98pOoLFsLA6KPyuWNERiIhuYCunAwEWVocFhkfA2dNLdAwiolZaB0d0s6Fr7CysDpIkCWF32M4nGSKSvx6R0dBotaJjWAwLqxPC7houOgIRUaveNvYhmoXVCd0HRMHR1U10DCIiqNRq9LKhARcAC6tTVGo1wnmURUQy0HPQYDi5uYuOYVEsrE7qO3yk6AhEROg/6l7RESyOhdVJIf0HwtnDU3QMIrJh9s7O6H3HMNExLI6F1UkqlRr9Rt4jOgYR2bC+w0ba1OjA61hYRoi8d4LoCERkw2zxdCAAyHY9Zb1ej6amJtExbsrJyxuhd8ai5PxZoTkMBj0aKith0OuE5iAiy/HwD0RwRH/RMYSQZWE1NTUhJycHer1edJR2hY2djOC7qoRmMMCAxupqZH6dgKaaaqFZiMgybPXoCpBhYRkMBhQVFUGtVqNbt25QqeR51tKg16O8qBB6nbhSNRiAq07O6DVyLE59uwWAQVgWIrIASUL/UbZ7DV12hdXS0oK6ujoEBQXByclJdJxbcnX3RF1lhdAM7i4uqOvRC1pHRzTX1wnNQkTm1SMyGu5+AaJjCCO7wxed7tr1GDs7O8FJbk8Os16oVRIktQoaB0fRUYjIzIZMniI6glCyK6zrJEkSHeG2tPb20Do4iI4BCZIivl9EZDyvoBD0jB4iOoZQsi0spbC1qVGISIyYSQ/a/AdTFlYXObi4Qq2R3aVAIrIiDs4uGDDadkcHXqeYd9qef9xu0f3lLozr0HaSJMHJwxPVl8tu+LPtiYlYm7AeWceP42pFBZK2bsbA/re/f+KbHd9i0dKlKCy8iNCePfHmqy9j7Jgxnf0SiMhKDLx3PLT24i8/iMYjLBNwdHWDSq2+4fG6unoMvWMI3njl5Q6/1pG0NDz/+5cw/ZFHsGvrZky8bxyeen4WTp05Y8rIRKQQKrUaMRMfEB1DFhRzhCVnKpUKTm7uqLla3ubxRx6KBwAUFBZ2+LU+Xb0G94waif975mkAwGu/fxEHDv6Af6/7DO+9/ReTZSYiZQi7MxZuPr6iY8gCj7BMxNHd3SQXRFPTMzByeNs1t8aMvBtH09O7/NpEpDx3PPCQ6AiywcIyEbVaA0e3rt+XVXb5Mnx9fNo85uvjg9Kyy11+bSJSlp7RQxAY1ld0DNlgYZnI559/jqCevdA7Khq9o6Jx6MgR0ZGISOFifzFNdARZ4TUsE3nwwQcxdOhQVF8pQ0NNLQIC/I16HV8fH5Rdbns0VXb5Mvx8fdp5BhFZox5RMQjqEyE6hqzwCMtEXF1dERYWhsjBd6BXaE84GjkDxh0x0TiYnNLmsQM/JGNITIwpYhKRQgx/5DHREWSHhWViGq0Wjv+d/eJqRQWyT5zAmXPnAADnc3KQfeIESst+umfrdy+/gncX/631908/+QT2fv89Vnz6L5w9fx5/W/YBjmVn4ze/ftyyXwgRCdNr8J08uroJFpYZOHt6QlKpsGv3Htz3YDwef/pZAMBzc36P+x6Mx9qEL1q3vXipqE2B3Tl4MD56fwk++/IrjLv/QWzbmYhVy/+JiD59LP51EJEAkoQRU38tOoUsSQaDQVaLKDU0NCAnJwehoaFwkMHEssaqKb9yw31Z5tCs0+FScQnSvliFunKOJCRSur6xI3H/i6+JjiFLPMIyEycPz5vOfkFE1B6VWoPhv+Lp//awsMxEpVLBxdNLdAwiUpCYSQ/AKyhYdAzZYmGZkaObO9RaregYRKQAzh6eGP5L3nd1KywsM5IkCa5e3qJjEJEC3D3tCdg5OomOIWssLDNzcHGFvRN/CImofYFhfTFg9FjRMWSPhWUBrj6+Nr9SKBG1Q5Jw71O/5XtEB7CwLECjtYOzp6foGEQkQwNGj0VAGO+z7AgWloU4e3hCY2cnOgYRyYi9kzNGTX9SdAzFYGFZiCSp4MpF2IjoZ0Y8+ms4uXuIjqEYLCwLsnd0gqOLq+gYRCQD3QZEIXp8nOgYiqKc5UXmu1t4f5WdfsqBAwewePFiHD16FEVFRdi0aRPi4+PbbOPi7YPG+lrodXoAQPKhH/Gnvy7AmbNnERQYiBdn/R+m/uJhU3wFRCRTWnsHTHjuBQ606CQeYZlQbW0tBg0ahH/+85/tbqPWaODqfe3UYH5BAR5/5lmMGDYUSd9swTNPPoE/vP4G9h743lKRiUiAUY89BXe/ANExFEc5R1gKMGnSJEyaNOm22zm6uqGxthZrv1iP7iEhmP/6XABAn7AwHD56FCtXrcY9o0aaOy4RCdBtQBQGjZ8sOoYi8QhLEDdfPxzNyMDIEcPbPD5m5EgcTU8XlIqIzImnAruGhSWISq3G5fKr8PVuO3WTr483qmtqUN/QICgZEZkLTwV2DQtLIEmSoFXwml9E1HHdB/JUYFexsAQKCAhARXVNmxuKyy5fgauLCxxZZERWw8ndA5Nmv8xTgV3EwhIoNjYWe/bsgbuff+sP8oEffsCQmBjByYjIVCRJhcmzX+b6eCbAwjKhmpoaZGRkICMjAwCQk5ODjIwM5OfnAwDmzp2LGTNmtG7/3HPP4cKFC3hj3lu4ePkyVn/2Obbu+BbPPvWkgPREZA7DfjEVPaKiRcewCiwsE0pNTUVMTAxi/nuE9NJLLyEmJgZvvfUWAKCoqKi1vAAgNDQU27dvR1JSEmJHjsbHq1ZjyV/f5ZB2IivRPTIasb/gooymIhkMBoPoED/X0NCAnJwchIaGwsHGruPo9TqUXyxES1NTh5/TrNPhUnEJ0r5Yhbryy2ZMR0Sd4ezphRmLPuBcgSbEIywZUanU8PAPhKTiXwuRkkkqFe5/4VWWlYnxnVFmNHZ2cPfzFx2DiLpgxK8eR0j/gaJjWB0Wlgw5OLvAmSOKiBSpT+xI3BX/iOgYVomFJVMunl6wd3ISHYOIOiEwvC8m/d/veb+VmbCwZEqSJLj7BUCt1YqOQkQd4Obrj/hX5nFlcTNiYcmYSq2GZ2AQVGq16ChEdAv2Ts54+I9/4iALM2NhyZxGawfPgCCOHCSSKZVajftffA3eId1FR7F6fBdUAK2DAzz8A3henEiG7n3qOfQcNFh0DJvAwlIIeydnuPn6iY5BRD8z5P6HMOi+2y/aSqbBwlIQR1c3uHh5335DIjK7AaPHYfTjvxEdw6ZoRAfoqMg1kRbdX9YTWZ3afsGCBfj6669x6tQpODo6Yvjw4Vi0aBH69u17y+dt2LAB8+bNQ25uLsLDw7Fo0SJMntz+mjkunl7Qt7SgrqqyU/mIyHT6xo7kysEC8AjLRPbv349Zs2bh0KFDSEpKQnNzM8aPH4/a2tp2n5OcnIxp06Zh5syZSE9PR3x8POLj45GdnX3Lfbn6+MLB2cXUXwIRdUDvO4Zh8u9e5kAoARQz+a3cj7D+V1lZGfz8/LB//36MGjXqpttMnToVtbW12LZtW+tjw4YNQ3R0NFasWHHL1zcYDKgsKUZ1VSUnvyWykJ6DBmPKK/Og4f2RQvAjgplUVl47Zefl1f4USykpKRg3blybxyZMmICUlJTbvr4kSXD3D4CdI2fDILKEkP4D8eDLb7CsBGJhmYFer8eLL76IESNGYODA9ifALC4uhr9/24lu/f39UVxc3KH9SJIENx8f3llPZGaB4X3x0Gt/gtbOXnQUm8bCMoNZs2YhOzsb69evN/u+JEkFRzd3dI8cZPZ9EdmiwLC+eHjun2Hn4Cg6is1TzChBpZg9eza2bduGAwcOICQk5JbbBgQEoKSkpM1jJSUlCAgI6NQ+JUnCPU88C31jI84cOtjpzER0cz2iYjDlD29Aa2OLycoVj7BMxGAwYPbs2di0aRP27NmD0NDQ2z4nNjYWu3fvbvNYUlISYmNjO71/lVqNuDmvIGLE6E4/l4hu1GfoCDz02lssKxnhEZaJzJo1CwkJCdiyZQtcXV1br0O5u7vD0fHaqYQZM2YgODgYCxYsAADMmTMHo0ePxpIlSxAXF4f169cjNTUVK1euNCqDSqXG5N+9DGcPDxzdvsU0XxiRDYocOwH3PT2LQ9dlhn8bJrJ8+XJUVlZizJgxCAwMbP315Zdftm6Tn5+PoqKi1t8PHz4cCQkJWLlyJQYNGoSNGzdi8+bNtxyocTuSJGHMjGcwZsbTAG9qJOq0O6f8EuOf/R3LSoYUcx8W3dytvl+nUw7i238uga65WVA6ImUZ9dhTuPPBX4iOQe3gKUEr1jf2bjh7eGDL4nfQUFsjOg6RbKnUGox75v8Qec940VHoFnjMa+VC+g3Eo395D64+vqKjEMmSo6sbHnnzHZaVArCwbIB3SHdMf2cJfHv2Eh2FSFZ8uvfEY3/9O0L6G3/dmCyHhWUjXDy9MO0v73HYO9F/hd05DNPeXgx3P//bb0yywGtYNkRr74C4F15BYHhf7F/3b+h1LaIjEQkx7OGpGP6rx7k8iMKwsGzQ4EkPwi+0N7b9fSFqK66KjkNkMRp7e0x8/kX0jR0pOgoZgacEbVRIxAA8vnAZgiP6i45CZBEe/oF49M/vsawUjIVlw1w8vfDIvL8iZtIDoqMQmVXf2JF4fOEy+If2Fh2FuoCnBG2cWqPBvU/+FkHhEfju04/QWNf+CslESqOxs8c9TzyDqHETRUchE2BhEQAgYsRoBPXtj8Tlf0d+dqboOERd5tu9Jya/8Ap8uvUQHYVMRDGFdTKin0X31+/UyU5tv3z5cixfvhy5ubkAgAEDBuCtt97CpEmT2n3Ohg0bMG/ePOTm5iI8PByLFi3C5MmTuxK7S9x8fPHLN99F2o6tOPjFGrQ0NwnLQmQ0ScLgSQ9i5PQnuTqwleE1LBMJCQnBwoULcfToUaSmpuLee+/FlClTcPz48Ztun5ycjGnTpmHmzJlIT09HfHw84uPjkZ2dbeHkbUmShCFxU/D4wqXw68nz/aQsLp5e+MUf5+OeJ55hWVkhxUx+K/cjrJvx8vLC4sWLMXPmzBv+bOrUqaitrcW2bdtaHxs2bBiio6OxYsWKDu/DnJMF61pakLIxAYe3bIRBrzfpaxOZlCQhauwEjHrsKdg7OYtOQ2bCIywz0Ol0WL9+PWpra9tdjDElJQXjxo1r89iECROQkpJiiYgdotZocPejMzB1/iJ4Bd169WQiUTwDgzH1rQW475nZLCsrp5hrWEqQlZWF2NhYNDQ0wMXFBZs2bUL//je/z6m4uBj+/m2nhPH3929d+FFOgvv2w4zF/0DqN5tw6Osv0dLUKDoSEVRqDe588GEM+8U0nv6zESwsE+rbty8yMjJQWVmJjRs34oknnsD+/fvbLS0lUWu0GPrQrxAxYjT2rP4YF44eFh2JbFhA73CM/+0L8O0RKjoKWRALy4Ts7OwQFhYGABgyZAiOHDmCZcuW4eOPP75h24CAAJSUlLR5rKSkBAEBARbJaix3P3889OpbOHfkEPauWYmqslLRkciG2Ds5I/aX0zF40gNcEdgG8W/cjPR6PRobb376LDY2Frt3727zWFJSUrvXvOQm7M5heHLJR7hryi+hUvNzD5mXSq1G9IQ4/GbZSgyJm8KyslF8pzGRuXPnYtKkSejevTuqq6uRkJCAffv2ITExEQAwY8YMBAcHY8GCBQCAOXPmYPTo0ViyZAni4uKwfv16pKamYuXKlSK/jE7R2jtg5PQn0X/0WHyfsAbnUw+JjkRWqNfgOzHq8d/AO7ib6CgkGAvLREpLSzFjxgwUFRXB3d0dUVFRSExMxH333QcAyM/Ph+pnnwqHDx+OhIQEvPnmm3j99dcRHh6OzZs3Y+BA5S0k5x3cDfGvvIlLZ07i+4Q1KDwp9l4ysg6+PUIx+tcz0SMyWnQUkgnF3IdFNyfH71dOeiq+X78WZbkXREchBXL29MKIqY9j4OhxPPVHbfAIi0wuNOYO9IweglM/7EfyV5+joqRIdCRSABdPL9z54C8QOW4itHb2ouOQDLGwyCwkSUK/u8egz7C7kbVnF45s3cgRhXRTbr5+uGvKLzFgzH28n4puiYVFZqXWaBA9fjKixk7A6UMHkbr1a5Tmnhcdi2TAIyAQQ+N/hX4j74Faw7ciuj3+lJBFqNRq9BsxGv1GjEZeZgaOfPMf5GWmi45FAniHdMfQh36FvsNHQqVSi45DCsLCIovrERWNHlHRKM29gCNb/4Mzhw5Cr9OJjkVmJKlU6D3kLgwaH4cekdGQJEl0JFIgjhJUOGv4flWVleLYd9/i+P7dqL1aLjoOmZCTuwci752AqHET4ebjKzoOKRwLS+Gs6ful1+twIS0V2Xt3ISc9lUddChYc0R+Dxsehz9DhUGs4kIJMg6cESTZUKjXC7hiKsDuGouZqOY7v+w7Z+5JQUcxh8Urg7OmFvsPuxsB77uOktGQWLCySJRdPLwx96Fe4K/4RFJ7IQva+73DuyCE01deJjkY/4+DsgvChwxExYjS69Y/kjb5kViwskjVJktBtQBS6DYhCS3Mz8jLTcDrlIM6n/sjyEkRr74DedwxFxIhR6DloME/5kcUoprD++dwei+5v1op7u/T8hQsXYu7cuZgzZw6WLl3a7nYbNmzAvHnzkJubi/DwcCxatAiTJ0/u0r6tlUarRe8hQ9F7yFC0NDejIPsYzh05hPNHf0RtxVXR8ayak7sHekTFoNfgO9F78F3QKvx6KSmTYgpLSY4cOYKPP/4YUVFRt9wuOTkZ06ZNw4IFC3D//fcjISEB8fHxSEtLU+QkuJak0WoRGnMHQmPuwDjDLBSdPYWc9FTkZ2ei+PwZDtjoIkmlQmBYX4RGD0HP6CHw7xXGoegkHAvLxGpqavDYY4/hk08+wTvvvHPLbZctW4aJEyfilVdeAQC8/fbbSEpKwocffogVK1ZYIq5VkCQJQX36IahPP4yYCjQ11KPwZDbyszORn30MZXk5gLwGw8qSi7cPekRGIzR6CHpExsDBxUV0JKI2WFgmNmvWLMTFxWHcuHG3LayUlBS89NJLbR6bMGECNm/ebMaE1s/OwRG9Yu5Er5g7AQD11VUoOJGF/OxMFJ09hSsFedC1tAhOKZZaq4VfaG8EhfdFYHg/BIb35X1SJHssLBNav3490tLScOTIkQ5tX1xcDH9//zaP+fv7o7i42BzxbJajqxv6DB2BPkNHAAB0Lc24nJ+HkpzzKM05h5Kc87icl4uW5ibBSc1EkuDu54+AXuEIDI9AUJ8I+IX24mAJUhwWlokUFBRgzpw5SEpKUvwNvNZOrdHCv1cY/HuFAZgAANDrdLhSmI/S3Asov1SIipJiVBRfQmVJMRrrasUG7iCVWgN3P394BgXDKygEPt16wDukO7xDukFrz59JUj4WlokcPXoUpaWlGDx4cOtjOp0OBw4cwIcffojGxkao1W0n+gwICEBJSUmbx0pKShAQEGCRzPQTlVoN3x6hN73htb66ChUlRagoKUZlcREqSotRV3EV9dVVqK+pRn1VldmH2Ks1Gjh7esHZwxMunt5w9vzvfz084ezpBQ//ALj7BUCl5mSyZL1YWCYyduxYZGVltXnsqaeeQkREBF577bUbygoAYmNjsXv3brz44outjyUlJSE2NtbccakTHF3d4OjqhsCwvu1uo2tpuVZg1VWor6pCQ00VWpqboW9pgV6vg75F99//tkCn08Gg00Gn00Gt0UBr7wCtvT009vbQ2ttDa3f9/x2gsbeHk5s7HF3dLPgVE8kTC8tEXF1dbxiK7uzsDG9v79bHZ8yYgeDgYCxYsAAAMGfOHIwePRpLlixBXFwc1q9fj9TUVKxcudLi+alr1BoNXDy94OLpJToKkdXiPCoWlJ+fj6Kin+bFGz58OBISErBy5UoMGjQIGzduxObNmxV/D9b8+fMhSVKbXxEREbd8zoYNGxAREQEHBwdERkZix44dFkpLRErB2doVTo7fr/nz52Pjxo347rvvWh/TaDTw8fG56fbJyckYNWpUmxuoFy1axBuoiagNHmGRWWg0GgQEBLT+aq+sgLY3UPfr1w9vv/02Bg8ejA8//NCCiYlI7lhYZBZnz55FUFAQevXqhcceewz5+fntbpuSkoJx48a1eWzChAlISUkxd0wiUhAWFpnc0KFDsXr1auzcuRPLly9HTk4ORo4cierq6ptuzxuoiagjOEqQTG7SpEmt/x8VFYWhQ4eiR48e+OqrrzBz5kyByYhIyXiERWbn4eGBPn364Ny5czf9c95ATUQdwcIis6upqcH58+cRGBh40z+/fgP1z/EGaiL6XywsMrmXX34Z+/fvR25uLpKTk/HQQw9BrVZj2rRpAK7dQD137tzW7efMmYOdO3diyZIlOHXqFObPn4/U1FTMnj1b1JdARDLEa1hkcoWFhZg2bRquXLkCX19f3H333Th06BB8fa8tX5Gfnw+V6qfPStdvoH7zzTfx+uuvIzw83CpuoCYi0+KNwwrH7xcR2QqeEiQiIkVQzCnBJVPvt+j+/vDltk5tP3/+fPz5z39u81jfvn1x6tSpdp+zYcMGzJs3D7m5uQgPD8eiRYswefJko/ISEVk7HmGZ0IABA1BUVNT66+DBg+1um5ycjGnTpmHmzJlIT09HfHw84uPjkZ2dbcHERETKwcIyIc6fR0RkPiwsE+L8eURE5sPCMhHOn0dEZF6KGXQhd5w/j4jIvHiEZSacP4+IyLRYWGbC+fOIiEyLhWUinD+PiMi8eA3LRDh/HhGReXEuQYXj94uIbAVPCRIRkSKwsIiISBFYWEREpAgsLCIiUgTZFpbMxoLIFr9PRGQrZFdYarUaANDU1CQ4iTJc/z5d/74REVkr2d2HpdFo4OTkhLKyMmi12jb3LlFber0eZWVlcHJygkYju79KIiKTkt19WMC1o4acnBzo9XrRUWRPpVIhNDQUdnZ2oqMQEZmVLAsLuHb0wNOCt2dnZ8ejUCKyCbItLCIiop/jR3MiIlIEFhYRESkCC4uIiBSBhUVERIrAwiIiIkVgYRERkSKwsIiISBFYWEREpAgsLCIiUgQWFhERKQILi4iIFIGFRUREisDCIiIiRWBhERGRIvw/G+c0oDfPGVoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = ndf.groupby(['ratings']).count()\n",
    "print(count)\n",
    "count.plot(kind='pie', subplots=True, figsize=(5,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1707179412119,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "K2Iuiryn6eAE",
    "outputId": "02bf59c8-2852-43f7-c53f-2df86ca43e6a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great product.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What's to say about this commodity item except...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Haven't used yet, but I am sure I will like it.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Although this was labeled as &amp;#34;new&amp;#34; the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gorgeous colors and easy to use</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640249</th>\n",
       "      <td>I can't live anymore whithout my Palm III. But...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640250</th>\n",
       "      <td>Although the Palm Pilot is thin and compact it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640251</th>\n",
       "      <td>This book had a lot of great content without b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640252</th>\n",
       "      <td>I am teaching a course in Excel and am using t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640253</th>\n",
       "      <td>A very comprehensive layout of exactly how Vis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2640254 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reviews  Labels\n",
       "0                                           Great product.       0\n",
       "1        What's to say about this commodity item except...       0\n",
       "2          Haven't used yet, but I am sure I will like it.       0\n",
       "3        Although this was labeled as &#34;new&#34; the...       1\n",
       "4                          Gorgeous colors and easy to use       0\n",
       "...                                                    ...     ...\n",
       "2640249  I can't live anymore whithout my Palm III. But...       0\n",
       "2640250  Although the Palm Pilot is thin and compact it...       0\n",
       "2640251  This book had a lot of great content without b...       0\n",
       "2640252  I am teaching a course in Excel and am using t...       0\n",
       "2640253  A very comprehensive layout of exactly how Vis...       0\n",
       "\n",
       "[2640254 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getTernaryLabel(ratings_Val):\n",
    "  if ratings_Val > 3:\n",
    "    return 0\n",
    "  elif ratings_Val <= 2:\n",
    "    return 1\n",
    "  else:\n",
    "    return 2\n",
    "\n",
    "#adding new column for the binary labels\n",
    "ndf['Labels'] = ndf['ratings'].apply(lambda x: getTernaryLabel(x))\n",
    "ndf = ndf.drop('ratings', axis=1)\n",
    "ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1707179412119,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "u0V3MIOA7HWu",
    "outputId": "dbbe17c2-b55b-493b-bdb8-d81858157034"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        reviews\n",
      "Labels         \n",
      "0       2001183\n",
      "1        445366\n",
      "2        193705\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count2 = ndf.groupby(['Labels']).count()\n",
    "print(count2)\n",
    "count2.plot(kind='pie', subplots=True, figsize=(5,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 191,
     "status": "ok",
     "timestamp": 1707179412305,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "0PpAQObb8dov",
    "outputId": "14889c64-abfd-4a5c-b0ce-d13dc140f113"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2640254, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BFQFJab8_R6"
   },
   "source": [
    "## Making Samples of 50K and joining them to Binary and Ternary Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1707179412305,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "pnuIqKSa87YV",
    "outputId": "eb3f629d-6261-47f0-e0aa-a3ee22bc59a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2001183, 2)\n",
      "(50000, 2)\n"
     ]
    }
   ],
   "source": [
    "#selecting all positive reviews\n",
    "pos_rec = ndf.loc[ndf['Labels'] == 0]\n",
    "print(pos_rec.shape)\n",
    "\n",
    "#selecting 100,000 of those positive reviews at random\n",
    "pos_rec = pos_rec.sample(n=50000)\n",
    "print(pos_rec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1707179412305,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "q7wmZbYG9gHq",
    "outputId": "ba5223c5-19f3-44a0-fdc9-a1582be97069"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(445366, 2)\n",
      "(50000, 2)\n"
     ]
    }
   ],
   "source": [
    "#selecting all negative reviews\n",
    "neg_rec = ndf.loc[ndf['Labels'] == 1]\n",
    "print(neg_rec.shape)\n",
    "\n",
    "#selecting 100,000 of those negative reviews at random\n",
    "neg_rec = neg_rec.sample(n=50000)\n",
    "print(neg_rec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1707179412305,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "m13s2-GR9r_u",
    "outputId": "04425ba4-7125-471a-cb65-c98f8196ddb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193705, 2)\n",
      "(50000, 2)\n"
     ]
    }
   ],
   "source": [
    "#selecting all neutral reviews\n",
    "neu_rec = ndf.loc[ndf['Labels'] == 2]\n",
    "print(neu_rec.shape)\n",
    "\n",
    "#selecting 100,000 of those neutral reviews at random\n",
    "neu_rec = neu_rec.sample(n=50000)\n",
    "print(neu_rec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am combining the positive review data and negative review data into Binary Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1707179412305,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "eMxU7MVs94KW",
    "outputId": "fdfa9868-dcf3-45a8-88e7-c1d2d5596cb0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1512915</th>\n",
       "      <td>I like these Panasonic cordless phones. They h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851035</th>\n",
       "      <td>The three batteries arrived well packed and ea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420245</th>\n",
       "      <td>My kids use these all the time in their Art Cl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839567</th>\n",
       "      <td>I only replace/ install these as they run out ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145903</th>\n",
       "      <td>Exactly what I needed for my music books.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398822</th>\n",
       "      <td>I fear that I must agree fully with another re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326453</th>\n",
       "      <td>They do not distribute the color evenly.Have t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795919</th>\n",
       "      <td>VERY POOR WIFI RECEPTER, CONTACTED CANON AND W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851482</th>\n",
       "      <td>I called Olympus at 800-622-6372 and was told ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209273</th>\n",
       "      <td>This is the worst printer I have ever gotten. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reviews  Labels\n",
       "1512915  I like these Panasonic cordless phones. They h...       0\n",
       "1851035  The three batteries arrived well packed and ea...       0\n",
       "1420245  My kids use these all the time in their Art Cl...       0\n",
       "1839567  I only replace/ install these as they run out ...       0\n",
       "145903           Exactly what I needed for my music books.       0\n",
       "...                                                    ...     ...\n",
       "2398822  I fear that I must agree fully with another re...       1\n",
       "326453   They do not distribute the color evenly.Have t...       1\n",
       "1795919  VERY POOR WIFI RECEPTER, CONTACTED CANON AND W...       1\n",
       "1851482  I called Olympus at 800-622-6372 and was told ...       1\n",
       "209273   This is the worst printer I have ever gotten. ...       1\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "framesbin = [pos_rec, neg_rec]\n",
    "binframes = pd.concat(framesbin)\n",
    "binframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am combining the Positive, Negative and Neutral data into a Ternary Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1512915</th>\n",
       "      <td>I like these Panasonic cordless phones. They h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851035</th>\n",
       "      <td>The three batteries arrived well packed and ea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420245</th>\n",
       "      <td>My kids use these all the time in their Art Cl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839567</th>\n",
       "      <td>I only replace/ install these as they run out ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145903</th>\n",
       "      <td>Exactly what I needed for my music books.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042827</th>\n",
       "      <td>My students were easily bored with the game.  ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661195</th>\n",
       "      <td>I really wanted to like this, but the folder p...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71154</th>\n",
       "      <td>Bought it for a 50th anniversary slide show mo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199084</th>\n",
       "      <td>Product as described, but I am not convinced t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305877</th>\n",
       "      <td>Lasted 4 months and I rarely print things.  Se...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reviews  Labels\n",
       "1512915  I like these Panasonic cordless phones. They h...       0\n",
       "1851035  The three batteries arrived well packed and ea...       0\n",
       "1420245  My kids use these all the time in their Art Cl...       0\n",
       "1839567  I only replace/ install these as they run out ...       0\n",
       "145903           Exactly what I needed for my music books.       0\n",
       "...                                                    ...     ...\n",
       "2042827  My students were easily bored with the game.  ...       2\n",
       "1661195  I really wanted to like this, but the folder p...       2\n",
       "71154    Bought it for a 50th anniversary slide show mo...       2\n",
       "1199084  Product as described, but I am not convinced t...       2\n",
       "1305877  Lasted 4 months and I rarely print things.  Se...       2\n",
       "\n",
       "[150000 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "framester = [pos_rec, neg_rec, neu_rec]\n",
    "terframes = pd.concat(framester)\n",
    "terframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we shuffle the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "executionInfo": {
     "elapsed": 293,
     "status": "ok",
     "timestamp": 1707179412595,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "4efP53aO_SP-",
    "outputId": "6901a8b4-da33-499f-e6ab-60517cf18a69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1921057</th>\n",
       "      <td>This item came in a home made bubble wrap labe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032152</th>\n",
       "      <td>It works.  I hope it continues working.  Perha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590977</th>\n",
       "      <td>The software that comes with the printer does ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685277</th>\n",
       "      <td>It arrived on time and it came in a huge box. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29865</th>\n",
       "      <td>Works as well as Canon toner</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234437</th>\n",
       "      <td>The signage faded completely away after only a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203972</th>\n",
       "      <td>Product was listed as usable on the MFC870DW. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283458</th>\n",
       "      <td>I cleaned the heads 10 times and there are sti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483295</th>\n",
       "      <td>The highlighters were not new or they were old...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556562</th>\n",
       "      <td>excellent, got one for my daughter. Perfect fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reviews  Labels\n",
       "1921057  This item came in a home made bubble wrap labe...       1\n",
       "2032152  It works.  I hope it continues working.  Perha...       0\n",
       "2590977  The software that comes with the printer does ...       1\n",
       "1685277  It arrived on time and it came in a huge box. ...       0\n",
       "29865                         Works as well as Canon toner       0\n",
       "...                                                    ...     ...\n",
       "1234437  The signage faded completely away after only a...       1\n",
       "203972   Product was listed as usable on the MFC870DW. ...       1\n",
       "2283458  I cleaned the heads 10 times and there are sti...       1\n",
       "483295   The highlighters were not new or they were old...       1\n",
       "556562   excellent, got one for my daughter. Perfect fo...       0\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binframes = binframes.sample(frac=1)\n",
    "print(binframes.shape)\n",
    "binframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1163606</th>\n",
       "      <td>Excellent pen!  Actually this is the only pen ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069284</th>\n",
       "      <td>When you have a fresh set of batteries in this...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338411</th>\n",
       "      <td>These file folder labels are great. I use them...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37088</th>\n",
       "      <td>work's well  ~ is Not the Heavy Duty All Steel...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752649</th>\n",
       "      <td>great quality, great value!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482466</th>\n",
       "      <td>I purchased this pen specifically for outdoor ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504746</th>\n",
       "      <td>We always use Scotch Heavy Duty Tape for packi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599944</th>\n",
       "      <td>I'm on a quest to find a cordless phone with d...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751783</th>\n",
       "      <td>Just received my new printer and love the size...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478502</th>\n",
       "      <td>Best phone bought to date</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reviews  Labels\n",
       "1163606  Excellent pen!  Actually this is the only pen ...       0\n",
       "2069284  When you have a fresh set of batteries in this...       2\n",
       "338411   These file folder labels are great. I use them...       0\n",
       "37088    work's well  ~ is Not the Heavy Duty All Steel...       2\n",
       "752649                         great quality, great value!       0\n",
       "...                                                    ...     ...\n",
       "2482466  I purchased this pen specifically for outdoor ...       1\n",
       "1504746  We always use Scotch Heavy Duty Tape for packi...       2\n",
       "2599944  I'm on a quest to find a cordless phone with d...       2\n",
       "1751783  Just received my new printer and love the size...       2\n",
       "478502                           Best phone bought to date       0\n",
       "\n",
       "[150000 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terframes = terframes.sample(frac=1)\n",
    "print(terframes.shape)\n",
    "terframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-JSxJzX_srp"
   },
   "source": [
    "# Data Cleaning and Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JNN7LUw_4Eu"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1707179412595,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "1F8FlXjY_Xbp"
   },
   "outputs": [],
   "source": [
    "avg_before_dc_bin = np.mean(binframes['reviews'].apply(lambda x: len(x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1707179412595,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "1F8FlXjY_Xbp"
   },
   "outputs": [],
   "source": [
    "avg_before_dc_ter = np.mean(terframes['reviews'].apply(lambda x: len(x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1707179412595,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "qpSyItEu__AZ"
   },
   "outputs": [],
   "source": [
    "#converting to lower case\n",
    "binframes['reviews'] = binframes['reviews'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1707179412595,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "qpSyItEu__AZ"
   },
   "outputs": [],
   "source": [
    "#converting to lower case\n",
    "terframes['reviews'] = terframes['reviews'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1707179412596,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "BmHOAJ4GAFK-"
   },
   "outputs": [],
   "source": [
    "#removing html\n",
    "\n",
    "def clean_html(review_sent):\n",
    "  review_sent = re.sub(r\"<.*?>+\",\"\", review_sent)\n",
    "  return \" \".join(review_sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1707179412596,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "CRtb2vPVAHvE"
   },
   "outputs": [],
   "source": [
    "#removing url\n",
    "\n",
    "def clean_url(review_sent):\n",
    "  review_sent = re.sub(r\"http[^\\s]+\",\"\", review_sent)\n",
    "  return \" \".join(review_sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1707179412596,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "sxmJsOgzANHl"
   },
   "outputs": [],
   "source": [
    "#fix contractions inspired from geeksforgeeks tutorial\n",
    "\n",
    "def clean_contractions(review_sent):\n",
    "  expanded_words = []\n",
    "  for word in review_sent.split():\n",
    "    expanded_words.append(contractions.fix(word))\n",
    "  return \" \".join(expanded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1707179412596,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "j1CD9NKMAT3f"
   },
   "outputs": [],
   "source": [
    "#fix mentions\n",
    "\n",
    "def clean_mentions(tweet):\n",
    "    tweet = re.sub(r\"@[A-Za-z0-9_]+\",\"\", tweet)\n",
    "    return \" \".join(tweet.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1707179412596,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "pSGXiyYhBAhp",
    "outputId": "d8a3d5f7-2ec2-4339-9321-ccb4aeb5b582"
   },
   "outputs": [],
   "source": [
    "#removing non-alphabetic characters, numbers and extra spaces\n",
    "\n",
    "binframes['reviews'] = binframes['reviews'].str.replace('\\d+','')\n",
    "terframes['reviews'] = terframes['reviews'].str.replace('\\d+','')\n",
    "\n",
    "non_alphabetic_chars = ['\\\\n','!','\"','(',')','+',',','-','.','/',':',';','<','=','>','?','[','\\\\',']','^','`','{','|','}','~','#','â€œ','â€','â€•','â†’','â†','â„¢','â€™','â€¢','â€˜','Â»','Â«','@','&','$','*','Â¥','%','Ã·']\n",
    "\n",
    "def preprocess_reviews(review_vals, non_alphabetic_chars):\n",
    "    processed_review = review_vals\n",
    "    processed_review = clean_html(processed_review)\n",
    "    processed_review = clean_url(processed_review)\n",
    "    processed_review = clean_contractions(processed_review)\n",
    "    processed_review = clean_mentions(processed_review)\n",
    "    for char_wd in non_alphabetic_chars:\n",
    "      processed_review = processed_review.replace(char_wd,'')\n",
    "    processed_review = processed_review + \" \"\n",
    "    return(\" \".join(processed_review.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 26965,
     "status": "ok",
     "timestamp": 1707179439556,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "k5NYe_-BBpYO",
    "outputId": "65de23eb-448d-427c-8ca9-3606bb7c48c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1921057</th>\n",
       "      <td>this item came in a home made bubble wrap labe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032152</th>\n",
       "      <td>it works i hope it continues working perhaps i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590977</th>\n",
       "      <td>the software that comes with the printer does ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685277</th>\n",
       "      <td>it arrived on time and it came in a huge box i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29865</th>\n",
       "      <td>works as well as canon toner</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234437</th>\n",
       "      <td>the signage faded completely away after only a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203972</th>\n",
       "      <td>product was listed as usable on the mfc870dw i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283458</th>\n",
       "      <td>i cleaned the heads 10 times and there are sti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483295</th>\n",
       "      <td>the highlighters were not new or they were old...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556562</th>\n",
       "      <td>excellent got one for my daughter perfect for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reviews  Labels\n",
       "1921057  this item came in a home made bubble wrap labe...       1\n",
       "2032152  it works i hope it continues working perhaps i...       0\n",
       "2590977  the software that comes with the printer does ...       1\n",
       "1685277  it arrived on time and it came in a huge box i...       0\n",
       "29865                         works as well as canon toner       0\n",
       "...                                                    ...     ...\n",
       "1234437  the signage faded completely away after only a...       1\n",
       "203972   product was listed as usable on the mfc870dw i...       1\n",
       "2283458  i cleaned the heads 10 times and there are sti...       1\n",
       "483295   the highlighters were not new or they were old...       1\n",
       "556562   excellent got one for my daughter perfect for ...       0\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binframes['reviews'] = binframes['reviews'].apply(lambda x: preprocess_reviews(x, non_alphabetic_chars))\n",
    "binframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 26965,
     "status": "ok",
     "timestamp": 1707179439556,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "k5NYe_-BBpYO",
    "outputId": "65de23eb-448d-427c-8ca9-3606bb7c48c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1163606</th>\n",
       "      <td>excellent pen actually this is the only pen i ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069284</th>\n",
       "      <td>when you have a fresh set of batteries in this...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338411</th>\n",
       "      <td>these file folder labels are great i use them ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37088</th>\n",
       "      <td>work's well is not the heavy duty all steel or...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752649</th>\n",
       "      <td>great quality great value</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482466</th>\n",
       "      <td>i purchased this pen specifically for outdoor ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504746</th>\n",
       "      <td>we always use scotch heavy duty tape for packi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599944</th>\n",
       "      <td>i am on a quest to find a cordless phone with ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751783</th>\n",
       "      <td>just received my new printer and love the size...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478502</th>\n",
       "      <td>best phone bought to date</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reviews  Labels\n",
       "1163606  excellent pen actually this is the only pen i ...       0\n",
       "2069284  when you have a fresh set of batteries in this...       2\n",
       "338411   these file folder labels are great i use them ...       0\n",
       "37088    work's well is not the heavy duty all steel or...       2\n",
       "752649                           great quality great value       0\n",
       "...                                                    ...     ...\n",
       "2482466  i purchased this pen specifically for outdoor ...       1\n",
       "1504746  we always use scotch heavy duty tape for packi...       2\n",
       "2599944  i am on a quest to find a cordless phone with ...       2\n",
       "1751783  just received my new printer and love the size...       2\n",
       "478502                           best phone bought to date       0\n",
       "\n",
       "[150000 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terframes['reviews'] = terframes['reviews'].apply(lambda x: preprocess_reviews(x, non_alphabetic_chars))\n",
    "terframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 1041,
     "status": "ok",
     "timestamp": 1707179440594,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "9dcsGO71Bsjy"
   },
   "outputs": [],
   "source": [
    "avg_after_dc_bin = np.mean(binframes['reviews'].apply(lambda x: len(x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 1041,
     "status": "ok",
     "timestamp": 1707179440594,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "9dcsGO71Bsjy"
   },
   "outputs": [],
   "source": [
    "avg_after_dc_ter = np.mean(terframes['reviews'].apply(lambda x: len(x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1707179440595,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "Qwp5b2kAB2g5",
    "outputId": "afd028dd-f92d-4219-e624-164bf09bc05c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of Reviews before and after Data Cleaning for Binary Data: 58.63282 , 58.67989\n",
      "Average length of Reviews before and after Data Cleaning for Ternary Data: 61.25425333333333 , 61.32564\n"
     ]
    }
   ],
   "source": [
    "print('Average length of Reviews before and after Data Cleaning for Binary Data:',avg_before_dc_bin,',',avg_after_dc_bin)\n",
    "print('Average length of Reviews before and after Data Cleaning for Ternary Data:',avg_before_dc_ter,',',avg_after_dc_ter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaDRyvwZFqP4"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2afnrciFxDy"
   },
   "source": [
    "### Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 1052,
     "status": "ok",
     "timestamp": 1707179441644,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "t6SmHwtJB5yW"
   },
   "outputs": [],
   "source": [
    "avg_before_pp_bin = np.mean(binframes['reviews'].apply(lambda x: len(x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 1052,
     "status": "ok",
     "timestamp": 1707179441644,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "t6SmHwtJB5yW"
   },
   "outputs": [],
   "source": [
    "avg_before_pp_ter = np.mean(terframes['reviews'].apply(lambda x: len(x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1707179441645,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "jyUVfdFRF4Wz",
    "outputId": "dfe38c91-8807-4a2f-8dd0-8410f0ad3f8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'you', 'needn', \"haven't\", 'where', \"wasn't\", 'some', \"don't\", 'until', 'were', 'here', 'wouldn', 'm', 'below', 'aren', 'most', 'just', \"you're\", 'him', 'no', 'more', \"doesn't\", \"mustn't\", 'between', 's', 'hers', 'wasn', \"that'll\", 'other', 'its', 'above', 'them', 'such', 'off', 'so', 'after', 'who', 'those', 'from', 'being', 'her', 'as', 'it', 'for', 'any', 'over', 'that', 'did', 'your', 'by', 'further', 'too', 'he', 'have', 'against', 'or', 'through', 'i', 'ain', 'ours', 'my', 'how', 'am', 'of', 'an', 'mightn', 'under', 'll', \"didn't\", 'having', 'ourselves', 'can', 'than', 'y', 'doesn', 'into', 'when', 'hadn', \"hadn't\", 'been', 'don', \"should've\", 'with', 'then', 'same', 'are', 'couldn', 'they', \"couldn't\", 'should', 'mustn', 'doing', 'themselves', 'does', 'weren', 'do', 'own', 'but', 'all', 'ma', 'yours', 'haven', 'again', \"mightn't\", 'up', 'on', 'once', 'was', 'in', \"it's\", \"hasn't\", 'while', \"shouldn't\", 'shan', 'if', 'there', 'won', 'few', \"weren't\", \"you'll\", 'to', 'hasn', 'now', \"needn't\", 've', 'both', 'his', \"won't\", 'herself', \"wouldn't\", 'itself', 'is', 'not', 'because', 'at', 'shouldn', 'she', 'their', 'before', 'me', 'these', 't', 'didn', 'out', \"shan't\", \"isn't\", 'o', 'down', 'what', \"she's\", 're', 'why', \"aren't\", 'very', 'each', 'only', 'myself', 'yourself', 'which', 'this', 'we', 'whom', \"you'd\", 'd', 'has', 'about', \"you've\", 'himself', 'the', 'had', 'during', 'our', 'and', 'a', 'will', 'theirs', 'yourselves', 'be', 'isn', 'nor'}\n"
     ]
    }
   ],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "print(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1707179441645,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "5vU6TrFWGIY6"
   },
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "\n",
    "def clean_stopwords(review_sent):\n",
    "  filtered_sentence = []\n",
    "  for w in review_sent.split():\n",
    "    if w not in stops:\n",
    "        filtered_sentence.append(w)\n",
    "  return \" \".join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 1973,
     "status": "ok",
     "timestamp": 1707179443616,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "u6TULioPGLCu",
    "outputId": "58392791-018e-4230-b61d-86ff2d5b4624"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1921057</th>\n",
       "      <td>item came home made bubble wrap labeled new ou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032152</th>\n",
       "      <td>works hope continues working perhaps get disco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590977</th>\n",
       "      <td>software comes printer support newer versions ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685277</th>\n",
       "      <td>arrived time came huge box expecting big pictu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29865</th>\n",
       "      <td>works well canon toner</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234437</th>\n",
       "      <td>signage faded completely away couple weeks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203972</th>\n",
       "      <td>product listed usable mfc870dw bought time bou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283458</th>\n",
       "      <td>cleaned heads 10 times still gaps printing goi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483295</th>\n",
       "      <td>highlighters new old dried good buy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556562</th>\n",
       "      <td>excellent got one daughter perfect pill bottles</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reviews  Labels\n",
       "1921057  item came home made bubble wrap labeled new ou...       1\n",
       "2032152  works hope continues working perhaps get disco...       0\n",
       "2590977  software comes printer support newer versions ...       1\n",
       "1685277  arrived time came huge box expecting big pictu...       0\n",
       "29865                               works well canon toner       0\n",
       "...                                                    ...     ...\n",
       "1234437         signage faded completely away couple weeks       1\n",
       "203972   product listed usable mfc870dw bought time bou...       1\n",
       "2283458  cleaned heads 10 times still gaps printing goi...       1\n",
       "483295                 highlighters new old dried good buy       1\n",
       "556562     excellent got one daughter perfect pill bottles       0\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binframes['reviews'] = binframes['reviews'].apply(lambda x: clean_stopwords(x))\n",
    "binframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 1973,
     "status": "ok",
     "timestamp": 1707179443616,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "u6TULioPGLCu",
    "outputId": "58392791-018e-4230-b61d-86ff2d5b4624"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1163606</th>\n",
       "      <td>excellent pen actually pen like use write anyt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069284</th>\n",
       "      <td>fresh set batteries nice strong beam unfortuna...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338411</th>\n",
       "      <td>file folder labels great use folders</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37088</th>\n",
       "      <td>work's well heavy duty steel original stapler ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752649</th>\n",
       "      <td>great quality great value</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482466</th>\n",
       "      <td>purchased pen specifically outdoor use package...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504746</th>\n",
       "      <td>always use scotch heavy duty tape packing supe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599944</th>\n",
       "      <td>quest find cordless phone decent features exce...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751783</th>\n",
       "      <td>received new printer love size functions probl...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478502</th>\n",
       "      <td>best phone bought date</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reviews  Labels\n",
       "1163606  excellent pen actually pen like use write anyt...       0\n",
       "2069284  fresh set batteries nice strong beam unfortuna...       2\n",
       "338411                file folder labels great use folders       0\n",
       "37088    work's well heavy duty steel original stapler ...       2\n",
       "752649                           great quality great value       0\n",
       "...                                                    ...     ...\n",
       "2482466  purchased pen specifically outdoor use package...       1\n",
       "1504746  always use scotch heavy duty tape packing supe...       2\n",
       "2599944  quest find cordless phone decent features exce...       2\n",
       "1751783  received new printer love size functions probl...       2\n",
       "478502                              best phone bought date       0\n",
       "\n",
       "[150000 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terframes['reviews'] = terframes['reviews'].apply(lambda x: clean_stopwords(x))\n",
    "terframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Padkw_pdGQ97"
   },
   "source": [
    "### Perform Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1707179443616,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "EdIOJynTGNY5"
   },
   "outputs": [],
   "source": [
    "def lets_lemmatize(review_sent):\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  lemmatized_sentence = []\n",
    "  for word in nltk.word_tokenize(review_sent):\n",
    "    word =lemmatizer.lemmatize(word)\n",
    "    lemmatized_sentence.append(word)\n",
    "  return \" \".join(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 51970,
     "status": "ok",
     "timestamp": 1707179495582,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "3mJ_GRGZGe_A",
    "outputId": "cb707442-103f-493c-b78e-a435f7fd3a7c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1921057</th>\n",
       "      <td>item came home made bubble wrap labeled new ou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032152</th>\n",
       "      <td>work hope continues working perhaps get discou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590977</th>\n",
       "      <td>software come printer support newer version ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685277</th>\n",
       "      <td>arrived time came huge box expecting big pictu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29865</th>\n",
       "      <td>work well canon toner</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234437</th>\n",
       "      <td>signage faded completely away couple week</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203972</th>\n",
       "      <td>product listed usable mfc870dw bought time bou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283458</th>\n",
       "      <td>cleaned head 10 time still gap printing going ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483295</th>\n",
       "      <td>highlighter new old dried good buy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556562</th>\n",
       "      <td>excellent got one daughter perfect pill bottle</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reviews  Labels\n",
       "1921057  item came home made bubble wrap labeled new ou...       1\n",
       "2032152  work hope continues working perhaps get discou...       0\n",
       "2590977  software come printer support newer version ma...       1\n",
       "1685277  arrived time came huge box expecting big pictu...       0\n",
       "29865                                work well canon toner       0\n",
       "...                                                    ...     ...\n",
       "1234437          signage faded completely away couple week       1\n",
       "203972   product listed usable mfc870dw bought time bou...       1\n",
       "2283458  cleaned head 10 time still gap printing going ...       1\n",
       "483295                  highlighter new old dried good buy       1\n",
       "556562      excellent got one daughter perfect pill bottle       0\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binframes['reviews'] = binframes['reviews'].apply(lambda x: lets_lemmatize(x))\n",
    "binframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 51970,
     "status": "ok",
     "timestamp": 1707179495582,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "3mJ_GRGZGe_A",
    "outputId": "cb707442-103f-493c-b78e-a435f7fd3a7c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1163606</th>\n",
       "      <td>excellent pen actually pen like use write anyt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069284</th>\n",
       "      <td>fresh set battery nice strong beam unfortunate...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338411</th>\n",
       "      <td>file folder label great use folder</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37088</th>\n",
       "      <td>work 's well heavy duty steel original stapler...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752649</th>\n",
       "      <td>great quality great value</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482466</th>\n",
       "      <td>purchased pen specifically outdoor use package...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504746</th>\n",
       "      <td>always use scotch heavy duty tape packing supe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599944</th>\n",
       "      <td>quest find cordless phone decent feature excel...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751783</th>\n",
       "      <td>received new printer love size function proble...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478502</th>\n",
       "      <td>best phone bought date</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reviews  Labels\n",
       "1163606  excellent pen actually pen like use write anyt...       0\n",
       "2069284  fresh set battery nice strong beam unfortunate...       2\n",
       "338411                  file folder label great use folder       0\n",
       "37088    work 's well heavy duty steel original stapler...       2\n",
       "752649                           great quality great value       0\n",
       "...                                                    ...     ...\n",
       "2482466  purchased pen specifically outdoor use package...       1\n",
       "1504746  always use scotch heavy duty tape packing supe...       2\n",
       "2599944  quest find cordless phone decent feature excel...       2\n",
       "1751783  received new printer love size function proble...       2\n",
       "478502                              best phone bought date       0\n",
       "\n",
       "[150000 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terframes['reviews'] = terframes['reviews'].apply(lambda x: lets_lemmatize(x))\n",
    "terframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1707179495817,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "6GtZ1G0JGhmY",
    "outputId": "a3c09395-18c9-4ecf-d0b0-79c8b3f1dbfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of Reviews before and after Pre-Processing: 58.67989 , 29.20605\n",
      "Average length of Reviews before and after Pre-Processing: 61.32564 , 30.324166666666667\n"
     ]
    }
   ],
   "source": [
    "avg_after_pp_bin = np.mean(binframes['reviews'].apply(lambda x: len(x.split())))\n",
    "avg_after_pp_ter = np.mean(terframes['reviews'].apply(lambda x: len(x.split())))\n",
    "print('Average length of Reviews before and after Pre-Processing:',avg_before_pp_bin,',',avg_after_pp_bin)\n",
    "print('Average length of Reviews before and after Pre-Processing:',avg_before_pp_ter,',',avg_after_pp_ter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZDK7rrvcIO9"
   },
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8aNjUGCHcMvD"
   },
   "source": [
    "## Word2Vec using Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/namyashah/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 703607,
     "status": "ok",
     "timestamp": 1707180199421,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "k2i0w_W9LdIF",
    "outputId": "4ef6482d-040c-4725-bfc4-853b4f6246d5"
   },
   "outputs": [],
   "source": [
    "#importing gensim and pre-trained word2vec model\n",
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "with tempfile.NamedTemporaryFile(prefix='gensim-model-', delete=False) as tmp:\n",
    "    temporary_filepath = tmp.name\n",
    "    wv.save(temporary_filepath)\n",
    "    #\n",
    "    # The model is now safely stored in the filepath.\n",
    "    # You can copy it to other machines, share it with others, etc.\n",
    "    #\n",
    "    # To load a saved model:\n",
    "    #\n",
    "    new_model = KeyedVectors.load(temporary_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1707180199421,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "Fjd12sDIrJUR"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1707180199421,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "GOj7f2P0sAh3",
    "outputId": "f42d2d17-83aa-453d-9d23-8349fbd38f1a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Labels</th>\n",
       "      <th>MyReviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1921057</th>\n",
       "      <td>item came home made bubble wrap labeled new ou...</td>\n",
       "      <td>1</td>\n",
       "      <td>[item, came, home, made, bubble, wrap, labeled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032152</th>\n",
       "      <td>work hope continues working perhaps get discou...</td>\n",
       "      <td>0</td>\n",
       "      <td>[work, hope, continues, working, perhaps, get,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590977</th>\n",
       "      <td>software come printer support newer version ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>[software, come, printer, support, newer, vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685277</th>\n",
       "      <td>arrived time came huge box expecting big pictu...</td>\n",
       "      <td>0</td>\n",
       "      <td>[arrived, time, came, huge, box, expecting, bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29865</th>\n",
       "      <td>work well canon toner</td>\n",
       "      <td>0</td>\n",
       "      <td>[work, well, canon, toner]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reviews  Labels  \\\n",
       "1921057  item came home made bubble wrap labeled new ou...       1   \n",
       "2032152  work hope continues working perhaps get discou...       0   \n",
       "2590977  software come printer support newer version ma...       1   \n",
       "1685277  arrived time came huge box expecting big pictu...       0   \n",
       "29865                                work well canon toner       0   \n",
       "\n",
       "                                                 MyReviews  \n",
       "1921057  [item, came, home, made, bubble, wrap, labeled...  \n",
       "2032152  [work, hope, continues, working, perhaps, get,...  \n",
       "2590977  [software, come, printer, support, newer, vers...  \n",
       "1685277  [arrived, time, came, huge, box, expecting, bi...  \n",
       "29865                           [work, well, canon, toner]  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenizing the reviews into words\n",
    "binframes['MyReviews'] = [word_tokenize(t) for t in binframes['reviews']]\n",
    "binframes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Word Embeddings from the Pre-trained Model\n",
    "\n",
    "def embeddingFun(sent):\n",
    "    vectorsize = wv.vector_size\n",
    "    PT_Embeddings = np.zeros(vectorsize)\n",
    "    c=1\n",
    "    \n",
    "    for word in sent:\n",
    "        if word in wv:\n",
    "            c+=1\n",
    "            PT_Embeddings+=wv[word]\n",
    "    avg = PT_Embeddings/c\n",
    "    return avg\n",
    "        \n",
    "binframes['gvectors']=binframes['MyReviews'].apply(embeddingFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "CgPDErGtn9jf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7118192911148071)]\n"
     ]
    }
   ],
   "source": [
    "#Example 1 to check semantic similarities of the generated vectors\n",
    "print(wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1707176839764,
     "user": {
      "displayName": "Namya Hemal Shah",
      "userId": "15397931779291644464"
     },
     "user_tz": 480
    },
    "id": "DIKDgqE8oWNM",
    "outputId": "4ed50800-4759-42ba-cb3e-db53f0ecb6ad",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity score between excellent and outstanding is: 0.5567486\n"
     ]
    }
   ],
   "source": [
    "#Example 2 to check semantic similarities of the generated vectors\n",
    "print('The similarity score between excellent and outstanding is:', wv.similarity('excellent','outstanding'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This process took 85.48 seconds.\n"
     ]
    }
   ],
   "source": [
    "#making and saving our custom Word2Vec Model\n",
    "start = time.time()\n",
    "model = Word2Vec(sentences=binframes['MyReviews'], vector_size=300, window=11, min_count=10, workers=cores-1, sg=1, hs=1)\n",
    "end = round(time.time()-start,2)\n",
    "print(\"This process took\",end,\"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus_iterable = MyReviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.build_vocab(corpus_iterable=corpus_iterable, keep_raw_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train(corpus_iterable=corpus_iterable, total_examples=model.corpus_count, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store just the words + their trained embeddings.\n",
    "word_vectors = model.wv\n",
    "word_vectors.save(\"word2vec.wordvectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load back with memory-mapping = read-only, shared across processes.\n",
    "wv2 = KeyedVectors.load(\"word2vec.wordvectors\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Word Embeddings from the Custom trained Model\n",
    "\n",
    "def embeddingFun2(sent):\n",
    "    vectorsize = wv2.vector_size\n",
    "    CM_Embeddings = np.zeros(vectorsize)\n",
    "    c=1\n",
    "    \n",
    "    for word in sent:\n",
    "        if word in wv2:\n",
    "            c+=1\n",
    "            PT_Embeddings+=wv[word]\n",
    "    avg = CM_Embeddings/c\n",
    "    return avg\n",
    "        \n",
    "binframes['cvectors']=binframes['MyReviews'].apply(embeddingFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('romney', 0.3914776146411896), ('men', 0.381064236164093), ('mitt', 0.3443523347377777), ('darling', 0.3400265872478485), ('manly', 0.33894944190979004)]\n"
     ]
    }
   ],
   "source": [
    "#Example 1 to check semantic similarities of the generated vectors\n",
    "print(model.wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity score between excellent and outstanding is: 0.52947176\n"
     ]
    }
   ],
   "source": [
    "#Example 2 to check semantic similarities of the generated vectors\n",
    "print('The similarity score between excellent and outstanding is:', model.wv.similarity('excellent','outstanding'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do you conclude from comparing vectors generated by yourself and the pretrained model?\n",
    "\n",
    "A. The vectors generated by the pre-trained model gives more accurate similar words and has a better similarity score compare to the custom model I created. This can mean that pre-trained model has a huge training set and hence it might have more context to say that King and Queen are semantically similar with the only difference of Man and Woman, while our pre-trained model is not as rich to understand that context. This also means that the word embeddings in the custom model is centric to the context of data we provied to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which of the Word2Vec models seems to encode semantic similarities between words better?\n",
    "\n",
    "A. The Pre-trained Gensim Word2Vec Model seems to encode semantic similarities between words better than the Custom model I created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Models for Pre-trained Word2Vec, Custom Word2Vec and TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Table = [['TFIDF','Percepton','Binary'],['TFIDF','SVM','Binary'],['Avg Pre-trained W2V','Percepton','Binary'],['Avg Pre-trained W2V','SVM','Binary'],['Avg Custom W2V','Percepton','Binary'],['Avg Custom W2V','SVM','Binary'],['Avg Pre-trained W2V','FNN','Binary'],['Avg Custom W2V','FNN','Binary'],['Con Pre-trained W2V','FNN','Binary'],['Con Custom W2V','FNN','Binary'],['Avg Pre-trained W2V','FNN','Ternary'],['Avg Custom W2V','FNN','Ternary'],['Con Pre-trained W2V','FNN','Ternary'],['Con Custom W2V','FNN','Ternary'],['Avg Pre-trained W2V','CNN','Binary'],['Avg Custom W2V','CNN','Binary'],['Avg Pre-trained W2V','CNN','Ternary'],['Avg Custom W2V','CNN','Ternary']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Models for TF-IDF Feature Extraxtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_feature_extracter = TfidfVectorizer()\n",
    "Rev_tfidf = tf_idf_feature_extracter.fit_transform(binframes['reviews'])\n",
    "#print(Rev_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 80-20 train-test\n",
    "x_train, x_test, y_train, y_test = train_test_split(Rev_tfidf, binframes['Labels'], test_size=0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percepton Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Perceptron<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.Perceptron.html\">?<span>Documentation for Perceptron</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Perceptron()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_model_tfidf = Perceptron()\n",
    "perceptron_model_tfidf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_perceptron_test = perceptron_model_tfidf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Test Metrics: Accuracy =  0.84775\n"
     ]
    }
   ],
   "source": [
    "accuracy_test_perceptron = accuracy_score(y_test, y_pred_perceptron_test)\n",
    "print('Perceptron Test Metrics: Accuracy = ', accuracy_test_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Table[0].append(accuracy_test_perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/namyashah/Library/Python/3.9/lib/python/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearSVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.LinearSVC.html\">?<span>Documentation for LinearSVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearSVC()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model_tfidf = LinearSVC()\n",
    "svm_model_tfidf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_test = svm_model_tfidf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Test Metrics: Accuracy =  0.88845\n"
     ]
    }
   ],
   "source": [
    "accuracy_test_svm = accuracy_score(y_test, y_pred_svm_test)\n",
    "print('SVM Test Metrics: Accuracy = ', accuracy_test_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Table[1].append(accuracy_test_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Models for Pre-trained Word2Vec Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 80-20 train-test\n",
    "x_train, x_test, y_train, y_test = train_test_split(binframes['gvectors'], binframes['Labels'], test_size=0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percepton Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Perceptron<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.Perceptron.html\">?<span>Documentation for Perceptron</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Perceptron()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_model = Perceptron()\n",
    "perceptron_model.fit(x_train.to_list(), y_train.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_perceptron_test = perceptron_model.predict(x_test.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Test Metrics: Accuracy =  0.7971\n"
     ]
    }
   ],
   "source": [
    "accuracy_test_perceptron = accuracy_score(y_test, y_pred_perceptron_test)\n",
    "print('Perceptron Test Metrics: Accuracy = ', accuracy_test_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Table[2].append(accuracy_test_perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/namyashah/Library/Python/3.9/lib/python/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearSVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.LinearSVC.html\">?<span>Documentation for LinearSVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearSVC()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model_tfidf = LinearSVC()\n",
    "svm_model_tfidf.fit(x_train.to_list(), y_train.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_test = svm_model_tfidf.predict(x_test.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Test Metrics: Accuracy =  0.8487\n"
     ]
    }
   ],
   "source": [
    "accuracy_test_svm = accuracy_score(y_test, y_pred_svm_test)\n",
    "print('SVM Test Metrics: Accuracy = ', accuracy_test_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Table[3].append(accuracy_test_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Models for Custom Word2Vec Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 80-20 train-test\n",
    "x_train, x_test, y_train, y_test = train_test_split(binframes['cvectors'], binframes['Labels'], test_size=0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percepton Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Perceptron<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.Perceptron.html\">?<span>Documentation for Perceptron</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Perceptron()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_model = Perceptron()\n",
    "perceptron_model.fit(x_train.to_list(), y_train.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_perceptron_test = perceptron_model.predict(x_test.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Train Metrics: Accuracy =  0.7971\n"
     ]
    }
   ],
   "source": [
    "accuracy_test_perceptron = accuracy_score(y_test, y_pred_perceptron_test)\n",
    "print('Perceptron Train Metrics: Accuracy = ', accuracy_test_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Table[4].append(accuracy_test_perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/namyashah/Library/Python/3.9/lib/python/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearSVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.LinearSVC.html\">?<span>Documentation for LinearSVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearSVC()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model_tfidf = LinearSVC()\n",
    "svm_model_tfidf.fit(x_train.to_list(), y_train.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_test = svm_model_tfidf.predict(x_test.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Test Metrics: Accuracy =  0.8487\n"
     ]
    }
   ],
   "source": [
    "accuracy_test_svm = accuracy_score(y_test, y_pred_svm_test)\n",
    "print('SVM Test Metrics: Accuracy = ', accuracy_test_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Table[5].append(accuracy_test_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do you conclude from comparing performances for the models trained using the three different feature types (TF-IDF, pretrained Word2Vec, your trained Word2Vec)?\n",
    "\n",
    "A. From the results, it is apparent that the TF-IDF feature extraction gives better accuracy score compares to the Pre-trained Gensim Word2vec and my custom Word2Vec feature extracter. This could mean that TF-IDF features fit better with the SVM and Percepton model in comparison to the features from the other two models. This could also mean that TF-IDF is better at extracting features from this specific reviews dataset in comparison to the other two. It is also observed that SVM model gives a better accuracy score than the Percepton model, which can suggest that the SVM model does the job of classification for this specific reviews dataset better than the Percepton model. All this being said, one thing to be kept in mind is that these performances can have varied answers if we change parameters such as sample size of the data set, hyperparameter in the custom Word2Vec model or change the dataset in itself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FNN for Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Features extracted from Pre-trained Avg Word2Vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the Feedforward Neural Network is used for the Binary Classification, where the feature extracter is the Pre-trained Gensim Word2Vec model and the vector for a review are the average of the vectors for each word in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 80-20 train-test\n",
    "x_train, x_test, y_train, y_test = train_test_split(binframes['gvectors'], binframes['Labels'], test_size=0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting NumPy arrays to TensorFlow tensors\n",
    "X_train_tf = tf.convert_to_tensor(x_train.to_list(), dtype=tf.float32)\n",
    "y_train_tf = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "X_test_tf = tf.convert_to_tensor(x_test.to_list(), dtype=tf.float32)\n",
    "y_test_tf = tf.convert_to_tensor(y_test, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network_1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation='relu', input_shape=(300,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the neural network\n",
    "neural_network_1.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2500/2500 [==============================] - 1s 432us/step - loss: 0.3755 - accuracy: 0.8339\n",
      "Epoch 2/100\n",
      "2500/2500 [==============================] - 1s 423us/step - loss: 0.3382 - accuracy: 0.8534\n",
      "Epoch 3/100\n",
      "2500/2500 [==============================] - 1s 457us/step - loss: 0.3253 - accuracy: 0.8598\n",
      "Epoch 4/100\n",
      "2500/2500 [==============================] - 1s 439us/step - loss: 0.3162 - accuracy: 0.8642\n",
      "Epoch 5/100\n",
      "2500/2500 [==============================] - 1s 452us/step - loss: 0.3078 - accuracy: 0.8687\n",
      "Epoch 6/100\n",
      "2500/2500 [==============================] - 1s 417us/step - loss: 0.3005 - accuracy: 0.8723\n",
      "Epoch 7/100\n",
      "2500/2500 [==============================] - 1s 411us/step - loss: 0.2947 - accuracy: 0.8751\n",
      "Epoch 8/100\n",
      "2500/2500 [==============================] - 1s 409us/step - loss: 0.2884 - accuracy: 0.8778\n",
      "Epoch 9/100\n",
      "2500/2500 [==============================] - 1s 409us/step - loss: 0.2835 - accuracy: 0.8800\n",
      "Epoch 10/100\n",
      "2500/2500 [==============================] - 1s 410us/step - loss: 0.2783 - accuracy: 0.8823\n",
      "Epoch 11/100\n",
      "2500/2500 [==============================] - 1s 410us/step - loss: 0.2739 - accuracy: 0.8848\n",
      "Epoch 12/100\n",
      "2500/2500 [==============================] - 1s 411us/step - loss: 0.2691 - accuracy: 0.8873\n",
      "Epoch 13/100\n",
      "2500/2500 [==============================] - 1s 416us/step - loss: 0.2656 - accuracy: 0.8884\n",
      "Epoch 14/100\n",
      "2500/2500 [==============================] - 1s 439us/step - loss: 0.2617 - accuracy: 0.8916\n",
      "Epoch 15/100\n",
      "2500/2500 [==============================] - 1s 423us/step - loss: 0.2584 - accuracy: 0.8926\n",
      "Epoch 16/100\n",
      "2500/2500 [==============================] - 1s 447us/step - loss: 0.2545 - accuracy: 0.8943\n",
      "Epoch 17/100\n",
      "2500/2500 [==============================] - 1s 447us/step - loss: 0.2509 - accuracy: 0.8964\n",
      "Epoch 18/100\n",
      "2500/2500 [==============================] - 1s 434us/step - loss: 0.2489 - accuracy: 0.8975\n",
      "Epoch 19/100\n",
      "2500/2500 [==============================] - 1s 426us/step - loss: 0.2453 - accuracy: 0.8987\n",
      "Epoch 20/100\n",
      "2500/2500 [==============================] - 1s 433us/step - loss: 0.2425 - accuracy: 0.9004\n",
      "Epoch 21/100\n",
      "2500/2500 [==============================] - 1s 415us/step - loss: 0.2402 - accuracy: 0.9005\n",
      "Epoch 22/100\n",
      "2500/2500 [==============================] - 1s 413us/step - loss: 0.2371 - accuracy: 0.9025\n",
      "Epoch 23/100\n",
      "2500/2500 [==============================] - 1s 411us/step - loss: 0.2336 - accuracy: 0.9046\n",
      "Epoch 24/100\n",
      "2500/2500 [==============================] - 1s 409us/step - loss: 0.2320 - accuracy: 0.9048\n",
      "Epoch 25/100\n",
      "2500/2500 [==============================] - 1s 414us/step - loss: 0.2294 - accuracy: 0.9066\n",
      "Epoch 26/100\n",
      "2500/2500 [==============================] - 1s 408us/step - loss: 0.2272 - accuracy: 0.9073\n",
      "Epoch 27/100\n",
      "2500/2500 [==============================] - 1s 407us/step - loss: 0.2244 - accuracy: 0.9076\n",
      "Epoch 28/100\n",
      "2500/2500 [==============================] - 1s 406us/step - loss: 0.2227 - accuracy: 0.9093\n",
      "Epoch 29/100\n",
      "2500/2500 [==============================] - 1s 436us/step - loss: 0.2203 - accuracy: 0.9105\n",
      "Epoch 30/100\n",
      "2500/2500 [==============================] - 1s 407us/step - loss: 0.2177 - accuracy: 0.9109\n",
      "Epoch 31/100\n",
      "2500/2500 [==============================] - 1s 407us/step - loss: 0.2162 - accuracy: 0.9127\n",
      "Epoch 32/100\n",
      "2500/2500 [==============================] - 1s 406us/step - loss: 0.2147 - accuracy: 0.9128\n",
      "Epoch 33/100\n",
      "2500/2500 [==============================] - 1s 407us/step - loss: 0.2126 - accuracy: 0.9134\n",
      "Epoch 34/100\n",
      "2500/2500 [==============================] - 1s 408us/step - loss: 0.2105 - accuracy: 0.9153\n",
      "Epoch 35/100\n",
      "2500/2500 [==============================] - 1s 407us/step - loss: 0.2088 - accuracy: 0.9144\n",
      "Epoch 36/100\n",
      "2500/2500 [==============================] - 1s 407us/step - loss: 0.2070 - accuracy: 0.9162\n",
      "Epoch 37/100\n",
      "2500/2500 [==============================] - 1s 433us/step - loss: 0.2051 - accuracy: 0.9166\n",
      "Epoch 38/100\n",
      "2500/2500 [==============================] - 1s 432us/step - loss: 0.2029 - accuracy: 0.9175\n",
      "Epoch 39/100\n",
      "2500/2500 [==============================] - 1s 407us/step - loss: 0.2022 - accuracy: 0.9176\n",
      "Epoch 40/100\n",
      "2500/2500 [==============================] - 1s 407us/step - loss: 0.1999 - accuracy: 0.9195\n",
      "Epoch 41/100\n",
      "2500/2500 [==============================] - 1s 408us/step - loss: 0.1984 - accuracy: 0.9195\n",
      "Epoch 42/100\n",
      "2500/2500 [==============================] - 1s 407us/step - loss: 0.1973 - accuracy: 0.9204\n",
      "Epoch 43/100\n",
      "2500/2500 [==============================] - 1s 409us/step - loss: 0.1947 - accuracy: 0.9208\n",
      "Epoch 44/100\n",
      "2500/2500 [==============================] - 1s 407us/step - loss: 0.1940 - accuracy: 0.9222\n",
      "Epoch 45/100\n",
      "2500/2500 [==============================] - 1s 432us/step - loss: 0.1928 - accuracy: 0.9216\n",
      "Epoch 46/100\n",
      "2500/2500 [==============================] - 1s 407us/step - loss: 0.1909 - accuracy: 0.9233\n",
      "Epoch 47/100\n",
      "2500/2500 [==============================] - 1s 407us/step - loss: 0.1904 - accuracy: 0.9224\n",
      "Epoch 48/100\n",
      "2500/2500 [==============================] - 1s 408us/step - loss: 0.1875 - accuracy: 0.9244\n",
      "Epoch 49/100\n",
      "2500/2500 [==============================] - 1s 408us/step - loss: 0.1862 - accuracy: 0.9256\n",
      "Epoch 50/100\n",
      "2500/2500 [==============================] - 1s 406us/step - loss: 0.1855 - accuracy: 0.9255\n",
      "Epoch 51/100\n",
      "2500/2500 [==============================] - 1s 405us/step - loss: 0.1832 - accuracy: 0.9261\n",
      "Epoch 52/100\n",
      "2500/2500 [==============================] - 1s 436us/step - loss: 0.1829 - accuracy: 0.9259\n",
      "Epoch 53/100\n",
      "2500/2500 [==============================] - 1s 411us/step - loss: 0.1812 - accuracy: 0.9270\n",
      "Epoch 54/100\n",
      "2500/2500 [==============================] - 1s 407us/step - loss: 0.1803 - accuracy: 0.9274\n",
      "Epoch 55/100\n",
      "2500/2500 [==============================] - 1s 413us/step - loss: 0.1785 - accuracy: 0.9280\n",
      "Epoch 56/100\n",
      "2500/2500 [==============================] - 1s 429us/step - loss: 0.1782 - accuracy: 0.9285\n",
      "Epoch 57/100\n",
      "2500/2500 [==============================] - 1s 450us/step - loss: 0.1761 - accuracy: 0.9295\n",
      "Epoch 58/100\n",
      "2500/2500 [==============================] - 1s 419us/step - loss: 0.1755 - accuracy: 0.9291\n",
      "Epoch 59/100\n",
      "2500/2500 [==============================] - 1s 426us/step - loss: 0.1742 - accuracy: 0.9303\n",
      "Epoch 60/100\n",
      "2500/2500 [==============================] - 1s 455us/step - loss: 0.1730 - accuracy: 0.9311\n",
      "Epoch 61/100\n",
      "2500/2500 [==============================] - 1s 456us/step - loss: 0.1728 - accuracy: 0.9307\n",
      "Epoch 62/100\n",
      "2500/2500 [==============================] - 1s 412us/step - loss: 0.1701 - accuracy: 0.9316\n",
      "Epoch 63/100\n",
      "2500/2500 [==============================] - 1s 409us/step - loss: 0.1704 - accuracy: 0.9316\n",
      "Epoch 64/100\n",
      "2500/2500 [==============================] - 1s 463us/step - loss: 0.1686 - accuracy: 0.9331\n",
      "Epoch 65/100\n",
      "2500/2500 [==============================] - 1s 480us/step - loss: 0.1674 - accuracy: 0.9330\n",
      "Epoch 66/100\n",
      "2500/2500 [==============================] - 1s 464us/step - loss: 0.1668 - accuracy: 0.9333\n",
      "Epoch 67/100\n",
      "2500/2500 [==============================] - 1s 470us/step - loss: 0.1657 - accuracy: 0.9337\n",
      "Epoch 68/100\n",
      "2500/2500 [==============================] - 1s 476us/step - loss: 0.1659 - accuracy: 0.9342\n",
      "Epoch 69/100\n",
      "2500/2500 [==============================] - 1s 486us/step - loss: 0.1641 - accuracy: 0.9345\n",
      "Epoch 70/100\n",
      "2500/2500 [==============================] - 1s 470us/step - loss: 0.1626 - accuracy: 0.9361\n",
      "Epoch 71/100\n",
      "2500/2500 [==============================] - 1s 483us/step - loss: 0.1627 - accuracy: 0.9350\n",
      "Epoch 72/100\n",
      "2500/2500 [==============================] - 1s 470us/step - loss: 0.1607 - accuracy: 0.9359\n",
      "Epoch 73/100\n",
      "2500/2500 [==============================] - 1s 413us/step - loss: 0.1603 - accuracy: 0.9363\n",
      "Epoch 74/100\n",
      "2500/2500 [==============================] - 1s 407us/step - loss: 0.1604 - accuracy: 0.9360\n",
      "Epoch 75/100\n",
      "2500/2500 [==============================] - 1s 406us/step - loss: 0.1584 - accuracy: 0.9368\n",
      "Epoch 76/100\n",
      "2500/2500 [==============================] - 1s 404us/step - loss: 0.1577 - accuracy: 0.9377\n",
      "Epoch 77/100\n",
      "2500/2500 [==============================] - 1s 407us/step - loss: 0.1567 - accuracy: 0.9383\n",
      "Epoch 78/100\n",
      "2500/2500 [==============================] - 1s 408us/step - loss: 0.1555 - accuracy: 0.9381\n",
      "Epoch 79/100\n",
      "2500/2500 [==============================] - 1s 432us/step - loss: 0.1556 - accuracy: 0.9379\n",
      "Epoch 80/100\n",
      "2500/2500 [==============================] - 1s 408us/step - loss: 0.1535 - accuracy: 0.9389\n",
      "Epoch 81/100\n",
      "2500/2500 [==============================] - 1s 405us/step - loss: 0.1540 - accuracy: 0.9384\n",
      "Epoch 82/100\n",
      "2500/2500 [==============================] - 1s 409us/step - loss: 0.1522 - accuracy: 0.9399\n",
      "Epoch 83/100\n",
      "2500/2500 [==============================] - 1s 407us/step - loss: 0.1517 - accuracy: 0.9406\n",
      "Epoch 84/100\n",
      "2500/2500 [==============================] - 1s 407us/step - loss: 0.1512 - accuracy: 0.9404\n",
      "Epoch 85/100\n",
      "2500/2500 [==============================] - 1s 406us/step - loss: 0.1494 - accuracy: 0.9415\n",
      "Epoch 86/100\n",
      "2500/2500 [==============================] - 1s 443us/step - loss: 0.1486 - accuracy: 0.9415\n",
      "Epoch 87/100\n",
      "2500/2500 [==============================] - 1s 413us/step - loss: 0.1481 - accuracy: 0.9412\n",
      "Epoch 88/100\n",
      "2500/2500 [==============================] - 1s 406us/step - loss: 0.1479 - accuracy: 0.9418\n",
      "Epoch 89/100\n",
      "2500/2500 [==============================] - 1s 408us/step - loss: 0.1460 - accuracy: 0.9419\n",
      "Epoch 90/100\n",
      "2500/2500 [==============================] - 1s 406us/step - loss: 0.1453 - accuracy: 0.9428\n",
      "Epoch 91/100\n",
      "2500/2500 [==============================] - 1s 408us/step - loss: 0.1449 - accuracy: 0.9420\n",
      "Epoch 92/100\n",
      "2500/2500 [==============================] - 1s 406us/step - loss: 0.1452 - accuracy: 0.9430\n",
      "Epoch 93/100\n",
      "2500/2500 [==============================] - 1s 433us/step - loss: 0.1435 - accuracy: 0.9426\n",
      "Epoch 94/100\n",
      "2500/2500 [==============================] - 1s 405us/step - loss: 0.1421 - accuracy: 0.9437\n",
      "Epoch 95/100\n",
      "2500/2500 [==============================] - 1s 406us/step - loss: 0.1425 - accuracy: 0.9439\n",
      "Epoch 96/100\n",
      "2500/2500 [==============================] - 1s 406us/step - loss: 0.1412 - accuracy: 0.9443\n",
      "Epoch 97/100\n",
      "2500/2500 [==============================] - 1s 408us/step - loss: 0.1402 - accuracy: 0.9449\n",
      "Epoch 98/100\n",
      "2500/2500 [==============================] - 1s 407us/step - loss: 0.1410 - accuracy: 0.9445\n",
      "Epoch 99/100\n",
      "2500/2500 [==============================] - 1s 431us/step - loss: 0.1393 - accuracy: 0.9456\n",
      "Epoch 100/100\n",
      "2500/2500 [==============================] - 1s 407us/step - loss: 0.1397 - accuracy: 0.9451\n"
     ]
    }
   ],
   "source": [
    "# Training the neural network\n",
    "history1 = neural_network_1.fit(X_train_tf, y_train_tf, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 0s 297us/step - loss: 0.5328 - accuracy: 0.8498\n",
      "Test accuracy: 0.8498499989509583\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the neural network on the test set\n",
    "test_loss, test_acc = neural_network_1.evaluate(X_test_tf, y_test_tf)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Table[6].append(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Features extracted from Custom Avg Word2Vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the Feedforward Neural Network is used for the Binary Classification, where the feature extracter is the Custom Word2Vec model and the vector for a review are the average of the vectors for each word in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 80-20 train-test\n",
    "x_train, x_test, y_train, y_test = train_test_split(binframes['cvectors'], binframes['Labels'], test_size=0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting NumPy arrays to TensorFlow tensors\n",
    "X_train_tf = tf.convert_to_tensor(x_train.to_list(), dtype=tf.float32)\n",
    "y_train_tf = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "X_test_tf = tf.convert_to_tensor(x_test.to_list(), dtype=tf.float32)\n",
    "y_test_tf = tf.convert_to_tensor(y_test, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network_2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation='relu', input_shape=(300,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the neural network\n",
    "neural_network_2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  87/2500 [>.............................] - ETA: 1s - loss: 0.6104 - accuracy: 0.7432  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 1s 403us/step - loss: 0.3771 - accuracy: 0.8369\n",
      "Epoch 2/100\n",
      "2500/2500 [==============================] - 1s 393us/step - loss: 0.3375 - accuracy: 0.8539\n",
      "Epoch 3/100\n",
      "2500/2500 [==============================] - 1s 400us/step - loss: 0.3233 - accuracy: 0.8623\n",
      "Epoch 4/100\n",
      "2500/2500 [==============================] - 1s 425us/step - loss: 0.3127 - accuracy: 0.8657\n",
      "Epoch 5/100\n",
      "2500/2500 [==============================] - 1s 415us/step - loss: 0.3048 - accuracy: 0.8703\n",
      "Epoch 6/100\n",
      "2500/2500 [==============================] - 1s 424us/step - loss: 0.2984 - accuracy: 0.8735\n",
      "Epoch 7/100\n",
      "2500/2500 [==============================] - 1s 405us/step - loss: 0.2929 - accuracy: 0.8761\n",
      "Epoch 8/100\n",
      "2500/2500 [==============================] - 1s 466us/step - loss: 0.2866 - accuracy: 0.8794\n",
      "Epoch 9/100\n",
      "2500/2500 [==============================] - 1s 435us/step - loss: 0.2818 - accuracy: 0.8805\n",
      "Epoch 10/100\n",
      "2500/2500 [==============================] - 1s 406us/step - loss: 0.2774 - accuracy: 0.8834\n",
      "Epoch 11/100\n",
      "2500/2500 [==============================] - 1s 411us/step - loss: 0.2720 - accuracy: 0.8852\n",
      "Epoch 12/100\n",
      "2500/2500 [==============================] - 1s 404us/step - loss: 0.2680 - accuracy: 0.8876\n",
      "Epoch 13/100\n",
      "2500/2500 [==============================] - 1s 431us/step - loss: 0.2647 - accuracy: 0.8889\n",
      "Epoch 14/100\n",
      "2500/2500 [==============================] - 1s 404us/step - loss: 0.2606 - accuracy: 0.8910\n",
      "Epoch 15/100\n",
      "2500/2500 [==============================] - 1s 406us/step - loss: 0.2570 - accuracy: 0.8933\n",
      "Epoch 16/100\n",
      "2500/2500 [==============================] - 1s 407us/step - loss: 0.2535 - accuracy: 0.8947\n",
      "Epoch 17/100\n",
      "2500/2500 [==============================] - 1s 402us/step - loss: 0.2504 - accuracy: 0.8965\n",
      "Epoch 18/100\n",
      "2500/2500 [==============================] - 1s 403us/step - loss: 0.2464 - accuracy: 0.8989\n",
      "Epoch 19/100\n",
      "2500/2500 [==============================] - 1s 405us/step - loss: 0.2447 - accuracy: 0.8990\n",
      "Epoch 20/100\n",
      "2500/2500 [==============================] - 1s 402us/step - loss: 0.2418 - accuracy: 0.9002\n",
      "Epoch 21/100\n",
      "2500/2500 [==============================] - 1s 402us/step - loss: 0.2387 - accuracy: 0.9017\n",
      "Epoch 22/100\n",
      "2500/2500 [==============================] - 1s 429us/step - loss: 0.2355 - accuracy: 0.9037\n",
      "Epoch 23/100\n",
      "2500/2500 [==============================] - 1s 405us/step - loss: 0.2339 - accuracy: 0.9045\n",
      "Epoch 24/100\n",
      "2500/2500 [==============================] - 1s 403us/step - loss: 0.2309 - accuracy: 0.9060\n",
      "Epoch 25/100\n",
      "2500/2500 [==============================] - 1s 403us/step - loss: 0.2288 - accuracy: 0.9072\n",
      "Epoch 26/100\n",
      "2500/2500 [==============================] - 1s 400us/step - loss: 0.2254 - accuracy: 0.9086\n",
      "Epoch 27/100\n",
      "2500/2500 [==============================] - 1s 405us/step - loss: 0.2238 - accuracy: 0.9086\n",
      "Epoch 28/100\n",
      "2500/2500 [==============================] - 1s 408us/step - loss: 0.2210 - accuracy: 0.9109\n",
      "Epoch 29/100\n",
      "2500/2500 [==============================] - 1s 403us/step - loss: 0.2197 - accuracy: 0.9103\n",
      "Epoch 30/100\n",
      "2500/2500 [==============================] - 1s 401us/step - loss: 0.2175 - accuracy: 0.9122\n",
      "Epoch 31/100\n",
      "2500/2500 [==============================] - 1s 427us/step - loss: 0.2155 - accuracy: 0.9127\n",
      "Epoch 32/100\n",
      "2500/2500 [==============================] - 1s 402us/step - loss: 0.2134 - accuracy: 0.9136\n",
      "Epoch 33/100\n",
      "2500/2500 [==============================] - 1s 403us/step - loss: 0.2115 - accuracy: 0.9148\n",
      "Epoch 34/100\n",
      "2500/2500 [==============================] - 1s 402us/step - loss: 0.2096 - accuracy: 0.9151\n",
      "Epoch 35/100\n",
      "2500/2500 [==============================] - 1s 404us/step - loss: 0.2091 - accuracy: 0.9151\n",
      "Epoch 36/100\n",
      "2500/2500 [==============================] - 1s 401us/step - loss: 0.2052 - accuracy: 0.9183\n",
      "Epoch 37/100\n",
      "2500/2500 [==============================] - 1s 404us/step - loss: 0.2050 - accuracy: 0.9173\n",
      "Epoch 38/100\n",
      "2500/2500 [==============================] - 1s 401us/step - loss: 0.2027 - accuracy: 0.9194\n",
      "Epoch 39/100\n",
      "2500/2500 [==============================] - 1s 402us/step - loss: 0.2008 - accuracy: 0.9194\n",
      "Epoch 40/100\n",
      "2500/2500 [==============================] - 1s 421us/step - loss: 0.1993 - accuracy: 0.9196\n",
      "Epoch 41/100\n",
      "2500/2500 [==============================] - 1s 404us/step - loss: 0.1984 - accuracy: 0.9207\n",
      "Epoch 42/100\n",
      "2500/2500 [==============================] - 1s 402us/step - loss: 0.1969 - accuracy: 0.9208\n",
      "Epoch 43/100\n",
      "2500/2500 [==============================] - 1s 402us/step - loss: 0.1959 - accuracy: 0.9205\n",
      "Epoch 44/100\n",
      "2500/2500 [==============================] - 1s 402us/step - loss: 0.1945 - accuracy: 0.9222\n",
      "Epoch 45/100\n",
      "2500/2500 [==============================] - 1s 401us/step - loss: 0.1930 - accuracy: 0.9230\n",
      "Epoch 46/100\n",
      "2500/2500 [==============================] - 1s 403us/step - loss: 0.1908 - accuracy: 0.9236\n",
      "Epoch 47/100\n",
      "2500/2500 [==============================] - 1s 403us/step - loss: 0.1890 - accuracy: 0.9246\n",
      "Epoch 48/100\n",
      "2500/2500 [==============================] - 1s 427us/step - loss: 0.1881 - accuracy: 0.9249\n",
      "Epoch 49/100\n",
      "2500/2500 [==============================] - 1s 407us/step - loss: 0.1863 - accuracy: 0.9259\n",
      "Epoch 50/100\n",
      "2500/2500 [==============================] - 1s 433us/step - loss: 0.1858 - accuracy: 0.9255\n",
      "Epoch 51/100\n",
      "2500/2500 [==============================] - 1s 465us/step - loss: 0.1842 - accuracy: 0.9264\n",
      "Epoch 52/100\n",
      "2500/2500 [==============================] - 1s 479us/step - loss: 0.1832 - accuracy: 0.9271\n",
      "Epoch 53/100\n",
      "2500/2500 [==============================] - 1s 507us/step - loss: 0.1817 - accuracy: 0.9280\n",
      "Epoch 54/100\n",
      "2500/2500 [==============================] - 1s 454us/step - loss: 0.1816 - accuracy: 0.9277\n",
      "Epoch 55/100\n",
      "2500/2500 [==============================] - 1s 412us/step - loss: 0.1794 - accuracy: 0.9288\n",
      "Epoch 56/100\n",
      "2500/2500 [==============================] - 1s 428us/step - loss: 0.1776 - accuracy: 0.9291\n",
      "Epoch 57/100\n",
      "2500/2500 [==============================] - 1s 460us/step - loss: 0.1782 - accuracy: 0.9293\n",
      "Epoch 58/100\n",
      "2500/2500 [==============================] - 1s 461us/step - loss: 0.1760 - accuracy: 0.9308\n",
      "Epoch 59/100\n",
      "2500/2500 [==============================] - 1s 419us/step - loss: 0.1749 - accuracy: 0.9313\n",
      "Epoch 60/100\n",
      "2500/2500 [==============================] - 1s 412us/step - loss: 0.1726 - accuracy: 0.9317\n",
      "Epoch 61/100\n",
      "2500/2500 [==============================] - 1s 436us/step - loss: 0.1727 - accuracy: 0.9319\n",
      "Epoch 62/100\n",
      "2500/2500 [==============================] - 1s 419us/step - loss: 0.1722 - accuracy: 0.9317\n",
      "Epoch 63/100\n",
      "2500/2500 [==============================] - 1s 406us/step - loss: 0.1706 - accuracy: 0.9322\n",
      "Epoch 64/100\n",
      "2500/2500 [==============================] - 1s 400us/step - loss: 0.1684 - accuracy: 0.9331\n",
      "Epoch 65/100\n",
      "2500/2500 [==============================] - 1s 396us/step - loss: 0.1689 - accuracy: 0.9335\n",
      "Epoch 66/100\n",
      "2500/2500 [==============================] - 1s 420us/step - loss: 0.1667 - accuracy: 0.9342\n",
      "Epoch 67/100\n",
      "2500/2500 [==============================] - 1s 396us/step - loss: 0.1660 - accuracy: 0.9343\n",
      "Epoch 68/100\n",
      "2500/2500 [==============================] - 1s 394us/step - loss: 0.1639 - accuracy: 0.9355\n",
      "Epoch 69/100\n",
      "2500/2500 [==============================] - 1s 401us/step - loss: 0.1644 - accuracy: 0.9349\n",
      "Epoch 70/100\n",
      "2500/2500 [==============================] - 1s 397us/step - loss: 0.1629 - accuracy: 0.9357\n",
      "Epoch 71/100\n",
      "2500/2500 [==============================] - 1s 401us/step - loss: 0.1625 - accuracy: 0.9359\n",
      "Epoch 72/100\n",
      "2500/2500 [==============================] - 1s 404us/step - loss: 0.1621 - accuracy: 0.9361\n",
      "Epoch 73/100\n",
      "2500/2500 [==============================] - 1s 423us/step - loss: 0.1605 - accuracy: 0.9371\n",
      "Epoch 74/100\n",
      "2500/2500 [==============================] - 1s 398us/step - loss: 0.1591 - accuracy: 0.9369\n",
      "Epoch 75/100\n",
      "2500/2500 [==============================] - 1s 400us/step - loss: 0.1589 - accuracy: 0.9373\n",
      "Epoch 76/100\n",
      "2500/2500 [==============================] - 1s 394us/step - loss: 0.1581 - accuracy: 0.9376\n",
      "Epoch 77/100\n",
      "2500/2500 [==============================] - 1s 398us/step - loss: 0.1577 - accuracy: 0.9380\n",
      "Epoch 78/100\n",
      "2500/2500 [==============================] - 1s 419us/step - loss: 0.1557 - accuracy: 0.9393\n",
      "Epoch 79/100\n",
      "2500/2500 [==============================] - 1s 398us/step - loss: 0.1548 - accuracy: 0.9382\n",
      "Epoch 80/100\n",
      "2500/2500 [==============================] - 1s 396us/step - loss: 0.1548 - accuracy: 0.9390\n",
      "Epoch 81/100\n",
      "2500/2500 [==============================] - 1s 403us/step - loss: 0.1530 - accuracy: 0.9397\n",
      "Epoch 82/100\n",
      "2500/2500 [==============================] - 1s 430us/step - loss: 0.1537 - accuracy: 0.9397\n",
      "Epoch 83/100\n",
      "2500/2500 [==============================] - 1s 403us/step - loss: 0.1520 - accuracy: 0.9398\n",
      "Epoch 84/100\n",
      "2500/2500 [==============================] - 1s 398us/step - loss: 0.1509 - accuracy: 0.9405\n",
      "Epoch 85/100\n",
      "2500/2500 [==============================] - 1s 400us/step - loss: 0.1509 - accuracy: 0.9412\n",
      "Epoch 86/100\n",
      "2500/2500 [==============================] - 1s 436us/step - loss: 0.1497 - accuracy: 0.9413\n",
      "Epoch 87/100\n",
      "2500/2500 [==============================] - 1s 399us/step - loss: 0.1485 - accuracy: 0.9423\n",
      "Epoch 88/100\n",
      "2500/2500 [==============================] - 1s 432us/step - loss: 0.1488 - accuracy: 0.9422\n",
      "Epoch 89/100\n",
      "2500/2500 [==============================] - 1s 412us/step - loss: 0.1476 - accuracy: 0.9418\n",
      "Epoch 90/100\n",
      "2500/2500 [==============================] - 1s 395us/step - loss: 0.1474 - accuracy: 0.9424\n",
      "Epoch 91/100\n",
      "2500/2500 [==============================] - 1s 417us/step - loss: 0.1452 - accuracy: 0.9439\n",
      "Epoch 92/100\n",
      "2500/2500 [==============================] - 1s 449us/step - loss: 0.1460 - accuracy: 0.9428\n",
      "Epoch 93/100\n",
      "2500/2500 [==============================] - 1s 406us/step - loss: 0.1447 - accuracy: 0.9433\n",
      "Epoch 94/100\n",
      "2500/2500 [==============================] - 1s 405us/step - loss: 0.1438 - accuracy: 0.9441\n",
      "Epoch 95/100\n",
      "2500/2500 [==============================] - 1s 419us/step - loss: 0.1436 - accuracy: 0.9438\n",
      "Epoch 96/100\n",
      "2500/2500 [==============================] - 1s 413us/step - loss: 0.1422 - accuracy: 0.9445\n",
      "Epoch 97/100\n",
      "2500/2500 [==============================] - 1s 410us/step - loss: 0.1418 - accuracy: 0.9445\n",
      "Epoch 98/100\n",
      "2500/2500 [==============================] - 1s 453us/step - loss: 0.1406 - accuracy: 0.9451\n",
      "Epoch 99/100\n",
      "2500/2500 [==============================] - 1s 413us/step - loss: 0.1404 - accuracy: 0.9451\n",
      "Epoch 100/100\n",
      "2500/2500 [==============================] - 1s 408us/step - loss: 0.1401 - accuracy: 0.9456\n"
     ]
    }
   ],
   "source": [
    "# Training the neural network\n",
    "history2 = neural_network_2.fit(X_train_tf, y_train_tf, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 0s 300us/step - loss: 0.5405 - accuracy: 0.8510\n",
      "Test accuracy: 0.8510000109672546\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the neural network on the test set\n",
    "test_loss, test_acc = neural_network_2.evaluate(X_test_tf, y_test_tf)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Table[7].append(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pre-trained Word2Vec for Concatenanting Extracted Features in Binary Data Set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are preparing the concatenated vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Labels</th>\n",
       "      <th>MyReviews</th>\n",
       "      <th>gvectors</th>\n",
       "      <th>cvectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1921057</th>\n",
       "      <td>item came home made bubble wrap labeled new ou...</td>\n",
       "      <td>1</td>\n",
       "      <td>[item, came, home, made, bubble, wrap, labeled...</td>\n",
       "      <td>[0.027547836303710938, 0.09846019744873047, 0....</td>\n",
       "      <td>[0.027547836303710938, 0.09846019744873047, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032152</th>\n",
       "      <td>work hope continues working perhaps get discou...</td>\n",
       "      <td>0</td>\n",
       "      <td>[work, hope, continues, working, perhaps, get,...</td>\n",
       "      <td>[0.05845424107142857, 0.016178676060267856, -0...</td>\n",
       "      <td>[0.05845424107142857, 0.016178676060267856, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590977</th>\n",
       "      <td>software come printer support newer version ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>[software, come, printer, support, newer, vers...</td>\n",
       "      <td>[0.06760212912488339, -0.03568415855293843, -0...</td>\n",
       "      <td>[0.06760212912488339, -0.03568415855293843, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685277</th>\n",
       "      <td>arrived time came huge box expecting big pictu...</td>\n",
       "      <td>0</td>\n",
       "      <td>[arrived, time, came, huge, box, expecting, bi...</td>\n",
       "      <td>[0.03836669921875, 0.05717875162760417, -0.008...</td>\n",
       "      <td>[0.03836669921875, 0.05717875162760417, -0.008...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29865</th>\n",
       "      <td>work well canon toner</td>\n",
       "      <td>0</td>\n",
       "      <td>[work, well, canon, toner]</td>\n",
       "      <td>[0.0806640625, 0.07841796875, -0.0003662109375...</td>\n",
       "      <td>[0.0806640625, 0.07841796875, -0.0003662109375...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reviews  Labels  \\\n",
       "1921057  item came home made bubble wrap labeled new ou...       1   \n",
       "2032152  work hope continues working perhaps get discou...       0   \n",
       "2590977  software come printer support newer version ma...       1   \n",
       "1685277  arrived time came huge box expecting big pictu...       0   \n",
       "29865                                work well canon toner       0   \n",
       "\n",
       "                                                 MyReviews  \\\n",
       "1921057  [item, came, home, made, bubble, wrap, labeled...   \n",
       "2032152  [work, hope, continues, working, perhaps, get,...   \n",
       "2590977  [software, come, printer, support, newer, vers...   \n",
       "1685277  [arrived, time, came, huge, box, expecting, bi...   \n",
       "29865                           [work, well, canon, toner]   \n",
       "\n",
       "                                                  gvectors  \\\n",
       "1921057  [0.027547836303710938, 0.09846019744873047, 0....   \n",
       "2032152  [0.05845424107142857, 0.016178676060267856, -0...   \n",
       "2590977  [0.06760212912488339, -0.03568415855293843, -0...   \n",
       "1685277  [0.03836669921875, 0.05717875162760417, -0.008...   \n",
       "29865    [0.0806640625, 0.07841796875, -0.0003662109375...   \n",
       "\n",
       "                                                  cvectors  \n",
       "1921057  [0.027547836303710938, 0.09846019744873047, 0....  \n",
       "2032152  [0.05845424107142857, 0.016178676060267856, -0...  \n",
       "2590977  [0.06760212912488339, -0.03568415855293843, -0...  \n",
       "1685277  [0.03836669921875, 0.05717875162760417, -0.008...  \n",
       "29865    [0.0806640625, 0.07841796875, -0.0003662109375...  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binframes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = KeyedVectors.load(temporary_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The padding function does the job of padding the concatenated vectors in a way that each vector has a fixed length of 10 vectors, each containing 300 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(list_of_lists, pad_value, desired_length, max_num_lists=10):\n",
    "    padded_list = []\n",
    "    \n",
    "    # Iterate over the original list, keeping the original content unchanged\n",
    "    for sublist in list_of_lists[:max_num_lists]:\n",
    "        padded_sublist = sublist[:]  # Create a copy of the sublist\n",
    "        \n",
    "        # Pad or truncate the copied sublist\n",
    "        if len(sublist) < desired_length:\n",
    "            padded_sublist.extend([pad_value] * (desired_length - len(sublist)))\n",
    "        else:\n",
    "            padded_sublist = padded_sublist[:desired_length]  # truncate if longer\n",
    "        \n",
    "        padded_list.append(padded_sublist)\n",
    "    \n",
    "    # Add empty lists if there are fewer than max_num_lists lists\n",
    "    while len(padded_list) < max_num_lists:\n",
    "        padded_list.append([pad_value] * desired_length)\n",
    "    \n",
    "    return padded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Labels</th>\n",
       "      <th>MyReviews</th>\n",
       "      <th>gvectors</th>\n",
       "      <th>cvectors</th>\n",
       "      <th>congvectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1921057</th>\n",
       "      <td>item came home made bubble wrap labeled new ou...</td>\n",
       "      <td>1</td>\n",
       "      <td>[item, came, home, made, bubble, wrap, labeled...</td>\n",
       "      <td>[0.027547836303710938, 0.09846019744873047, 0....</td>\n",
       "      <td>[0.027547836303710938, 0.09846019744873047, 0....</td>\n",
       "      <td>[[0.024291992, 0.010803223, -0.107421875, 0.30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032152</th>\n",
       "      <td>work hope continues working perhaps get discou...</td>\n",
       "      <td>0</td>\n",
       "      <td>[work, hope, continues, working, perhaps, get,...</td>\n",
       "      <td>[0.05845424107142857, 0.016178676060267856, -0...</td>\n",
       "      <td>[0.05845424107142857, 0.016178676060267856, -0...</td>\n",
       "      <td>[[-0.075683594, 0.033691406, -0.064941406, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590977</th>\n",
       "      <td>software come printer support newer version ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>[software, come, printer, support, newer, vers...</td>\n",
       "      <td>[0.06760212912488339, -0.03568415855293843, -0...</td>\n",
       "      <td>[0.06760212912488339, -0.03568415855293843, -0...</td>\n",
       "      <td>[[0.20410156, -0.30078125, -0.013916016, 0.119...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685277</th>\n",
       "      <td>arrived time came huge box expecting big pictu...</td>\n",
       "      <td>0</td>\n",
       "      <td>[arrived, time, came, huge, box, expecting, bi...</td>\n",
       "      <td>[0.03836669921875, 0.05717875162760417, -0.008...</td>\n",
       "      <td>[0.03836669921875, 0.05717875162760417, -0.008...</td>\n",
       "      <td>[[0.15429688, 0.26757812, 0.09326172, -0.15234...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29865</th>\n",
       "      <td>work well canon toner</td>\n",
       "      <td>0</td>\n",
       "      <td>[work, well, canon, toner]</td>\n",
       "      <td>[0.0806640625, 0.07841796875, -0.0003662109375...</td>\n",
       "      <td>[0.0806640625, 0.07841796875, -0.0003662109375...</td>\n",
       "      <td>[[-0.07568359375, 0.03369140625, -0.0649414062...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reviews  Labels  \\\n",
       "1921057  item came home made bubble wrap labeled new ou...       1   \n",
       "2032152  work hope continues working perhaps get discou...       0   \n",
       "2590977  software come printer support newer version ma...       1   \n",
       "1685277  arrived time came huge box expecting big pictu...       0   \n",
       "29865                                work well canon toner       0   \n",
       "\n",
       "                                                 MyReviews  \\\n",
       "1921057  [item, came, home, made, bubble, wrap, labeled...   \n",
       "2032152  [work, hope, continues, working, perhaps, get,...   \n",
       "2590977  [software, come, printer, support, newer, vers...   \n",
       "1685277  [arrived, time, came, huge, box, expecting, bi...   \n",
       "29865                           [work, well, canon, toner]   \n",
       "\n",
       "                                                  gvectors  \\\n",
       "1921057  [0.027547836303710938, 0.09846019744873047, 0....   \n",
       "2032152  [0.05845424107142857, 0.016178676060267856, -0...   \n",
       "2590977  [0.06760212912488339, -0.03568415855293843, -0...   \n",
       "1685277  [0.03836669921875, 0.05717875162760417, -0.008...   \n",
       "29865    [0.0806640625, 0.07841796875, -0.0003662109375...   \n",
       "\n",
       "                                                  cvectors  \\\n",
       "1921057  [0.027547836303710938, 0.09846019744873047, 0....   \n",
       "2032152  [0.05845424107142857, 0.016178676060267856, -0...   \n",
       "2590977  [0.06760212912488339, -0.03568415855293843, -0...   \n",
       "1685277  [0.03836669921875, 0.05717875162760417, -0.008...   \n",
       "29865    [0.0806640625, 0.07841796875, -0.0003662109375...   \n",
       "\n",
       "                                               congvectors  \n",
       "1921057  [[0.024291992, 0.010803223, -0.107421875, 0.30...  \n",
       "2032152  [[-0.075683594, 0.033691406, -0.064941406, 0.1...  \n",
       "2590977  [[0.20410156, -0.30078125, -0.013916016, 0.119...  \n",
       "1685277  [[0.15429688, 0.26757812, 0.09326172, -0.15234...  \n",
       "29865    [[-0.07568359375, 0.03369140625, -0.0649414062...  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting Word Embeddings from the Pre-trained Model\n",
    "\n",
    "def embeddingFun(sent):\n",
    "    vectorsize = new_model.vector_size\n",
    "    PT_Embeddings_temp = np.zeros(vectorsize)\n",
    "    PT_Embeddings = []\n",
    "    c=0\n",
    "    pad_value=0\n",
    "    desired_length=300\n",
    "    \n",
    "    for word in sent:\n",
    "        if word in new_model:\n",
    "            PT_Embeddings_temp=wv[word]\n",
    "        if c in range(0,10):\n",
    "            PT_Embeddings.append(PT_Embeddings_temp)\n",
    "            c+=1\n",
    "    \n",
    "    PT_Embeddings = padding(PT_Embeddings, pad_value, desired_length)\n",
    "    return np.array(PT_Embeddings)\n",
    "        \n",
    "binframes['congvectors']=binframes['MyReviews'].apply(embeddingFun)\n",
    "binframes.head(5)\n",
    "#temp =pd.DataFrame()\n",
    "#temp['congvectors'] = binframes['MyReviews'].apply(embeddingFun)\n",
    "#temp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#just checking vectorizing was done correctly\\ncount0 =0\\ncount1 =0\\ncount2 =0\\ncount3 =0\\nfor i in range(100000):\\n    if len(temp[\\'congvectors\\'].iloc[i]) >10:\\n        count0+=1\\n    elif len(temp[\\'congvectors\\'].iloc[i]) == 10:\\n        count1+=1\\n    elif len(temp[\\'congvectors\\'].iloc[i]) in range(5,10):\\n        count2+=1\\n    else:\\n        count3+=1\\nprint(\"Vectors of size greater than 10: \",count0)        \\nprint(\"Vectors of size 10: \",count1)\\nprint(\"Vectors of size between 5 and 10: \",count2)\\nprint(\"Vectors of size between 0 and 5: \",count3)\\nprint(\"Sentences vectorized\",(count0+count1+count2+count3))\\n'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#just checking vectorizing was done correctly\n",
    "count0 =0\n",
    "count1 =0\n",
    "count2 =0\n",
    "count3 =0\n",
    "for i in range(100000):\n",
    "    if len(temp['congvectors'].iloc[i]) >10:\n",
    "        count0+=1\n",
    "    elif len(temp['congvectors'].iloc[i]) == 10:\n",
    "        count1+=1\n",
    "    elif len(temp['congvectors'].iloc[i]) in range(5,10):\n",
    "        count2+=1\n",
    "    else:\n",
    "        count3+=1\n",
    "print(\"Vectors of size greater than 10: \",count0)        \n",
    "print(\"Vectors of size 10: \",count1)\n",
    "print(\"Vectors of size between 5 and 10: \",count2)\n",
    "print(\"Vectors of size between 0 and 5: \",count3)\n",
    "print(\"Sentences vectorized\",(count0+count1+count2+count3))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(temp['congvectors'].iloc[2000].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Custom Word2Vec for Concatenanting Extracted Features in Binary Data Set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are preparing the concatenated vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the word vectors from the previously custom trained model\n",
    "wvcon = KeyedVectors.load(\"word2vec.wordvectors\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Labels</th>\n",
       "      <th>MyReviews</th>\n",
       "      <th>gvectors</th>\n",
       "      <th>cvectors</th>\n",
       "      <th>congvectors</th>\n",
       "      <th>concvectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1921057</th>\n",
       "      <td>item came home made bubble wrap labeled new ou...</td>\n",
       "      <td>1</td>\n",
       "      <td>[item, came, home, made, bubble, wrap, labeled...</td>\n",
       "      <td>[0.027547836303710938, 0.09846019744873047, 0....</td>\n",
       "      <td>[0.027547836303710938, 0.09846019744873047, 0....</td>\n",
       "      <td>[[0.024291992, 0.010803223, -0.107421875, 0.30...</td>\n",
       "      <td>[[0.035866924, -0.01820376, 0.17473365, 0.0287...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032152</th>\n",
       "      <td>work hope continues working perhaps get discou...</td>\n",
       "      <td>0</td>\n",
       "      <td>[work, hope, continues, working, perhaps, get,...</td>\n",
       "      <td>[0.05845424107142857, 0.016178676060267856, -0...</td>\n",
       "      <td>[0.05845424107142857, 0.016178676060267856, -0...</td>\n",
       "      <td>[[-0.075683594, 0.033691406, -0.064941406, 0.1...</td>\n",
       "      <td>[[0.04482966, -0.032019116, 0.06074907, 0.0353...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590977</th>\n",
       "      <td>software come printer support newer version ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>[software, come, printer, support, newer, vers...</td>\n",
       "      <td>[0.06760212912488339, -0.03568415855293843, -0...</td>\n",
       "      <td>[0.06760212912488339, -0.03568415855293843, -0...</td>\n",
       "      <td>[[0.20410156, -0.30078125, -0.013916016, 0.119...</td>\n",
       "      <td>[[0.047153026, -0.038383402, -0.02039575, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685277</th>\n",
       "      <td>arrived time came huge box expecting big pictu...</td>\n",
       "      <td>0</td>\n",
       "      <td>[arrived, time, came, huge, box, expecting, bi...</td>\n",
       "      <td>[0.03836669921875, 0.05717875162760417, -0.008...</td>\n",
       "      <td>[0.03836669921875, 0.05717875162760417, -0.008...</td>\n",
       "      <td>[[0.15429688, 0.26757812, 0.09326172, -0.15234...</td>\n",
       "      <td>[[0.0069977418, -0.1542149, 0.39981222, 0.0632...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29865</th>\n",
       "      <td>work well canon toner</td>\n",
       "      <td>0</td>\n",
       "      <td>[work, well, canon, toner]</td>\n",
       "      <td>[0.0806640625, 0.07841796875, -0.0003662109375...</td>\n",
       "      <td>[0.0806640625, 0.07841796875, -0.0003662109375...</td>\n",
       "      <td>[[-0.07568359375, 0.03369140625, -0.0649414062...</td>\n",
       "      <td>[[0.044829659163951874, -0.03201911598443985, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reviews  Labels  \\\n",
       "1921057  item came home made bubble wrap labeled new ou...       1   \n",
       "2032152  work hope continues working perhaps get discou...       0   \n",
       "2590977  software come printer support newer version ma...       1   \n",
       "1685277  arrived time came huge box expecting big pictu...       0   \n",
       "29865                                work well canon toner       0   \n",
       "\n",
       "                                                 MyReviews  \\\n",
       "1921057  [item, came, home, made, bubble, wrap, labeled...   \n",
       "2032152  [work, hope, continues, working, perhaps, get,...   \n",
       "2590977  [software, come, printer, support, newer, vers...   \n",
       "1685277  [arrived, time, came, huge, box, expecting, bi...   \n",
       "29865                           [work, well, canon, toner]   \n",
       "\n",
       "                                                  gvectors  \\\n",
       "1921057  [0.027547836303710938, 0.09846019744873047, 0....   \n",
       "2032152  [0.05845424107142857, 0.016178676060267856, -0...   \n",
       "2590977  [0.06760212912488339, -0.03568415855293843, -0...   \n",
       "1685277  [0.03836669921875, 0.05717875162760417, -0.008...   \n",
       "29865    [0.0806640625, 0.07841796875, -0.0003662109375...   \n",
       "\n",
       "                                                  cvectors  \\\n",
       "1921057  [0.027547836303710938, 0.09846019744873047, 0....   \n",
       "2032152  [0.05845424107142857, 0.016178676060267856, -0...   \n",
       "2590977  [0.06760212912488339, -0.03568415855293843, -0...   \n",
       "1685277  [0.03836669921875, 0.05717875162760417, -0.008...   \n",
       "29865    [0.0806640625, 0.07841796875, -0.0003662109375...   \n",
       "\n",
       "                                               congvectors  \\\n",
       "1921057  [[0.024291992, 0.010803223, -0.107421875, 0.30...   \n",
       "2032152  [[-0.075683594, 0.033691406, -0.064941406, 0.1...   \n",
       "2590977  [[0.20410156, -0.30078125, -0.013916016, 0.119...   \n",
       "1685277  [[0.15429688, 0.26757812, 0.09326172, -0.15234...   \n",
       "29865    [[-0.07568359375, 0.03369140625, -0.0649414062...   \n",
       "\n",
       "                                               concvectors  \n",
       "1921057  [[0.035866924, -0.01820376, 0.17473365, 0.0287...  \n",
       "2032152  [[0.04482966, -0.032019116, 0.06074907, 0.0353...  \n",
       "2590977  [[0.047153026, -0.038383402, -0.02039575, -0.1...  \n",
       "1685277  [[0.0069977418, -0.1542149, 0.39981222, 0.0632...  \n",
       "29865    [[0.044829659163951874, -0.03201911598443985, ...  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting Word Embeddings from the Pre-trained Model\n",
    "\n",
    "def embeddingFun(sent):\n",
    "    vectorsize = new_model.vector_size\n",
    "    CM_Embeddings_temp = np.zeros(vectorsize)\n",
    "    CM_Embeddings = []\n",
    "    c=0\n",
    "    pad_value=0\n",
    "    desired_length=300\n",
    "    \n",
    "    for word in sent:\n",
    "        if word in wvcon:\n",
    "            CM_Embeddings_temp=wvcon[word]\n",
    "        if c in range(0,10):\n",
    "            CM_Embeddings.append(CM_Embeddings_temp)\n",
    "            c+=1\n",
    "    \n",
    "    CM_Embeddings = padding(CM_Embeddings, pad_value, desired_length)\n",
    "    return np.array(CM_Embeddings)\n",
    "        \n",
    "binframes['concvectors']=binframes['MyReviews'].apply(embeddingFun)\n",
    "binframes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNN Using Features extracted from Pre-trained Concatenated Word2Vec Model for Binary Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the Feedforward Neural Network is used for the Binary Classification, where the feature extracter is the Pre-trained Gensim Word2Vec model and the vector for a review are the concatenation of the vectors for each word in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 80-20 train-test\n",
    "x_train, x_test, y_train, y_test = train_test_split(binframes['congvectors'], binframes['Labels'], test_size=0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting NumPy arrays to TensorFlow tensors\n",
    "X_train_tf = tf.convert_to_tensor(x_train.to_list(), dtype=tf.float32)\n",
    "y_train_tf = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "X_test_tf = tf.convert_to_tensor(x_test.to_list(), dtype=tf.float32)\n",
    "y_test_tf = tf.convert_to_tensor(y_test, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening the tensor into a single feature vector\n",
    "x_train_tf_flat = tf.reshape(X_train_tf, (X_train_tf.shape[0],-1))\n",
    "X_test_tf_flat = tf.reshape(X_test_tf, (X_test_tf.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network_3 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation='relu', input_shape=((3000),)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the neural network\n",
    "neural_network_3.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2500/2500 [==============================] - 2s 653us/step - loss: 0.4609 - accuracy: 0.7789\n",
      "Epoch 2/100\n",
      "2500/2500 [==============================] - 2s 622us/step - loss: 0.3993 - accuracy: 0.8150\n",
      "Epoch 3/100\n",
      "2500/2500 [==============================] - 1s 597us/step - loss: 0.3422 - accuracy: 0.8475\n",
      "Epoch 4/100\n",
      "2500/2500 [==============================] - 1s 590us/step - loss: 0.2763 - accuracy: 0.8829\n",
      "Epoch 5/100\n",
      "2500/2500 [==============================] - 2s 625us/step - loss: 0.2119 - accuracy: 0.9147\n",
      "Epoch 6/100\n",
      "2500/2500 [==============================] - 2s 619us/step - loss: 0.1612 - accuracy: 0.9380\n",
      "Epoch 7/100\n",
      "2500/2500 [==============================] - 2s 819us/step - loss: 0.1235 - accuracy: 0.9537\n",
      "Epoch 8/100\n",
      "2500/2500 [==============================] - 2s 929us/step - loss: 0.0999 - accuracy: 0.9626\n",
      "Epoch 9/100\n",
      "2500/2500 [==============================] - 2s 720us/step - loss: 0.0855 - accuracy: 0.9686\n",
      "Epoch 10/100\n",
      "2500/2500 [==============================] - 2s 794us/step - loss: 0.0718 - accuracy: 0.9742\n",
      "Epoch 11/100\n",
      "2500/2500 [==============================] - 2s 684us/step - loss: 0.0669 - accuracy: 0.9761\n",
      "Epoch 12/100\n",
      "2500/2500 [==============================] - 2s 756us/step - loss: 0.0600 - accuracy: 0.9786\n",
      "Epoch 13/100\n",
      "2500/2500 [==============================] - 2s 726us/step - loss: 0.0559 - accuracy: 0.9798\n",
      "Epoch 14/100\n",
      "2500/2500 [==============================] - 2s 793us/step - loss: 0.0518 - accuracy: 0.9816\n",
      "Epoch 15/100\n",
      "2500/2500 [==============================] - 2s 701us/step - loss: 0.0499 - accuracy: 0.9827\n",
      "Epoch 16/100\n",
      "2500/2500 [==============================] - 2s 659us/step - loss: 0.0459 - accuracy: 0.9843\n",
      "Epoch 17/100\n",
      "2500/2500 [==============================] - 2s 703us/step - loss: 0.0437 - accuracy: 0.9847\n",
      "Epoch 18/100\n",
      "2500/2500 [==============================] - 2s 675us/step - loss: 0.0418 - accuracy: 0.9853\n",
      "Epoch 19/100\n",
      "2500/2500 [==============================] - 2s 642us/step - loss: 0.0402 - accuracy: 0.9861\n",
      "Epoch 20/100\n",
      "2500/2500 [==============================] - 2s 713us/step - loss: 0.0401 - accuracy: 0.9858\n",
      "Epoch 21/100\n",
      "2500/2500 [==============================] - 2s 659us/step - loss: 0.0357 - accuracy: 0.9876\n",
      "Epoch 22/100\n",
      "2500/2500 [==============================] - 2s 639us/step - loss: 0.0357 - accuracy: 0.9874\n",
      "Epoch 23/100\n",
      "2500/2500 [==============================] - 2s 646us/step - loss: 0.0341 - accuracy: 0.9880\n",
      "Epoch 24/100\n",
      "2500/2500 [==============================] - 2s 661us/step - loss: 0.0332 - accuracy: 0.9888\n",
      "Epoch 25/100\n",
      "2500/2500 [==============================] - 2s 623us/step - loss: 0.0321 - accuracy: 0.9889\n",
      "Epoch 26/100\n",
      "2500/2500 [==============================] - 2s 622us/step - loss: 0.0322 - accuracy: 0.9888\n",
      "Epoch 27/100\n",
      "2500/2500 [==============================] - 2s 623us/step - loss: 0.0312 - accuracy: 0.9892\n",
      "Epoch 28/100\n",
      "2500/2500 [==============================] - 2s 600us/step - loss: 0.0325 - accuracy: 0.9888\n",
      "Epoch 29/100\n",
      "2500/2500 [==============================] - 2s 604us/step - loss: 0.0292 - accuracy: 0.9898\n",
      "Epoch 30/100\n",
      "2500/2500 [==============================] - 2s 692us/step - loss: 0.0290 - accuracy: 0.9898\n",
      "Epoch 31/100\n",
      "2500/2500 [==============================] - 2s 656us/step - loss: 0.0302 - accuracy: 0.9894\n",
      "Epoch 32/100\n",
      "2500/2500 [==============================] - 2s 629us/step - loss: 0.0260 - accuracy: 0.9909\n",
      "Epoch 33/100\n",
      "2500/2500 [==============================] - 2s 643us/step - loss: 0.0269 - accuracy: 0.9905\n",
      "Epoch 34/100\n",
      "2500/2500 [==============================] - 2s 638us/step - loss: 0.0260 - accuracy: 0.9911\n",
      "Epoch 35/100\n",
      "2500/2500 [==============================] - 2s 632us/step - loss: 0.0279 - accuracy: 0.9906\n",
      "Epoch 36/100\n",
      "2500/2500 [==============================] - 2s 663us/step - loss: 0.0245 - accuracy: 0.9919\n",
      "Epoch 37/100\n",
      "2500/2500 [==============================] - 2s 619us/step - loss: 0.0261 - accuracy: 0.9908\n",
      "Epoch 38/100\n",
      "2500/2500 [==============================] - 2s 621us/step - loss: 0.0241 - accuracy: 0.9920\n",
      "Epoch 39/100\n",
      "2500/2500 [==============================] - 2s 624us/step - loss: 0.0222 - accuracy: 0.9922\n",
      "Epoch 40/100\n",
      "2500/2500 [==============================] - 2s 628us/step - loss: 0.0241 - accuracy: 0.9915\n",
      "Epoch 41/100\n",
      "2500/2500 [==============================] - 2s 657us/step - loss: 0.0233 - accuracy: 0.9922\n",
      "Epoch 42/100\n",
      "2500/2500 [==============================] - 2s 626us/step - loss: 0.0236 - accuracy: 0.9918\n",
      "Epoch 43/100\n",
      "2500/2500 [==============================] - 2s 632us/step - loss: 0.0225 - accuracy: 0.9923\n",
      "Epoch 44/100\n",
      "2500/2500 [==============================] - 2s 628us/step - loss: 0.0223 - accuracy: 0.9922\n",
      "Epoch 45/100\n",
      "2500/2500 [==============================] - 2s 628us/step - loss: 0.0216 - accuracy: 0.9924\n",
      "Epoch 46/100\n",
      "2500/2500 [==============================] - 2s 655us/step - loss: 0.0242 - accuracy: 0.9916\n",
      "Epoch 47/100\n",
      "2500/2500 [==============================] - 2s 742us/step - loss: 0.0204 - accuracy: 0.9927\n",
      "Epoch 48/100\n",
      "2500/2500 [==============================] - 2s 836us/step - loss: 0.0211 - accuracy: 0.9928\n",
      "Epoch 49/100\n",
      "2500/2500 [==============================] - 2s 682us/step - loss: 0.0226 - accuracy: 0.9922\n",
      "Epoch 50/100\n",
      "2500/2500 [==============================] - 2s 730us/step - loss: 0.0223 - accuracy: 0.9922\n",
      "Epoch 51/100\n",
      "2500/2500 [==============================] - 2s 666us/step - loss: 0.0203 - accuracy: 0.9927\n",
      "Epoch 52/100\n",
      "2500/2500 [==============================] - 2s 681us/step - loss: 0.0207 - accuracy: 0.9927\n",
      "Epoch 53/100\n",
      "2500/2500 [==============================] - 2s 648us/step - loss: 0.0188 - accuracy: 0.9933\n",
      "Epoch 54/100\n",
      "2500/2500 [==============================] - 2s 637us/step - loss: 0.0206 - accuracy: 0.9927\n",
      "Epoch 55/100\n",
      "2500/2500 [==============================] - 2s 658us/step - loss: 0.0187 - accuracy: 0.9936\n",
      "Epoch 56/100\n",
      "2500/2500 [==============================] - 2s 649us/step - loss: 0.0205 - accuracy: 0.9930\n",
      "Epoch 57/100\n",
      "2500/2500 [==============================] - 2s 700us/step - loss: 0.0193 - accuracy: 0.9937\n",
      "Epoch 58/100\n",
      "2500/2500 [==============================] - 2s 653us/step - loss: 0.0194 - accuracy: 0.9934\n",
      "Epoch 59/100\n",
      "2500/2500 [==============================] - 2s 610us/step - loss: 0.0200 - accuracy: 0.9931\n",
      "Epoch 60/100\n",
      "2500/2500 [==============================] - 2s 693us/step - loss: 0.0194 - accuracy: 0.9932\n",
      "Epoch 61/100\n",
      "2500/2500 [==============================] - 2s 650us/step - loss: 0.0188 - accuracy: 0.9933\n",
      "Epoch 62/100\n",
      "2500/2500 [==============================] - 1s 594us/step - loss: 0.0184 - accuracy: 0.9934\n",
      "Epoch 63/100\n",
      "2500/2500 [==============================] - 2s 602us/step - loss: 0.0201 - accuracy: 0.9931\n",
      "Epoch 64/100\n",
      "2500/2500 [==============================] - 2s 681us/step - loss: 0.0182 - accuracy: 0.9936\n",
      "Epoch 65/100\n",
      "2500/2500 [==============================] - 2s 650us/step - loss: 0.0183 - accuracy: 0.9934\n",
      "Epoch 66/100\n",
      "2500/2500 [==============================] - 2s 733us/step - loss: 0.0187 - accuracy: 0.9934\n",
      "Epoch 67/100\n",
      "2500/2500 [==============================] - 2s 739us/step - loss: 0.0182 - accuracy: 0.9937\n",
      "Epoch 68/100\n",
      "2500/2500 [==============================] - 2s 686us/step - loss: 0.0187 - accuracy: 0.9933\n",
      "Epoch 69/100\n",
      "2500/2500 [==============================] - 2s 695us/step - loss: 0.0171 - accuracy: 0.9941\n",
      "Epoch 70/100\n",
      "2500/2500 [==============================] - 2s 657us/step - loss: 0.0176 - accuracy: 0.9939\n",
      "Epoch 71/100\n",
      "2500/2500 [==============================] - 2s 650us/step - loss: 0.0175 - accuracy: 0.9937\n",
      "Epoch 72/100\n",
      "2500/2500 [==============================] - 2s 641us/step - loss: 0.0175 - accuracy: 0.9940\n",
      "Epoch 73/100\n",
      "2500/2500 [==============================] - 2s 682us/step - loss: 0.0166 - accuracy: 0.9941\n",
      "Epoch 74/100\n",
      "2500/2500 [==============================] - 2s 639us/step - loss: 0.0171 - accuracy: 0.9940\n",
      "Epoch 75/100\n",
      "2500/2500 [==============================] - 2s 613us/step - loss: 0.0165 - accuracy: 0.9939\n",
      "Epoch 76/100\n",
      "2500/2500 [==============================] - 2s 614us/step - loss: 0.0176 - accuracy: 0.9937\n",
      "Epoch 77/100\n",
      "2500/2500 [==============================] - 1s 583us/step - loss: 0.0166 - accuracy: 0.9941\n",
      "Epoch 78/100\n",
      "2500/2500 [==============================] - 2s 623us/step - loss: 0.0172 - accuracy: 0.9939\n",
      "Epoch 79/100\n",
      "2500/2500 [==============================] - 2s 640us/step - loss: 0.0165 - accuracy: 0.9942\n",
      "Epoch 80/100\n",
      "2500/2500 [==============================] - 2s 676us/step - loss: 0.0166 - accuracy: 0.9943\n",
      "Epoch 81/100\n",
      "2500/2500 [==============================] - 2s 630us/step - loss: 0.0153 - accuracy: 0.9944\n",
      "Epoch 82/100\n",
      "2500/2500 [==============================] - 2s 635us/step - loss: 0.0159 - accuracy: 0.9944\n",
      "Epoch 83/100\n",
      "2500/2500 [==============================] - 2s 691us/step - loss: 0.0170 - accuracy: 0.9940\n",
      "Epoch 84/100\n",
      "2500/2500 [==============================] - 1s 577us/step - loss: 0.0164 - accuracy: 0.9944\n",
      "Epoch 85/100\n",
      "2500/2500 [==============================] - 1s 588us/step - loss: 0.0176 - accuracy: 0.9940\n",
      "Epoch 86/100\n",
      "2500/2500 [==============================] - 2s 610us/step - loss: 0.0158 - accuracy: 0.9942\n",
      "Epoch 87/100\n",
      "2500/2500 [==============================] - 2s 603us/step - loss: 0.0155 - accuracy: 0.9944\n",
      "Epoch 88/100\n",
      "2500/2500 [==============================] - 2s 618us/step - loss: 0.0153 - accuracy: 0.9945\n",
      "Epoch 89/100\n",
      "2500/2500 [==============================] - 2s 600us/step - loss: 0.0172 - accuracy: 0.9939\n",
      "Epoch 90/100\n",
      "2500/2500 [==============================] - 1s 591us/step - loss: 0.0157 - accuracy: 0.9944\n",
      "Epoch 91/100\n",
      "2500/2500 [==============================] - 1s 598us/step - loss: 0.0155 - accuracy: 0.9942\n",
      "Epoch 92/100\n",
      "2500/2500 [==============================] - 2s 605us/step - loss: 0.0162 - accuracy: 0.9942\n",
      "Epoch 93/100\n",
      "2500/2500 [==============================] - 2s 627us/step - loss: 0.0157 - accuracy: 0.9944\n",
      "Epoch 94/100\n",
      "2500/2500 [==============================] - 2s 621us/step - loss: 0.0153 - accuracy: 0.9947\n",
      "Epoch 95/100\n",
      "2500/2500 [==============================] - 1s 599us/step - loss: 0.0145 - accuracy: 0.9948\n",
      "Epoch 96/100\n",
      "2500/2500 [==============================] - 1s 595us/step - loss: 0.0158 - accuracy: 0.9945\n",
      "Epoch 97/100\n",
      "2500/2500 [==============================] - 2s 705us/step - loss: 0.0147 - accuracy: 0.9945\n",
      "Epoch 98/100\n",
      "2500/2500 [==============================] - 2s 605us/step - loss: 0.0149 - accuracy: 0.9948\n",
      "Epoch 99/100\n",
      "2500/2500 [==============================] - 2s 675us/step - loss: 0.0157 - accuracy: 0.9943\n",
      "Epoch 100/100\n",
      "2500/2500 [==============================] - 2s 688us/step - loss: 0.0144 - accuracy: 0.9948\n"
     ]
    }
   ],
   "source": [
    "# Training the neural network\n",
    "history3 = neural_network_3.fit(x_train_tf_flat, y_train_tf, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 0s 517us/step - loss: 3.0111 - accuracy: 0.7652\n",
      "Test accuracy: 0.7652000188827515\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the neural network on the test set\n",
    "test_loss, test_acc = neural_network_3.evaluate(X_test_tf_flat, y_test_tf)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Table[8].append(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNN Using Features extracted from Custom Concatenated Word2Vec Model For Binary Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the Feedforward Neural Network is used for the Binary Classification, where the feature extracter is the Custom Word2Vec model and the vector for a review are the concatenation of the vectors for each word in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 80-20 train-test\n",
    "x_train, x_test, y_train, y_test = train_test_split(binframes['concvectors'], binframes['Labels'], test_size=0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting NumPy arrays to TensorFlow tensors\n",
    "X_train_tf = tf.convert_to_tensor(x_train.to_list(), dtype=tf.float32)\n",
    "y_train_tf = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "X_test_tf = tf.convert_to_tensor(x_test.to_list(), dtype=tf.float32)\n",
    "y_test_tf = tf.convert_to_tensor(y_test, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening the tensor into a single feature vector\n",
    "x_train_tf_flat = tf.reshape(X_train_tf, (X_train_tf.shape[0],-1))\n",
    "X_test_tf_flat = tf.reshape(X_test_tf, (X_test_tf.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network_4 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation='relu', input_shape=((3000),)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the neural network\n",
    "neural_network_4.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  50/2500 [..............................] - ETA: 2s - loss: 0.5508 - accuracy: 0.7300  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 2s 775us/step - loss: 0.4087 - accuracy: 0.8116\n",
      "Epoch 2/100\n",
      "2500/2500 [==============================] - 2s 617us/step - loss: 0.3618 - accuracy: 0.8364\n",
      "Epoch 3/100\n",
      "2500/2500 [==============================] - 2s 610us/step - loss: 0.3208 - accuracy: 0.8581\n",
      "Epoch 4/100\n",
      "2500/2500 [==============================] - 1s 596us/step - loss: 0.2655 - accuracy: 0.8888\n",
      "Epoch 5/100\n",
      "2500/2500 [==============================] - 2s 664us/step - loss: 0.2055 - accuracy: 0.9185\n",
      "Epoch 6/100\n",
      "2500/2500 [==============================] - 2s 683us/step - loss: 0.1514 - accuracy: 0.9430\n",
      "Epoch 7/100\n",
      "2500/2500 [==============================] - 2s 612us/step - loss: 0.1124 - accuracy: 0.9587\n",
      "Epoch 8/100\n",
      "2500/2500 [==============================] - 1s 595us/step - loss: 0.0861 - accuracy: 0.9692\n",
      "Epoch 9/100\n",
      "2500/2500 [==============================] - 2s 603us/step - loss: 0.0688 - accuracy: 0.9756\n",
      "Epoch 10/100\n",
      "2500/2500 [==============================] - 2s 602us/step - loss: 0.0617 - accuracy: 0.9790\n",
      "Epoch 11/100\n",
      "2500/2500 [==============================] - 2s 609us/step - loss: 0.0569 - accuracy: 0.9804\n",
      "Epoch 12/100\n",
      "2500/2500 [==============================] - 2s 661us/step - loss: 0.0495 - accuracy: 0.9831\n",
      "Epoch 13/100\n",
      "2500/2500 [==============================] - 2s 660us/step - loss: 0.0456 - accuracy: 0.9845\n",
      "Epoch 14/100\n",
      "2500/2500 [==============================] - 2s 653us/step - loss: 0.0424 - accuracy: 0.9850\n",
      "Epoch 15/100\n",
      "2500/2500 [==============================] - 2s 695us/step - loss: 0.0422 - accuracy: 0.9855\n",
      "Epoch 16/100\n",
      "2500/2500 [==============================] - 1s 597us/step - loss: 0.0373 - accuracy: 0.9871\n",
      "Epoch 17/100\n",
      "2500/2500 [==============================] - 2s 609us/step - loss: 0.0393 - accuracy: 0.9862\n",
      "Epoch 18/100\n",
      "2500/2500 [==============================] - 2s 606us/step - loss: 0.0349 - accuracy: 0.9878\n",
      "Epoch 19/100\n",
      "2500/2500 [==============================] - 2s 600us/step - loss: 0.0336 - accuracy: 0.9882\n",
      "Epoch 20/100\n",
      "2500/2500 [==============================] - 2s 636us/step - loss: 0.0324 - accuracy: 0.9890\n",
      "Epoch 21/100\n",
      "2500/2500 [==============================] - 2s 719us/step - loss: 0.0331 - accuracy: 0.9888\n",
      "Epoch 22/100\n",
      "2500/2500 [==============================] - 2s 711us/step - loss: 0.0311 - accuracy: 0.9893\n",
      "Epoch 23/100\n",
      "2500/2500 [==============================] - 2s 660us/step - loss: 0.0332 - accuracy: 0.9887\n",
      "Epoch 24/100\n",
      "2500/2500 [==============================] - 2s 656us/step - loss: 0.0278 - accuracy: 0.9902\n",
      "Epoch 25/100\n",
      "2500/2500 [==============================] - 2s 622us/step - loss: 0.0290 - accuracy: 0.9899\n",
      "Epoch 26/100\n",
      "2500/2500 [==============================] - 1s 593us/step - loss: 0.0290 - accuracy: 0.9900\n",
      "Epoch 27/100\n",
      "2500/2500 [==============================] - 2s 609us/step - loss: 0.0264 - accuracy: 0.9911\n",
      "Epoch 28/100\n",
      "2500/2500 [==============================] - 1s 597us/step - loss: 0.0249 - accuracy: 0.9914\n",
      "Epoch 29/100\n",
      "2500/2500 [==============================] - 1s 594us/step - loss: 0.0283 - accuracy: 0.9901\n",
      "Epoch 30/100\n",
      "2500/2500 [==============================] - 2s 646us/step - loss: 0.0257 - accuracy: 0.9913\n",
      "Epoch 31/100\n",
      "2500/2500 [==============================] - 2s 606us/step - loss: 0.0261 - accuracy: 0.9916\n",
      "Epoch 32/100\n",
      "2500/2500 [==============================] - 2s 674us/step - loss: 0.0255 - accuracy: 0.9912\n",
      "Epoch 33/100\n",
      "2500/2500 [==============================] - 2s 659us/step - loss: 0.0246 - accuracy: 0.9913\n",
      "Epoch 34/100\n",
      "2500/2500 [==============================] - 2s 600us/step - loss: 0.0233 - accuracy: 0.9921\n",
      "Epoch 35/100\n",
      "2500/2500 [==============================] - 2s 639us/step - loss: 0.0227 - accuracy: 0.9920\n",
      "Epoch 36/100\n",
      "2500/2500 [==============================] - 1s 589us/step - loss: 0.0241 - accuracy: 0.9917\n",
      "Epoch 37/100\n",
      "2500/2500 [==============================] - 1s 586us/step - loss: 0.0220 - accuracy: 0.9924\n",
      "Epoch 38/100\n",
      "2500/2500 [==============================] - 1s 599us/step - loss: 0.0217 - accuracy: 0.9925\n",
      "Epoch 39/100\n",
      "2500/2500 [==============================] - 1s 591us/step - loss: 0.0224 - accuracy: 0.9923\n",
      "Epoch 40/100\n",
      "2500/2500 [==============================] - 2s 651us/step - loss: 0.0218 - accuracy: 0.9926\n",
      "Epoch 41/100\n",
      "2500/2500 [==============================] - 2s 707us/step - loss: 0.0214 - accuracy: 0.9925\n",
      "Epoch 42/100\n",
      "2500/2500 [==============================] - 2s 601us/step - loss: 0.0222 - accuracy: 0.9924\n",
      "Epoch 43/100\n",
      "2500/2500 [==============================] - 1s 596us/step - loss: 0.0216 - accuracy: 0.9927\n",
      "Epoch 44/100\n",
      "2500/2500 [==============================] - 1s 593us/step - loss: 0.0212 - accuracy: 0.9925\n",
      "Epoch 45/100\n",
      "2500/2500 [==============================] - 1s 592us/step - loss: 0.0204 - accuracy: 0.9929\n",
      "Epoch 46/100\n",
      "2500/2500 [==============================] - 2s 604us/step - loss: 0.0199 - accuracy: 0.9929\n",
      "Epoch 47/100\n",
      "2500/2500 [==============================] - 2s 640us/step - loss: 0.0205 - accuracy: 0.9929\n",
      "Epoch 48/100\n",
      "2500/2500 [==============================] - 2s 602us/step - loss: 0.0203 - accuracy: 0.9930\n",
      "Epoch 49/100\n",
      "2500/2500 [==============================] - 1s 599us/step - loss: 0.0187 - accuracy: 0.9935\n",
      "Epoch 50/100\n",
      "2500/2500 [==============================] - 2s 613us/step - loss: 0.0208 - accuracy: 0.9931\n",
      "Epoch 51/100\n",
      "2500/2500 [==============================] - 2s 613us/step - loss: 0.0174 - accuracy: 0.9937\n",
      "Epoch 52/100\n",
      "2500/2500 [==============================] - 2s 605us/step - loss: 0.0190 - accuracy: 0.9936\n",
      "Epoch 53/100\n",
      "2500/2500 [==============================] - 2s 634us/step - loss: 0.0180 - accuracy: 0.9936\n",
      "Epoch 54/100\n",
      "2500/2500 [==============================] - 1s 598us/step - loss: 0.0178 - accuracy: 0.9936\n",
      "Epoch 55/100\n",
      "2500/2500 [==============================] - 1s 593us/step - loss: 0.0188 - accuracy: 0.9936\n",
      "Epoch 56/100\n",
      "2500/2500 [==============================] - 1s 595us/step - loss: 0.0180 - accuracy: 0.9938\n",
      "Epoch 57/100\n",
      "2500/2500 [==============================] - 2s 603us/step - loss: 0.0178 - accuracy: 0.9937\n",
      "Epoch 58/100\n",
      "2500/2500 [==============================] - 2s 610us/step - loss: 0.0165 - accuracy: 0.9940\n",
      "Epoch 59/100\n",
      "2500/2500 [==============================] - 2s 634us/step - loss: 0.0194 - accuracy: 0.9933\n",
      "Epoch 60/100\n",
      "2500/2500 [==============================] - 1s 586us/step - loss: 0.0187 - accuracy: 0.9936\n",
      "Epoch 61/100\n",
      "2500/2500 [==============================] - 1s 586us/step - loss: 0.0183 - accuracy: 0.9934\n",
      "Epoch 62/100\n",
      "2500/2500 [==============================] - 1s 589us/step - loss: 0.0175 - accuracy: 0.9939\n",
      "Epoch 63/100\n",
      "2500/2500 [==============================] - 1s 594us/step - loss: 0.0160 - accuracy: 0.9944\n",
      "Epoch 64/100\n",
      "2500/2500 [==============================] - 2s 708us/step - loss: 0.0171 - accuracy: 0.9940\n",
      "Epoch 65/100\n",
      "2500/2500 [==============================] - 2s 630us/step - loss: 0.0184 - accuracy: 0.9936\n",
      "Epoch 66/100\n",
      "2500/2500 [==============================] - 1s 594us/step - loss: 0.0182 - accuracy: 0.9937\n",
      "Epoch 67/100\n",
      "2500/2500 [==============================] - 1s 596us/step - loss: 0.0165 - accuracy: 0.9943\n",
      "Epoch 68/100\n",
      "2500/2500 [==============================] - 1s 581us/step - loss: 0.0163 - accuracy: 0.9945\n",
      "Epoch 69/100\n",
      "2500/2500 [==============================] - 1s 592us/step - loss: 0.0159 - accuracy: 0.9943\n",
      "Epoch 70/100\n",
      "2500/2500 [==============================] - 2s 676us/step - loss: 0.0163 - accuracy: 0.9943\n",
      "Epoch 71/100\n",
      "2500/2500 [==============================] - 1s 571us/step - loss: 0.0155 - accuracy: 0.9944\n",
      "Epoch 72/100\n",
      "2500/2500 [==============================] - 1s 564us/step - loss: 0.0177 - accuracy: 0.9939\n",
      "Epoch 73/100\n",
      "2500/2500 [==============================] - 1s 560us/step - loss: 0.0147 - accuracy: 0.9946\n",
      "Epoch 74/100\n",
      "2500/2500 [==============================] - 1s 592us/step - loss: 0.0163 - accuracy: 0.9944\n",
      "Epoch 75/100\n",
      "2500/2500 [==============================] - 2s 652us/step - loss: 0.0160 - accuracy: 0.9943\n",
      "Epoch 76/100\n",
      "2500/2500 [==============================] - 1s 568us/step - loss: 0.0153 - accuracy: 0.9947\n",
      "Epoch 77/100\n",
      "2500/2500 [==============================] - 1s 566us/step - loss: 0.0155 - accuracy: 0.9945\n",
      "Epoch 78/100\n",
      "2500/2500 [==============================] - 1s 570us/step - loss: 0.0152 - accuracy: 0.9946\n",
      "Epoch 79/100\n",
      "2500/2500 [==============================] - 2s 646us/step - loss: 0.0155 - accuracy: 0.9944\n",
      "Epoch 80/100\n",
      "2500/2500 [==============================] - 2s 911us/step - loss: 0.0164 - accuracy: 0.9944\n",
      "Epoch 81/100\n",
      "2500/2500 [==============================] - 2s 682us/step - loss: 0.0171 - accuracy: 0.9938\n",
      "Epoch 82/100\n",
      "2500/2500 [==============================] - 2s 668us/step - loss: 0.0153 - accuracy: 0.9945\n",
      "Epoch 83/100\n",
      "2500/2500 [==============================] - 2s 614us/step - loss: 0.0148 - accuracy: 0.9948\n",
      "Epoch 84/100\n",
      "2500/2500 [==============================] - 2s 670us/step - loss: 0.0145 - accuracy: 0.9945\n",
      "Epoch 85/100\n",
      "2500/2500 [==============================] - 2s 657us/step - loss: 0.0153 - accuracy: 0.9946\n",
      "Epoch 86/100\n",
      "2500/2500 [==============================] - 2s 642us/step - loss: 0.0142 - accuracy: 0.9947\n",
      "Epoch 87/100\n",
      "2500/2500 [==============================] - 2s 675us/step - loss: 0.0147 - accuracy: 0.9945\n",
      "Epoch 88/100\n",
      "2500/2500 [==============================] - 2s 640us/step - loss: 0.0149 - accuracy: 0.9947\n",
      "Epoch 89/100\n",
      "2500/2500 [==============================] - 2s 650us/step - loss: 0.0149 - accuracy: 0.9946\n",
      "Epoch 90/100\n",
      "2500/2500 [==============================] - 2s 721us/step - loss: 0.0136 - accuracy: 0.9951\n",
      "Epoch 91/100\n",
      "2500/2500 [==============================] - 2s 636us/step - loss: 0.0162 - accuracy: 0.9943\n",
      "Epoch 92/100\n",
      "2500/2500 [==============================] - 2s 650us/step - loss: 0.0153 - accuracy: 0.9945\n",
      "Epoch 93/100\n",
      "2500/2500 [==============================] - 1s 576us/step - loss: 0.0152 - accuracy: 0.9945\n",
      "Epoch 94/100\n",
      "2500/2500 [==============================] - 1s 597us/step - loss: 0.0166 - accuracy: 0.9944\n",
      "Epoch 95/100\n",
      "2500/2500 [==============================] - 2s 641us/step - loss: 0.0133 - accuracy: 0.9952\n",
      "Epoch 96/100\n",
      "2500/2500 [==============================] - 2s 632us/step - loss: 0.0143 - accuracy: 0.9949\n",
      "Epoch 97/100\n",
      "2500/2500 [==============================] - 1s 580us/step - loss: 0.0143 - accuracy: 0.9949\n",
      "Epoch 98/100\n",
      "2500/2500 [==============================] - 2s 618us/step - loss: 0.0142 - accuracy: 0.9950\n",
      "Epoch 99/100\n",
      "2500/2500 [==============================] - 2s 635us/step - loss: 0.0151 - accuracy: 0.9948\n",
      "Epoch 100/100\n",
      "2500/2500 [==============================] - 2s 712us/step - loss: 0.0130 - accuracy: 0.9953\n"
     ]
    }
   ],
   "source": [
    "# Training the neural network\n",
    "history4 = neural_network_4.fit(x_train_tf_flat, y_train_tf, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 0s 398us/step - loss: 3.0079 - accuracy: 0.7911\n",
      "Test accuracy: 0.7910500168800354\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the neural network on the test set\n",
    "test_loss, test_acc = neural_network_4.evaluate(X_test_tf_flat, y_test_tf)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Table[9].append(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FNN for Ternary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pre-trained Avg Word2Vec for Feature Extraction in Ternary DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are performing the Pre-trained Gensim Word2Vec feature extraction for Ternary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Labels</th>\n",
       "      <th>MyReviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1163606</th>\n",
       "      <td>excellent pen actually pen like use write anyt...</td>\n",
       "      <td>0</td>\n",
       "      <td>[excellent, pen, actually, pen, like, use, wri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069284</th>\n",
       "      <td>fresh set battery nice strong beam unfortunate...</td>\n",
       "      <td>2</td>\n",
       "      <td>[fresh, set, battery, nice, strong, beam, unfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338411</th>\n",
       "      <td>file folder label great use folder</td>\n",
       "      <td>0</td>\n",
       "      <td>[file, folder, label, great, use, folder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37088</th>\n",
       "      <td>work 's well heavy duty steel original stapler...</td>\n",
       "      <td>2</td>\n",
       "      <td>[work, 's, well, heavy, duty, steel, original,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752649</th>\n",
       "      <td>great quality great value</td>\n",
       "      <td>0</td>\n",
       "      <td>[great, quality, great, value]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reviews  Labels  \\\n",
       "1163606  excellent pen actually pen like use write anyt...       0   \n",
       "2069284  fresh set battery nice strong beam unfortunate...       2   \n",
       "338411                  file folder label great use folder       0   \n",
       "37088    work 's well heavy duty steel original stapler...       2   \n",
       "752649                           great quality great value       0   \n",
       "\n",
       "                                                 MyReviews  \n",
       "1163606  [excellent, pen, actually, pen, like, use, wri...  \n",
       "2069284  [fresh, set, battery, nice, strong, beam, unfo...  \n",
       "338411           [file, folder, label, great, use, folder]  \n",
       "37088    [work, 's, well, heavy, duty, steel, original,...  \n",
       "752649                      [great, quality, great, value]  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenizing the reviews into words\n",
    "terframes['MyReviews'] = [word_tokenize(t) for t in terframes['reviews']]\n",
    "terframes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = KeyedVectors.load(temporary_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Word Embeddings from the Pre-trained Model\n",
    "\n",
    "def embeddingFun(sent):\n",
    "    vectorsize = new_model.vector_size\n",
    "    PT_Embeddings = np.zeros(vectorsize)\n",
    "    c=1\n",
    "    \n",
    "    for word in sent:\n",
    "        if word in new_model:\n",
    "            c+=1\n",
    "            PT_Embeddings+=wv[word]\n",
    "    avg = PT_Embeddings/c\n",
    "    return avg\n",
    "        \n",
    "terframes['gvectors']=terframes['MyReviews'].apply(embeddingFun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Custom Avg Word2Vec for Feature Extraction in Ternary DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are performing the Custom Word2Vec feature extraction for Ternary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This process took 158.33 seconds.\n"
     ]
    }
   ],
   "source": [
    "#making and saving our custom Word2Vec Model\n",
    "start = time.time()\n",
    "model = Word2Vec(sentences=terframes['MyReviews'], vector_size=300, window=11, min_count=10, workers=cores-1, sg=1, hs=1)\n",
    "end = round(time.time()-start,2)\n",
    "print(\"This process took\",end,\"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vecTer.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"word2vecTer.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = model.wv\n",
    "word_vectors.save(\"word2vecTer.wordvectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load back with memory-mapping = read-only, shared across processes.\n",
    "wv2 = KeyedVectors.load(\"word2vecTer.wordvectors\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Word Embeddings from the Pre-trained Model\n",
    "\n",
    "def embeddingFun2(sent):\n",
    "    vectorsize = wv2.vector_size\n",
    "    CM_Embeddings = np.zeros(vectorsize)\n",
    "    c=1\n",
    "    \n",
    "    for word in sent:\n",
    "        if word in wv2:\n",
    "            c+=1\n",
    "            PT_Embeddings+=wv[word]\n",
    "    avg = CM_Embeddings/c\n",
    "    return avg\n",
    "        \n",
    "terframes['cvectors']=terframes['MyReviews'].apply(embeddingFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Labels</th>\n",
       "      <th>MyReviews</th>\n",
       "      <th>gvectors</th>\n",
       "      <th>cvectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1163606</th>\n",
       "      <td>excellent pen actually pen like use write anyt...</td>\n",
       "      <td>0</td>\n",
       "      <td>[excellent, pen, actually, pen, like, use, wri...</td>\n",
       "      <td>[0.013108995225694444, -0.015750461154513888, ...</td>\n",
       "      <td>[0.013108995225694444, -0.015750461154513888, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069284</th>\n",
       "      <td>fresh set battery nice strong beam unfortunate...</td>\n",
       "      <td>2</td>\n",
       "      <td>[fresh, set, battery, nice, strong, beam, unfo...</td>\n",
       "      <td>[0.035248976487379804, 0.09482046274038461, 0....</td>\n",
       "      <td>[0.035248976487379804, 0.09482046274038461, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338411</th>\n",
       "      <td>file folder label great use folder</td>\n",
       "      <td>0</td>\n",
       "      <td>[file, folder, label, great, use, folder]</td>\n",
       "      <td>[0.11321149553571429, 0.029767717633928572, -0...</td>\n",
       "      <td>[0.11321149553571429, 0.029767717633928572, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37088</th>\n",
       "      <td>work 's well heavy duty steel original stapler...</td>\n",
       "      <td>2</td>\n",
       "      <td>[work, 's, well, heavy, duty, steel, original,...</td>\n",
       "      <td>[0.07191051136363637, 0.07883522727272728, -0....</td>\n",
       "      <td>[0.07191051136363637, 0.07883522727272728, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752649</th>\n",
       "      <td>great quality great value</td>\n",
       "      <td>0</td>\n",
       "      <td>[great, quality, great, value]</td>\n",
       "      <td>[-0.00732421875, 0.141259765625, 0.03442382812...</td>\n",
       "      <td>[-0.00732421875, 0.141259765625, 0.03442382812...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reviews  Labels  \\\n",
       "1163606  excellent pen actually pen like use write anyt...       0   \n",
       "2069284  fresh set battery nice strong beam unfortunate...       2   \n",
       "338411                  file folder label great use folder       0   \n",
       "37088    work 's well heavy duty steel original stapler...       2   \n",
       "752649                           great quality great value       0   \n",
       "\n",
       "                                                 MyReviews  \\\n",
       "1163606  [excellent, pen, actually, pen, like, use, wri...   \n",
       "2069284  [fresh, set, battery, nice, strong, beam, unfo...   \n",
       "338411           [file, folder, label, great, use, folder]   \n",
       "37088    [work, 's, well, heavy, duty, steel, original,...   \n",
       "752649                      [great, quality, great, value]   \n",
       "\n",
       "                                                  gvectors  \\\n",
       "1163606  [0.013108995225694444, -0.015750461154513888, ...   \n",
       "2069284  [0.035248976487379804, 0.09482046274038461, 0....   \n",
       "338411   [0.11321149553571429, 0.029767717633928572, -0...   \n",
       "37088    [0.07191051136363637, 0.07883522727272728, -0....   \n",
       "752649   [-0.00732421875, 0.141259765625, 0.03442382812...   \n",
       "\n",
       "                                                  cvectors  \n",
       "1163606  [0.013108995225694444, -0.015750461154513888, ...  \n",
       "2069284  [0.035248976487379804, 0.09482046274038461, 0....  \n",
       "338411   [0.11321149553571429, 0.029767717633928572, -0...  \n",
       "37088    [0.07191051136363637, 0.07883522727272728, -0....  \n",
       "752649   [-0.00732421875, 0.141259765625, 0.03442382812...  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terframes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pre-trained Word2Vec for Concatenanting Extracted Features in Ternary Data Set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are preparing the concatenated vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Labels</th>\n",
       "      <th>MyReviews</th>\n",
       "      <th>gvectors</th>\n",
       "      <th>cvectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1163606</th>\n",
       "      <td>excellent pen actually pen like use write anyt...</td>\n",
       "      <td>0</td>\n",
       "      <td>[excellent, pen, actually, pen, like, use, wri...</td>\n",
       "      <td>[0.013108995225694444, -0.015750461154513888, ...</td>\n",
       "      <td>[0.013108995225694444, -0.015750461154513888, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069284</th>\n",
       "      <td>fresh set battery nice strong beam unfortunate...</td>\n",
       "      <td>2</td>\n",
       "      <td>[fresh, set, battery, nice, strong, beam, unfo...</td>\n",
       "      <td>[0.035248976487379804, 0.09482046274038461, 0....</td>\n",
       "      <td>[0.035248976487379804, 0.09482046274038461, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338411</th>\n",
       "      <td>file folder label great use folder</td>\n",
       "      <td>0</td>\n",
       "      <td>[file, folder, label, great, use, folder]</td>\n",
       "      <td>[0.11321149553571429, 0.029767717633928572, -0...</td>\n",
       "      <td>[0.11321149553571429, 0.029767717633928572, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37088</th>\n",
       "      <td>work 's well heavy duty steel original stapler...</td>\n",
       "      <td>2</td>\n",
       "      <td>[work, 's, well, heavy, duty, steel, original,...</td>\n",
       "      <td>[0.07191051136363637, 0.07883522727272728, -0....</td>\n",
       "      <td>[0.07191051136363637, 0.07883522727272728, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752649</th>\n",
       "      <td>great quality great value</td>\n",
       "      <td>0</td>\n",
       "      <td>[great, quality, great, value]</td>\n",
       "      <td>[-0.00732421875, 0.141259765625, 0.03442382812...</td>\n",
       "      <td>[-0.00732421875, 0.141259765625, 0.03442382812...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reviews  Labels  \\\n",
       "1163606  excellent pen actually pen like use write anyt...       0   \n",
       "2069284  fresh set battery nice strong beam unfortunate...       2   \n",
       "338411                  file folder label great use folder       0   \n",
       "37088    work 's well heavy duty steel original stapler...       2   \n",
       "752649                           great quality great value       0   \n",
       "\n",
       "                                                 MyReviews  \\\n",
       "1163606  [excellent, pen, actually, pen, like, use, wri...   \n",
       "2069284  [fresh, set, battery, nice, strong, beam, unfo...   \n",
       "338411           [file, folder, label, great, use, folder]   \n",
       "37088    [work, 's, well, heavy, duty, steel, original,...   \n",
       "752649                      [great, quality, great, value]   \n",
       "\n",
       "                                                  gvectors  \\\n",
       "1163606  [0.013108995225694444, -0.015750461154513888, ...   \n",
       "2069284  [0.035248976487379804, 0.09482046274038461, 0....   \n",
       "338411   [0.11321149553571429, 0.029767717633928572, -0...   \n",
       "37088    [0.07191051136363637, 0.07883522727272728, -0....   \n",
       "752649   [-0.00732421875, 0.141259765625, 0.03442382812...   \n",
       "\n",
       "                                                  cvectors  \n",
       "1163606  [0.013108995225694444, -0.015750461154513888, ...  \n",
       "2069284  [0.035248976487379804, 0.09482046274038461, 0....  \n",
       "338411   [0.11321149553571429, 0.029767717633928572, -0...  \n",
       "37088    [0.07191051136363637, 0.07883522727272728, -0....  \n",
       "752649   [-0.00732421875, 0.141259765625, 0.03442382812...  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terframes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = KeyedVectors.load(temporary_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Labels</th>\n",
       "      <th>MyReviews</th>\n",
       "      <th>gvectors</th>\n",
       "      <th>cvectors</th>\n",
       "      <th>congvectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1163606</th>\n",
       "      <td>excellent pen actually pen like use write anyt...</td>\n",
       "      <td>0</td>\n",
       "      <td>[excellent, pen, actually, pen, like, use, wri...</td>\n",
       "      <td>[0.013108995225694444, -0.015750461154513888, ...</td>\n",
       "      <td>[0.013108995225694444, -0.015750461154513888, ...</td>\n",
       "      <td>[[-0.212890625, -0.004302978515625, -0.1806640...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069284</th>\n",
       "      <td>fresh set battery nice strong beam unfortunate...</td>\n",
       "      <td>2</td>\n",
       "      <td>[fresh, set, battery, nice, strong, beam, unfo...</td>\n",
       "      <td>[0.035248976487379804, 0.09482046274038461, 0....</td>\n",
       "      <td>[0.035248976487379804, 0.09482046274038461, 0....</td>\n",
       "      <td>[[-0.042236328, 0.018066406, 0.22070312, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338411</th>\n",
       "      <td>file folder label great use folder</td>\n",
       "      <td>0</td>\n",
       "      <td>[file, folder, label, great, use, folder]</td>\n",
       "      <td>[0.11321149553571429, 0.029767717633928572, -0...</td>\n",
       "      <td>[0.11321149553571429, 0.029767717633928572, -0...</td>\n",
       "      <td>[[0.28515625, 0.023193359375, -0.03173828125, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37088</th>\n",
       "      <td>work 's well heavy duty steel original stapler...</td>\n",
       "      <td>2</td>\n",
       "      <td>[work, 's, well, heavy, duty, steel, original,...</td>\n",
       "      <td>[0.07191051136363637, 0.07883522727272728, -0....</td>\n",
       "      <td>[0.07191051136363637, 0.07883522727272728, -0....</td>\n",
       "      <td>[[-0.075683594, 0.033691406, -0.064941406, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752649</th>\n",
       "      <td>great quality great value</td>\n",
       "      <td>0</td>\n",
       "      <td>[great, quality, great, value]</td>\n",
       "      <td>[-0.00732421875, 0.141259765625, 0.03442382812...</td>\n",
       "      <td>[-0.00732421875, 0.141259765625, 0.03442382812...</td>\n",
       "      <td>[[0.07177734375, 0.2080078125, -0.028442382812...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reviews  Labels  \\\n",
       "1163606  excellent pen actually pen like use write anyt...       0   \n",
       "2069284  fresh set battery nice strong beam unfortunate...       2   \n",
       "338411                  file folder label great use folder       0   \n",
       "37088    work 's well heavy duty steel original stapler...       2   \n",
       "752649                           great quality great value       0   \n",
       "\n",
       "                                                 MyReviews  \\\n",
       "1163606  [excellent, pen, actually, pen, like, use, wri...   \n",
       "2069284  [fresh, set, battery, nice, strong, beam, unfo...   \n",
       "338411           [file, folder, label, great, use, folder]   \n",
       "37088    [work, 's, well, heavy, duty, steel, original,...   \n",
       "752649                      [great, quality, great, value]   \n",
       "\n",
       "                                                  gvectors  \\\n",
       "1163606  [0.013108995225694444, -0.015750461154513888, ...   \n",
       "2069284  [0.035248976487379804, 0.09482046274038461, 0....   \n",
       "338411   [0.11321149553571429, 0.029767717633928572, -0...   \n",
       "37088    [0.07191051136363637, 0.07883522727272728, -0....   \n",
       "752649   [-0.00732421875, 0.141259765625, 0.03442382812...   \n",
       "\n",
       "                                                  cvectors  \\\n",
       "1163606  [0.013108995225694444, -0.015750461154513888, ...   \n",
       "2069284  [0.035248976487379804, 0.09482046274038461, 0....   \n",
       "338411   [0.11321149553571429, 0.029767717633928572, -0...   \n",
       "37088    [0.07191051136363637, 0.07883522727272728, -0....   \n",
       "752649   [-0.00732421875, 0.141259765625, 0.03442382812...   \n",
       "\n",
       "                                               congvectors  \n",
       "1163606  [[-0.212890625, -0.004302978515625, -0.1806640...  \n",
       "2069284  [[-0.042236328, 0.018066406, 0.22070312, -0.01...  \n",
       "338411   [[0.28515625, 0.023193359375, -0.03173828125, ...  \n",
       "37088    [[-0.075683594, 0.033691406, -0.064941406, 0.1...  \n",
       "752649   [[0.07177734375, 0.2080078125, -0.028442382812...  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting Word Embeddings from the Pre-trained Model\n",
    "\n",
    "def embeddingFun(sent):\n",
    "    vectorsize = new_model.vector_size\n",
    "    PT_Embeddings_temp = np.zeros(vectorsize)\n",
    "    PT_Embeddings = []\n",
    "    c=0\n",
    "    pad_value=0\n",
    "    desired_length=300\n",
    "    \n",
    "    for word in sent:\n",
    "        if word in new_model:\n",
    "            PT_Embeddings_temp=wv[word]\n",
    "        if c in range(0,10):\n",
    "            PT_Embeddings.append(PT_Embeddings_temp)\n",
    "            c+=1\n",
    "    \n",
    "    PT_Embeddings = padding(PT_Embeddings, pad_value, desired_length)\n",
    "    return np.array(PT_Embeddings)\n",
    "        \n",
    "terframes['congvectors']=terframes['MyReviews'].apply(embeddingFun)\n",
    "terframes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Custom Word2Vec for Concatenanting Extracted Features in Ternary Data Set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are preparing the concatenated vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the word vectors from the previously custom trained model\n",
    "wvcon = KeyedVectors.load(\"word2vec.wordvectors\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Labels</th>\n",
       "      <th>MyReviews</th>\n",
       "      <th>gvectors</th>\n",
       "      <th>cvectors</th>\n",
       "      <th>congvectors</th>\n",
       "      <th>concvectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1163606</th>\n",
       "      <td>excellent pen actually pen like use write anyt...</td>\n",
       "      <td>0</td>\n",
       "      <td>[excellent, pen, actually, pen, like, use, wri...</td>\n",
       "      <td>[0.013108995225694444, -0.015750461154513888, ...</td>\n",
       "      <td>[0.013108995225694444, -0.015750461154513888, ...</td>\n",
       "      <td>[[-0.212890625, -0.004302978515625, -0.1806640...</td>\n",
       "      <td>[[0.1381412297487259, -0.06316769868135452, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069284</th>\n",
       "      <td>fresh set battery nice strong beam unfortunate...</td>\n",
       "      <td>2</td>\n",
       "      <td>[fresh, set, battery, nice, strong, beam, unfo...</td>\n",
       "      <td>[0.035248976487379804, 0.09482046274038461, 0....</td>\n",
       "      <td>[0.035248976487379804, 0.09482046274038461, 0....</td>\n",
       "      <td>[[-0.042236328, 0.018066406, 0.22070312, -0.01...</td>\n",
       "      <td>[[0.120346084, 0.057084102, -0.09761257, -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338411</th>\n",
       "      <td>file folder label great use folder</td>\n",
       "      <td>0</td>\n",
       "      <td>[file, folder, label, great, use, folder]</td>\n",
       "      <td>[0.11321149553571429, 0.029767717633928572, -0...</td>\n",
       "      <td>[0.11321149553571429, 0.029767717633928572, -0...</td>\n",
       "      <td>[[0.28515625, 0.023193359375, -0.03173828125, ...</td>\n",
       "      <td>[[-0.12393734604120255, 0.06283459812402725, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37088</th>\n",
       "      <td>work 's well heavy duty steel original stapler...</td>\n",
       "      <td>2</td>\n",
       "      <td>[work, 's, well, heavy, duty, steel, original,...</td>\n",
       "      <td>[0.07191051136363637, 0.07883522727272728, -0....</td>\n",
       "      <td>[0.07191051136363637, 0.07883522727272728, -0....</td>\n",
       "      <td>[[-0.075683594, 0.033691406, -0.064941406, 0.1...</td>\n",
       "      <td>[[0.04482966, -0.032019116, 0.06074907, 0.0353...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752649</th>\n",
       "      <td>great quality great value</td>\n",
       "      <td>0</td>\n",
       "      <td>[great, quality, great, value]</td>\n",
       "      <td>[-0.00732421875, 0.141259765625, 0.03442382812...</td>\n",
       "      <td>[-0.00732421875, 0.141259765625, 0.03442382812...</td>\n",
       "      <td>[[0.07177734375, 0.2080078125, -0.028442382812...</td>\n",
       "      <td>[[-0.006137721240520477, -0.06911127269268036,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reviews  Labels  \\\n",
       "1163606  excellent pen actually pen like use write anyt...       0   \n",
       "2069284  fresh set battery nice strong beam unfortunate...       2   \n",
       "338411                  file folder label great use folder       0   \n",
       "37088    work 's well heavy duty steel original stapler...       2   \n",
       "752649                           great quality great value       0   \n",
       "\n",
       "                                                 MyReviews  \\\n",
       "1163606  [excellent, pen, actually, pen, like, use, wri...   \n",
       "2069284  [fresh, set, battery, nice, strong, beam, unfo...   \n",
       "338411           [file, folder, label, great, use, folder]   \n",
       "37088    [work, 's, well, heavy, duty, steel, original,...   \n",
       "752649                      [great, quality, great, value]   \n",
       "\n",
       "                                                  gvectors  \\\n",
       "1163606  [0.013108995225694444, -0.015750461154513888, ...   \n",
       "2069284  [0.035248976487379804, 0.09482046274038461, 0....   \n",
       "338411   [0.11321149553571429, 0.029767717633928572, -0...   \n",
       "37088    [0.07191051136363637, 0.07883522727272728, -0....   \n",
       "752649   [-0.00732421875, 0.141259765625, 0.03442382812...   \n",
       "\n",
       "                                                  cvectors  \\\n",
       "1163606  [0.013108995225694444, -0.015750461154513888, ...   \n",
       "2069284  [0.035248976487379804, 0.09482046274038461, 0....   \n",
       "338411   [0.11321149553571429, 0.029767717633928572, -0...   \n",
       "37088    [0.07191051136363637, 0.07883522727272728, -0....   \n",
       "752649   [-0.00732421875, 0.141259765625, 0.03442382812...   \n",
       "\n",
       "                                               congvectors  \\\n",
       "1163606  [[-0.212890625, -0.004302978515625, -0.1806640...   \n",
       "2069284  [[-0.042236328, 0.018066406, 0.22070312, -0.01...   \n",
       "338411   [[0.28515625, 0.023193359375, -0.03173828125, ...   \n",
       "37088    [[-0.075683594, 0.033691406, -0.064941406, 0.1...   \n",
       "752649   [[0.07177734375, 0.2080078125, -0.028442382812...   \n",
       "\n",
       "                                               concvectors  \n",
       "1163606  [[0.1381412297487259, -0.06316769868135452, 0....  \n",
       "2069284  [[0.120346084, 0.057084102, -0.09761257, -0.03...  \n",
       "338411   [[-0.12393734604120255, 0.06283459812402725, -...  \n",
       "37088    [[0.04482966, -0.032019116, 0.06074907, 0.0353...  \n",
       "752649   [[-0.006137721240520477, -0.06911127269268036,...  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting Word Embeddings from the Pre-trained Model\n",
    "\n",
    "def embeddingFun(sent):\n",
    "    vectorsize = new_model.vector_size\n",
    "    CM_Embeddings_temp = np.zeros(vectorsize)\n",
    "    CM_Embeddings = []\n",
    "    c=0\n",
    "    pad_value=0\n",
    "    desired_length=300\n",
    "    \n",
    "    for word in sent:\n",
    "        if word in wvcon:\n",
    "            CM_Embeddings_temp=wvcon[word]\n",
    "        if c in range(0,10):\n",
    "            CM_Embeddings.append(CM_Embeddings_temp)\n",
    "            c+=1\n",
    "    \n",
    "    CM_Embeddings = padding(CM_Embeddings, pad_value, desired_length)\n",
    "    return np.array(CM_Embeddings)\n",
    "        \n",
    "terframes['concvectors']=terframes['MyReviews'].apply(embeddingFun)\n",
    "terframes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNN Using Features extracted from Pre-trained Avg Word2Vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the Feedforward Neural Network is used for the Ternary Classification, where the feature extracter is the Pre-trained Gensim Word2Vec model and the vector for a review is the Average of the vectors for each word in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 80-20 train-test\n",
    "x_train, x_test, y_train, y_test = train_test_split(terframes['gvectors'], terframes['Labels'], test_size=0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting NumPy arrays to TensorFlow tensors\n",
    "X_train_tf = tf.convert_to_tensor(x_train.to_list(), dtype=tf.float32)\n",
    "y_train_tf = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "X_test_tf = tf.convert_to_tensor(x_test.to_list(), dtype=tf.float32)\n",
    "y_test_tf = tf.convert_to_tensor(y_test, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network_5 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation='relu', input_shape=(300,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the neural network\n",
    "neural_network_5.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3750/3750 [==============================] - 2s 401us/step - loss: 0.8060 - accuracy: 0.6350\n",
      "Epoch 2/100\n",
      "3750/3750 [==============================] - 2s 402us/step - loss: 0.7695 - accuracy: 0.6550\n",
      "Epoch 3/100\n",
      "3750/3750 [==============================] - 2s 427us/step - loss: 0.7558 - accuracy: 0.6606\n",
      "Epoch 4/100\n",
      "3750/3750 [==============================] - 2s 402us/step - loss: 0.7461 - accuracy: 0.6652\n",
      "Epoch 5/100\n",
      "3750/3750 [==============================] - 2s 404us/step - loss: 0.7376 - accuracy: 0.6694\n",
      "Epoch 6/100\n",
      "3750/3750 [==============================] - 2s 404us/step - loss: 0.7301 - accuracy: 0.6719\n",
      "Epoch 7/100\n",
      "3750/3750 [==============================] - 2s 400us/step - loss: 0.7233 - accuracy: 0.6760\n",
      "Epoch 8/100\n",
      "3750/3750 [==============================] - 2s 414us/step - loss: 0.7175 - accuracy: 0.6799\n",
      "Epoch 9/100\n",
      "3750/3750 [==============================] - 2s 425us/step - loss: 0.7130 - accuracy: 0.6811\n",
      "Epoch 10/100\n",
      "3750/3750 [==============================] - 2s 404us/step - loss: 0.7080 - accuracy: 0.6842\n",
      "Epoch 11/100\n",
      "3750/3750 [==============================] - 1s 398us/step - loss: 0.7047 - accuracy: 0.6856\n",
      "Epoch 12/100\n",
      "3750/3750 [==============================] - 1s 399us/step - loss: 0.7010 - accuracy: 0.6877\n",
      "Epoch 13/100\n",
      "3750/3750 [==============================] - 2s 403us/step - loss: 0.6979 - accuracy: 0.6897\n",
      "Epoch 14/100\n",
      "3750/3750 [==============================] - 2s 426us/step - loss: 0.6953 - accuracy: 0.6910\n",
      "Epoch 15/100\n",
      "3750/3750 [==============================] - 2s 408us/step - loss: 0.6912 - accuracy: 0.6938\n",
      "Epoch 16/100\n",
      "3750/3750 [==============================] - 2s 405us/step - loss: 0.6888 - accuracy: 0.6939\n",
      "Epoch 17/100\n",
      "3750/3750 [==============================] - 2s 427us/step - loss: 0.6859 - accuracy: 0.6961\n",
      "Epoch 18/100\n",
      "3750/3750 [==============================] - 2s 410us/step - loss: 0.6837 - accuracy: 0.6962\n",
      "Epoch 19/100\n",
      "3750/3750 [==============================] - 2s 428us/step - loss: 0.6805 - accuracy: 0.6982\n",
      "Epoch 20/100\n",
      "3750/3750 [==============================] - 2s 408us/step - loss: 0.6784 - accuracy: 0.7006\n",
      "Epoch 21/100\n",
      "3750/3750 [==============================] - 2s 407us/step - loss: 0.6763 - accuracy: 0.7011\n",
      "Epoch 22/100\n",
      "3750/3750 [==============================] - 2s 441us/step - loss: 0.6745 - accuracy: 0.7022\n",
      "Epoch 23/100\n",
      "3750/3750 [==============================] - 1s 395us/step - loss: 0.6723 - accuracy: 0.7033\n",
      "Epoch 24/100\n",
      "3750/3750 [==============================] - 1s 391us/step - loss: 0.6696 - accuracy: 0.7039\n",
      "Epoch 25/100\n",
      "3750/3750 [==============================] - 1s 392us/step - loss: 0.6684 - accuracy: 0.7050\n",
      "Epoch 26/100\n",
      "3750/3750 [==============================] - 2s 431us/step - loss: 0.6670 - accuracy: 0.7062\n",
      "Epoch 27/100\n",
      "3750/3750 [==============================] - 1s 396us/step - loss: 0.6648 - accuracy: 0.7076\n",
      "Epoch 28/100\n",
      "3750/3750 [==============================] - 1s 396us/step - loss: 0.6635 - accuracy: 0.7071\n",
      "Epoch 29/100\n",
      "3750/3750 [==============================] - 2s 423us/step - loss: 0.6617 - accuracy: 0.7089\n",
      "Epoch 30/100\n",
      "3750/3750 [==============================] - 2s 407us/step - loss: 0.6594 - accuracy: 0.7094\n",
      "Epoch 31/100\n",
      "3750/3750 [==============================] - 2s 426us/step - loss: 0.6587 - accuracy: 0.7103\n",
      "Epoch 32/100\n",
      "3750/3750 [==============================] - 2s 405us/step - loss: 0.6568 - accuracy: 0.7118\n",
      "Epoch 33/100\n",
      "3750/3750 [==============================] - 2s 433us/step - loss: 0.6557 - accuracy: 0.7125\n",
      "Epoch 34/100\n",
      "3750/3750 [==============================] - 2s 425us/step - loss: 0.6549 - accuracy: 0.7127\n",
      "Epoch 35/100\n",
      "3750/3750 [==============================] - 2s 449us/step - loss: 0.6534 - accuracy: 0.7131\n",
      "Epoch 36/100\n",
      "3750/3750 [==============================] - 2s 406us/step - loss: 0.6519 - accuracy: 0.7135\n",
      "Epoch 37/100\n",
      "3750/3750 [==============================] - 2s 408us/step - loss: 0.6504 - accuracy: 0.7151\n",
      "Epoch 38/100\n",
      "3750/3750 [==============================] - 2s 427us/step - loss: 0.6495 - accuracy: 0.7154\n",
      "Epoch 39/100\n",
      "3750/3750 [==============================] - 1s 400us/step - loss: 0.6481 - accuracy: 0.7159\n",
      "Epoch 40/100\n",
      "3750/3750 [==============================] - 2s 402us/step - loss: 0.6470 - accuracy: 0.7162\n",
      "Epoch 41/100\n",
      "3750/3750 [==============================] - 2s 429us/step - loss: 0.6456 - accuracy: 0.7164\n",
      "Epoch 42/100\n",
      "3750/3750 [==============================] - 2s 406us/step - loss: 0.6448 - accuracy: 0.7182\n",
      "Epoch 43/100\n",
      "3750/3750 [==============================] - 2s 412us/step - loss: 0.6434 - accuracy: 0.7182\n",
      "Epoch 44/100\n",
      "3750/3750 [==============================] - 2s 420us/step - loss: 0.6430 - accuracy: 0.7180\n",
      "Epoch 45/100\n",
      "3750/3750 [==============================] - 2s 413us/step - loss: 0.6415 - accuracy: 0.7188\n",
      "Epoch 46/100\n",
      "3750/3750 [==============================] - 2s 402us/step - loss: 0.6405 - accuracy: 0.7199\n",
      "Epoch 47/100\n",
      "3750/3750 [==============================] - 2s 401us/step - loss: 0.6397 - accuracy: 0.7205\n",
      "Epoch 48/100\n",
      "3750/3750 [==============================] - 2s 406us/step - loss: 0.6389 - accuracy: 0.7205\n",
      "Epoch 49/100\n",
      "3750/3750 [==============================] - 2s 406us/step - loss: 0.6377 - accuracy: 0.7209\n",
      "Epoch 50/100\n",
      "3750/3750 [==============================] - 2s 423us/step - loss: 0.6372 - accuracy: 0.7211\n",
      "Epoch 51/100\n",
      "3750/3750 [==============================] - 1s 400us/step - loss: 0.6360 - accuracy: 0.7214\n",
      "Epoch 52/100\n",
      "3750/3750 [==============================] - 2s 406us/step - loss: 0.6351 - accuracy: 0.7228\n",
      "Epoch 53/100\n",
      "3750/3750 [==============================] - 2s 402us/step - loss: 0.6339 - accuracy: 0.7229\n",
      "Epoch 54/100\n",
      "3750/3750 [==============================] - 2s 423us/step - loss: 0.6337 - accuracy: 0.7230\n",
      "Epoch 55/100\n",
      "3750/3750 [==============================] - 2s 401us/step - loss: 0.6326 - accuracy: 0.7227\n",
      "Epoch 56/100\n",
      "3750/3750 [==============================] - 2s 401us/step - loss: 0.6321 - accuracy: 0.7243\n",
      "Epoch 57/100\n",
      "3750/3750 [==============================] - 2s 403us/step - loss: 0.6313 - accuracy: 0.7232\n",
      "Epoch 58/100\n",
      "3750/3750 [==============================] - 2s 400us/step - loss: 0.6308 - accuracy: 0.7251\n",
      "Epoch 59/100\n",
      "3750/3750 [==============================] - 2s 400us/step - loss: 0.6297 - accuracy: 0.7255\n",
      "Epoch 60/100\n",
      "3750/3750 [==============================] - 2s 434us/step - loss: 0.6294 - accuracy: 0.7249\n",
      "Epoch 61/100\n",
      "3750/3750 [==============================] - 2s 406us/step - loss: 0.6285 - accuracy: 0.7257\n",
      "Epoch 62/100\n",
      "3750/3750 [==============================] - 2s 408us/step - loss: 0.6279 - accuracy: 0.7248\n",
      "Epoch 63/100\n",
      "3750/3750 [==============================] - 2s 408us/step - loss: 0.6275 - accuracy: 0.7266\n",
      "Epoch 64/100\n",
      "3750/3750 [==============================] - 2s 427us/step - loss: 0.6262 - accuracy: 0.7268\n",
      "Epoch 65/100\n",
      "3750/3750 [==============================] - 2s 421us/step - loss: 0.6261 - accuracy: 0.7266\n",
      "Epoch 66/100\n",
      "3750/3750 [==============================] - 2s 404us/step - loss: 0.6248 - accuracy: 0.7263\n",
      "Epoch 67/100\n",
      "3750/3750 [==============================] - 2s 407us/step - loss: 0.6243 - accuracy: 0.7283\n",
      "Epoch 68/100\n",
      "3750/3750 [==============================] - 2s 429us/step - loss: 0.6240 - accuracy: 0.7277\n",
      "Epoch 69/100\n",
      "3750/3750 [==============================] - 2s 417us/step - loss: 0.6236 - accuracy: 0.7278\n",
      "Epoch 70/100\n",
      "3750/3750 [==============================] - 2s 418us/step - loss: 0.6226 - accuracy: 0.7296\n",
      "Epoch 71/100\n",
      "3750/3750 [==============================] - 2s 442us/step - loss: 0.6222 - accuracy: 0.7284\n",
      "Epoch 72/100\n",
      "3750/3750 [==============================] - 2s 411us/step - loss: 0.6218 - accuracy: 0.7289\n",
      "Epoch 73/100\n",
      "3750/3750 [==============================] - 2s 434us/step - loss: 0.6210 - accuracy: 0.7287\n",
      "Epoch 74/100\n",
      "3750/3750 [==============================] - 2s 410us/step - loss: 0.6208 - accuracy: 0.7300\n",
      "Epoch 75/100\n",
      "3750/3750 [==============================] - 2s 406us/step - loss: 0.6202 - accuracy: 0.7297\n",
      "Epoch 76/100\n",
      "3750/3750 [==============================] - 2s 406us/step - loss: 0.6196 - accuracy: 0.7291\n",
      "Epoch 77/100\n",
      "3750/3750 [==============================] - 2s 430us/step - loss: 0.6193 - accuracy: 0.7303\n",
      "Epoch 78/100\n",
      "3750/3750 [==============================] - 2s 413us/step - loss: 0.6185 - accuracy: 0.7316\n",
      "Epoch 79/100\n",
      "3750/3750 [==============================] - 2s 431us/step - loss: 0.6179 - accuracy: 0.7309\n",
      "Epoch 80/100\n",
      "3750/3750 [==============================] - 2s 405us/step - loss: 0.6175 - accuracy: 0.7303\n",
      "Epoch 81/100\n",
      "3750/3750 [==============================] - 2s 402us/step - loss: 0.6167 - accuracy: 0.7310\n",
      "Epoch 82/100\n",
      "3750/3750 [==============================] - 2s 429us/step - loss: 0.6171 - accuracy: 0.7313\n",
      "Epoch 83/100\n",
      "3750/3750 [==============================] - 2s 440us/step - loss: 0.6162 - accuracy: 0.7312\n",
      "Epoch 84/100\n",
      "3750/3750 [==============================] - 2s 413us/step - loss: 0.6164 - accuracy: 0.7306\n",
      "Epoch 85/100\n",
      "3750/3750 [==============================] - 2s 432us/step - loss: 0.6150 - accuracy: 0.7314\n",
      "Epoch 86/100\n",
      "3750/3750 [==============================] - 2s 406us/step - loss: 0.6146 - accuracy: 0.7307\n",
      "Epoch 87/100\n",
      "3750/3750 [==============================] - 2s 438us/step - loss: 0.6139 - accuracy: 0.7325\n",
      "Epoch 88/100\n",
      "3750/3750 [==============================] - 2s 430us/step - loss: 0.6139 - accuracy: 0.7324\n",
      "Epoch 89/100\n",
      "3750/3750 [==============================] - 2s 435us/step - loss: 0.6131 - accuracy: 0.7323\n",
      "Epoch 90/100\n",
      "3750/3750 [==============================] - 2s 409us/step - loss: 0.6128 - accuracy: 0.7329\n",
      "Epoch 91/100\n",
      "3750/3750 [==============================] - 2s 408us/step - loss: 0.6121 - accuracy: 0.7329\n",
      "Epoch 92/100\n",
      "3750/3750 [==============================] - 2s 431us/step - loss: 0.6116 - accuracy: 0.7331\n",
      "Epoch 93/100\n",
      "3750/3750 [==============================] - 2s 405us/step - loss: 0.6122 - accuracy: 0.7327\n",
      "Epoch 94/100\n",
      "3750/3750 [==============================] - 2s 411us/step - loss: 0.6116 - accuracy: 0.7341\n",
      "Epoch 95/100\n",
      "3750/3750 [==============================] - 2s 429us/step - loss: 0.6118 - accuracy: 0.7335\n",
      "Epoch 96/100\n",
      "3750/3750 [==============================] - 2s 405us/step - loss: 0.6106 - accuracy: 0.7339\n",
      "Epoch 97/100\n",
      "3750/3750 [==============================] - 2s 403us/step - loss: 0.6099 - accuracy: 0.7358\n",
      "Epoch 98/100\n",
      "3750/3750 [==============================] - 2s 434us/step - loss: 0.6104 - accuracy: 0.7343\n",
      "Epoch 99/100\n",
      "3750/3750 [==============================] - 2s 410us/step - loss: 0.6098 - accuracy: 0.7343\n",
      "Epoch 100/100\n",
      "3750/3750 [==============================] - 2s 428us/step - loss: 0.6092 - accuracy: 0.7341\n"
     ]
    }
   ],
   "source": [
    "# Training the neural network\n",
    "history5 = neural_network_5.fit(X_train_tf, y_train_tf, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 0s 304us/step - loss: 0.8378 - accuracy: 0.6428\n",
      "Test accuracy: 0.642799973487854\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the neural network on the test set\n",
    "test_loss, test_acc = neural_network_5.evaluate(X_test_tf, y_test_tf)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Table[10].append(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNN Using Features extracted from Custom Avg Word2Vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the Feedforward Neural Network is used for the Ternary Classification, where the feature extracter is the Custom Word2Vec model and the vector for a review is the Average of the vectors for each word in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 80-20 train-test\n",
    "x_train, x_test, y_train, y_test = train_test_split(terframes['cvectors'], terframes['Labels'], test_size=0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting NumPy arrays to TensorFlow tensors\n",
    "X_train_tf = tf.convert_to_tensor(x_train.to_list(), dtype=tf.float32)\n",
    "y_train_tf = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "X_test_tf = tf.convert_to_tensor(x_test.to_list(), dtype=tf.float32)\n",
    "y_test_tf = tf.convert_to_tensor(y_test, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network_6 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation='relu', input_shape=(300,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the neural network\n",
    "neural_network_6.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3750/3750 [==============================] - 2s 410us/step - loss: 0.8057 - accuracy: 0.6346\n",
      "Epoch 2/100\n",
      "3750/3750 [==============================] - 2s 404us/step - loss: 0.7651 - accuracy: 0.6552\n",
      "Epoch 3/100\n",
      "3750/3750 [==============================] - 2s 424us/step - loss: 0.7518 - accuracy: 0.6618\n",
      "Epoch 4/100\n",
      "3750/3750 [==============================] - 2s 403us/step - loss: 0.7417 - accuracy: 0.6668\n",
      "Epoch 5/100\n",
      "3750/3750 [==============================] - 2s 414us/step - loss: 0.7334 - accuracy: 0.6703\n",
      "Epoch 6/100\n",
      "3750/3750 [==============================] - 2s 407us/step - loss: 0.7272 - accuracy: 0.6741\n",
      "Epoch 7/100\n",
      "3750/3750 [==============================] - 2s 403us/step - loss: 0.7215 - accuracy: 0.6763\n",
      "Epoch 8/100\n",
      "3750/3750 [==============================] - 2s 404us/step - loss: 0.7166 - accuracy: 0.6806\n",
      "Epoch 9/100\n",
      "3750/3750 [==============================] - 2s 439us/step - loss: 0.7120 - accuracy: 0.6804\n",
      "Epoch 10/100\n",
      "3750/3750 [==============================] - 2s 409us/step - loss: 0.7074 - accuracy: 0.6844\n",
      "Epoch 11/100\n",
      "3750/3750 [==============================] - 2s 406us/step - loss: 0.7032 - accuracy: 0.6871\n",
      "Epoch 12/100\n",
      "3750/3750 [==============================] - 2s 433us/step - loss: 0.6996 - accuracy: 0.6881\n",
      "Epoch 13/100\n",
      "3750/3750 [==============================] - 2s 412us/step - loss: 0.6962 - accuracy: 0.6896\n",
      "Epoch 14/100\n",
      "3750/3750 [==============================] - 2s 410us/step - loss: 0.6935 - accuracy: 0.6918\n",
      "Epoch 15/100\n",
      "3750/3750 [==============================] - 2s 429us/step - loss: 0.6898 - accuracy: 0.6932\n",
      "Epoch 16/100\n",
      "3750/3750 [==============================] - 2s 412us/step - loss: 0.6868 - accuracy: 0.6950\n",
      "Epoch 17/100\n",
      "3750/3750 [==============================] - 2s 410us/step - loss: 0.6838 - accuracy: 0.6959\n",
      "Epoch 18/100\n",
      "3750/3750 [==============================] - 2s 411us/step - loss: 0.6817 - accuracy: 0.6984\n",
      "Epoch 19/100\n",
      "3750/3750 [==============================] - 2s 410us/step - loss: 0.6790 - accuracy: 0.6987\n",
      "Epoch 20/100\n",
      "3750/3750 [==============================] - 2s 425us/step - loss: 0.6769 - accuracy: 0.7005\n",
      "Epoch 21/100\n",
      "3750/3750 [==============================] - 2s 412us/step - loss: 0.6746 - accuracy: 0.7005\n",
      "Epoch 22/100\n",
      "3750/3750 [==============================] - 2s 412us/step - loss: 0.6722 - accuracy: 0.7025\n",
      "Epoch 23/100\n",
      "3750/3750 [==============================] - 2s 410us/step - loss: 0.6708 - accuracy: 0.7028\n",
      "Epoch 24/100\n",
      "3750/3750 [==============================] - 2s 424us/step - loss: 0.6687 - accuracy: 0.7043\n",
      "Epoch 25/100\n",
      "3750/3750 [==============================] - 2s 403us/step - loss: 0.6667 - accuracy: 0.7050\n",
      "Epoch 26/100\n",
      "3750/3750 [==============================] - 2s 405us/step - loss: 0.6650 - accuracy: 0.7067\n",
      "Epoch 27/100\n",
      "3750/3750 [==============================] - 2s 405us/step - loss: 0.6630 - accuracy: 0.7082\n",
      "Epoch 28/100\n",
      "3750/3750 [==============================] - 2s 405us/step - loss: 0.6621 - accuracy: 0.7076\n",
      "Epoch 29/100\n",
      "3750/3750 [==============================] - 2s 404us/step - loss: 0.6603 - accuracy: 0.7084\n",
      "Epoch 30/100\n",
      "3750/3750 [==============================] - 2s 404us/step - loss: 0.6586 - accuracy: 0.7096\n",
      "Epoch 31/100\n",
      "3750/3750 [==============================] - 2s 423us/step - loss: 0.6570 - accuracy: 0.7106\n",
      "Epoch 32/100\n",
      "3750/3750 [==============================] - 2s 406us/step - loss: 0.6555 - accuracy: 0.7111\n",
      "Epoch 33/100\n",
      "3750/3750 [==============================] - 2s 404us/step - loss: 0.6550 - accuracy: 0.7109\n",
      "Epoch 34/100\n",
      "3750/3750 [==============================] - 2s 404us/step - loss: 0.6526 - accuracy: 0.7120\n",
      "Epoch 35/100\n",
      "3750/3750 [==============================] - 2s 403us/step - loss: 0.6521 - accuracy: 0.7128\n",
      "Epoch 36/100\n",
      "3750/3750 [==============================] - 2s 406us/step - loss: 0.6504 - accuracy: 0.7126\n",
      "Epoch 37/100\n",
      "3750/3750 [==============================] - 2s 407us/step - loss: 0.6493 - accuracy: 0.7136\n",
      "Epoch 38/100\n",
      "3750/3750 [==============================] - 2s 424us/step - loss: 0.6479 - accuracy: 0.7144\n",
      "Epoch 39/100\n",
      "3750/3750 [==============================] - 2s 404us/step - loss: 0.6469 - accuracy: 0.7152\n",
      "Epoch 40/100\n",
      "3750/3750 [==============================] - 2s 421us/step - loss: 0.6457 - accuracy: 0.7154\n",
      "Epoch 41/100\n",
      "3750/3750 [==============================] - 2s 404us/step - loss: 0.6450 - accuracy: 0.7159\n",
      "Epoch 42/100\n",
      "3750/3750 [==============================] - 2s 410us/step - loss: 0.6446 - accuracy: 0.7158\n",
      "Epoch 43/100\n",
      "3750/3750 [==============================] - 2s 434us/step - loss: 0.6432 - accuracy: 0.7167\n",
      "Epoch 44/100\n",
      "3750/3750 [==============================] - 2s 409us/step - loss: 0.6415 - accuracy: 0.7184\n",
      "Epoch 45/100\n",
      "3750/3750 [==============================] - 2s 408us/step - loss: 0.6410 - accuracy: 0.7179\n",
      "Epoch 46/100\n",
      "3750/3750 [==============================] - 2s 405us/step - loss: 0.6402 - accuracy: 0.7187\n",
      "Epoch 47/100\n",
      "3750/3750 [==============================] - 2s 426us/step - loss: 0.6394 - accuracy: 0.7191\n",
      "Epoch 48/100\n",
      "3750/3750 [==============================] - 2s 408us/step - loss: 0.6380 - accuracy: 0.7191\n",
      "Epoch 49/100\n",
      "3750/3750 [==============================] - 2s 410us/step - loss: 0.6379 - accuracy: 0.7191\n",
      "Epoch 50/100\n",
      "3750/3750 [==============================] - 2s 406us/step - loss: 0.6366 - accuracy: 0.7196\n",
      "Epoch 51/100\n",
      "3750/3750 [==============================] - 2s 430us/step - loss: 0.6363 - accuracy: 0.7204\n",
      "Epoch 52/100\n",
      "3750/3750 [==============================] - 2s 413us/step - loss: 0.6348 - accuracy: 0.7211\n",
      "Epoch 53/100\n",
      "3750/3750 [==============================] - 2s 409us/step - loss: 0.6343 - accuracy: 0.7208\n",
      "Epoch 54/100\n",
      "3750/3750 [==============================] - 2s 405us/step - loss: 0.6335 - accuracy: 0.7221\n",
      "Epoch 55/100\n",
      "3750/3750 [==============================] - 2s 426us/step - loss: 0.6329 - accuracy: 0.7228\n",
      "Epoch 56/100\n",
      "3750/3750 [==============================] - 2s 407us/step - loss: 0.6321 - accuracy: 0.7224\n",
      "Epoch 57/100\n",
      "3750/3750 [==============================] - 2s 425us/step - loss: 0.6317 - accuracy: 0.7226\n",
      "Epoch 58/100\n",
      "3750/3750 [==============================] - 2s 443us/step - loss: 0.6306 - accuracy: 0.7237\n",
      "Epoch 59/100\n",
      "3750/3750 [==============================] - 2s 408us/step - loss: 0.6308 - accuracy: 0.7229\n",
      "Epoch 60/100\n",
      "3750/3750 [==============================] - 2s 401us/step - loss: 0.6299 - accuracy: 0.7240\n",
      "Epoch 61/100\n",
      "3750/3750 [==============================] - 2s 408us/step - loss: 0.6293 - accuracy: 0.7245\n",
      "Epoch 62/100\n",
      "3750/3750 [==============================] - 2s 407us/step - loss: 0.6282 - accuracy: 0.7243\n",
      "Epoch 63/100\n",
      "3750/3750 [==============================] - 2s 429us/step - loss: 0.6276 - accuracy: 0.7252\n",
      "Epoch 64/100\n",
      "3750/3750 [==============================] - 2s 406us/step - loss: 0.6270 - accuracy: 0.7245\n",
      "Epoch 65/100\n",
      "3750/3750 [==============================] - 2s 412us/step - loss: 0.6262 - accuracy: 0.7259\n",
      "Epoch 66/100\n",
      "3750/3750 [==============================] - 2s 431us/step - loss: 0.6260 - accuracy: 0.7254\n",
      "Epoch 67/100\n",
      "3750/3750 [==============================] - 2s 425us/step - loss: 0.6251 - accuracy: 0.7258\n",
      "Epoch 68/100\n",
      "3750/3750 [==============================] - 2s 462us/step - loss: 0.6242 - accuracy: 0.7263\n",
      "Epoch 69/100\n",
      "3750/3750 [==============================] - 2s 424us/step - loss: 0.6245 - accuracy: 0.7257\n",
      "Epoch 70/100\n",
      "3750/3750 [==============================] - 2s 413us/step - loss: 0.6240 - accuracy: 0.7270\n",
      "Epoch 71/100\n",
      "3750/3750 [==============================] - 2s 416us/step - loss: 0.6232 - accuracy: 0.7264\n",
      "Epoch 72/100\n",
      "3750/3750 [==============================] - 2s 435us/step - loss: 0.6231 - accuracy: 0.7271\n",
      "Epoch 73/100\n",
      "3750/3750 [==============================] - 2s 408us/step - loss: 0.6222 - accuracy: 0.7268\n",
      "Epoch 74/100\n",
      "3750/3750 [==============================] - 2s 409us/step - loss: 0.6216 - accuracy: 0.7275\n",
      "Epoch 75/100\n",
      "3750/3750 [==============================] - 2s 409us/step - loss: 0.6210 - accuracy: 0.7272\n",
      "Epoch 76/100\n",
      "3750/3750 [==============================] - 2s 409us/step - loss: 0.6205 - accuracy: 0.7287\n",
      "Epoch 77/100\n",
      "3750/3750 [==============================] - 2s 432us/step - loss: 0.6205 - accuracy: 0.7287\n",
      "Epoch 78/100\n",
      "3750/3750 [==============================] - 2s 414us/step - loss: 0.6196 - accuracy: 0.7293\n",
      "Epoch 79/100\n",
      "3750/3750 [==============================] - 2s 408us/step - loss: 0.6190 - accuracy: 0.7292\n",
      "Epoch 80/100\n",
      "3750/3750 [==============================] - 2s 408us/step - loss: 0.6192 - accuracy: 0.7294\n",
      "Epoch 81/100\n",
      "3750/3750 [==============================] - 2s 427us/step - loss: 0.6182 - accuracy: 0.7290\n",
      "Epoch 82/100\n",
      "3750/3750 [==============================] - 2s 408us/step - loss: 0.6178 - accuracy: 0.7297\n",
      "Epoch 83/100\n",
      "3750/3750 [==============================] - 2s 433us/step - loss: 0.6167 - accuracy: 0.7299\n",
      "Epoch 84/100\n",
      "3750/3750 [==============================] - 2s 412us/step - loss: 0.6168 - accuracy: 0.7307\n",
      "Epoch 85/100\n",
      "3750/3750 [==============================] - 2s 409us/step - loss: 0.6165 - accuracy: 0.7303\n",
      "Epoch 86/100\n",
      "3750/3750 [==============================] - 2s 409us/step - loss: 0.6159 - accuracy: 0.7301\n",
      "Epoch 87/100\n",
      "3750/3750 [==============================] - 2s 425us/step - loss: 0.6158 - accuracy: 0.7307\n",
      "Epoch 88/100\n",
      "3750/3750 [==============================] - 2s 410us/step - loss: 0.6156 - accuracy: 0.7309\n",
      "Epoch 89/100\n",
      "3750/3750 [==============================] - 2s 404us/step - loss: 0.6149 - accuracy: 0.7302\n",
      "Epoch 90/100\n",
      "3750/3750 [==============================] - 2s 415us/step - loss: 0.6143 - accuracy: 0.7305\n",
      "Epoch 91/100\n",
      "3750/3750 [==============================] - 2s 463us/step - loss: 0.6135 - accuracy: 0.7318\n",
      "Epoch 92/100\n",
      "3750/3750 [==============================] - 2s 419us/step - loss: 0.6140 - accuracy: 0.7311\n",
      "Epoch 93/100\n",
      "3750/3750 [==============================] - 2s 415us/step - loss: 0.6134 - accuracy: 0.7321\n",
      "Epoch 94/100\n",
      "3750/3750 [==============================] - 2s 412us/step - loss: 0.6124 - accuracy: 0.7321\n",
      "Epoch 95/100\n",
      "3750/3750 [==============================] - 2s 425us/step - loss: 0.6127 - accuracy: 0.7324\n",
      "Epoch 96/100\n",
      "3750/3750 [==============================] - 2s 405us/step - loss: 0.6120 - accuracy: 0.7314\n",
      "Epoch 97/100\n",
      "3750/3750 [==============================] - 2s 405us/step - loss: 0.6124 - accuracy: 0.7327\n",
      "Epoch 98/100\n",
      "3750/3750 [==============================] - 2s 403us/step - loss: 0.6114 - accuracy: 0.7331\n",
      "Epoch 99/100\n",
      "3750/3750 [==============================] - 2s 413us/step - loss: 0.6111 - accuracy: 0.7329\n",
      "Epoch 100/100\n",
      "3750/3750 [==============================] - 2s 424us/step - loss: 0.6102 - accuracy: 0.7332\n"
     ]
    }
   ],
   "source": [
    "# Training the neural network\n",
    "history6 = neural_network_6.fit(X_train_tf, y_train_tf, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 0s 309us/step - loss: 0.8307 - accuracy: 0.6476\n",
      "Test accuracy: 0.6476333141326904\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the neural network on the test set\n",
    "test_loss, test_acc = neural_network_6.evaluate(X_test_tf, y_test_tf)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Table[11].append(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNN Using Features extracted from Pre-trained Concatenated Word2Vec Model For Ternary Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the Feedforward Neural Network is used for the Ternary Classification, where the feature extracter is the Pre-trained Gensim Word2Vec model and the vector for a review is the concatenation of the vectors for each word in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 80-20 train-test\n",
    "x_train, x_test, y_train, y_test = train_test_split(terframes['congvectors'], terframes['Labels'], test_size=0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting NumPy arrays to TensorFlow tensors\n",
    "X_train_tf = tf.convert_to_tensor(x_train.to_list(), dtype=tf.float32)\n",
    "y_train_tf = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "X_test_tf = tf.convert_to_tensor(x_test.to_list(), dtype=tf.float32)\n",
    "y_test_tf = tf.convert_to_tensor(y_test, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening the tensor into a single feature vector\n",
    "x_train_tf_flat = tf.reshape(X_train_tf, (X_train_tf.shape[0],-1))\n",
    "X_test_tf_flat = tf.reshape(X_test_tf, (X_test_tf.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network_7 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation='relu', input_shape=((3000),)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the neural network\n",
    "neural_network_7.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3750/3750 [==============================] - 3s 697us/step - loss: 0.8927 - accuracy: 0.5740\n",
      "Epoch 2/100\n",
      "3750/3750 [==============================] - 2s 637us/step - loss: 0.8281 - accuracy: 0.6147\n",
      "Epoch 3/100\n",
      "3750/3750 [==============================] - 2s 603us/step - loss: 0.7793 - accuracy: 0.6441\n",
      "Epoch 4/100\n",
      "3750/3750 [==============================] - 2s 627us/step - loss: 0.7219 - accuracy: 0.6770\n",
      "Epoch 5/100\n",
      "3750/3750 [==============================] - 2s 656us/step - loss: 0.6634 - accuracy: 0.7098\n",
      "Epoch 6/100\n",
      "3750/3750 [==============================] - 2s 645us/step - loss: 0.6048 - accuracy: 0.7417\n",
      "Epoch 7/100\n",
      "3750/3750 [==============================] - 3s 667us/step - loss: 0.5534 - accuracy: 0.7673\n",
      "Epoch 8/100\n",
      "3750/3750 [==============================] - 2s 634us/step - loss: 0.5072 - accuracy: 0.7896\n",
      "Epoch 9/100\n",
      "3750/3750 [==============================] - 3s 680us/step - loss: 0.4661 - accuracy: 0.8097\n",
      "Epoch 10/100\n",
      "3750/3750 [==============================] - 2s 641us/step - loss: 0.4313 - accuracy: 0.8257\n",
      "Epoch 11/100\n",
      "3750/3750 [==============================] - 3s 707us/step - loss: 0.3970 - accuracy: 0.8407\n",
      "Epoch 12/100\n",
      "3750/3750 [==============================] - 2s 660us/step - loss: 0.3695 - accuracy: 0.8530\n",
      "Epoch 13/100\n",
      "3750/3750 [==============================] - 2s 637us/step - loss: 0.3433 - accuracy: 0.8654\n",
      "Epoch 14/100\n",
      "3750/3750 [==============================] - 3s 690us/step - loss: 0.3238 - accuracy: 0.8724\n",
      "Epoch 15/100\n",
      "3750/3750 [==============================] - 2s 639us/step - loss: 0.3042 - accuracy: 0.8810\n",
      "Epoch 16/100\n",
      "3750/3750 [==============================] - 3s 686us/step - loss: 0.2883 - accuracy: 0.8866\n",
      "Epoch 17/100\n",
      "3750/3750 [==============================] - 2s 649us/step - loss: 0.2723 - accuracy: 0.8944\n",
      "Epoch 18/100\n",
      "3750/3750 [==============================] - 3s 694us/step - loss: 0.2598 - accuracy: 0.8994\n",
      "Epoch 19/100\n",
      "3750/3750 [==============================] - 2s 611us/step - loss: 0.2505 - accuracy: 0.9032\n",
      "Epoch 20/100\n",
      "3750/3750 [==============================] - 2s 645us/step - loss: 0.2396 - accuracy: 0.9071\n",
      "Epoch 21/100\n",
      "3750/3750 [==============================] - 2s 650us/step - loss: 0.2280 - accuracy: 0.9118\n",
      "Epoch 22/100\n",
      "3750/3750 [==============================] - 3s 676us/step - loss: 0.2230 - accuracy: 0.9138\n",
      "Epoch 23/100\n",
      "3750/3750 [==============================] - 2s 645us/step - loss: 0.2124 - accuracy: 0.9181\n",
      "Epoch 24/100\n",
      "3750/3750 [==============================] - 2s 665us/step - loss: 0.2059 - accuracy: 0.9205\n",
      "Epoch 25/100\n",
      "3750/3750 [==============================] - 2s 636us/step - loss: 0.1982 - accuracy: 0.9244\n",
      "Epoch 26/100\n",
      "3750/3750 [==============================] - 3s 668us/step - loss: 0.1934 - accuracy: 0.9260\n",
      "Epoch 27/100\n",
      "3750/3750 [==============================] - 2s 661us/step - loss: 0.1885 - accuracy: 0.9280\n",
      "Epoch 28/100\n",
      "3750/3750 [==============================] - 3s 814us/step - loss: 0.1840 - accuracy: 0.9296\n",
      "Epoch 29/100\n",
      "3750/3750 [==============================] - 2s 666us/step - loss: 0.1762 - accuracy: 0.9326\n",
      "Epoch 30/100\n",
      "3750/3750 [==============================] - 3s 753us/step - loss: 0.1730 - accuracy: 0.9342\n",
      "Epoch 31/100\n",
      "3750/3750 [==============================] - 2s 643us/step - loss: 0.1698 - accuracy: 0.9356\n",
      "Epoch 32/100\n",
      "3750/3750 [==============================] - 2s 605us/step - loss: 0.1637 - accuracy: 0.9378\n",
      "Epoch 33/100\n",
      "3750/3750 [==============================] - 2s 612us/step - loss: 0.1632 - accuracy: 0.9380\n",
      "Epoch 34/100\n",
      "3750/3750 [==============================] - 3s 684us/step - loss: 0.1594 - accuracy: 0.9397\n",
      "Epoch 35/100\n",
      "3750/3750 [==============================] - 3s 671us/step - loss: 0.1553 - accuracy: 0.9415\n",
      "Epoch 36/100\n",
      "3750/3750 [==============================] - 2s 641us/step - loss: 0.1507 - accuracy: 0.9430\n",
      "Epoch 37/100\n",
      "3750/3750 [==============================] - 2s 618us/step - loss: 0.1497 - accuracy: 0.9442\n",
      "Epoch 38/100\n",
      "3750/3750 [==============================] - 3s 691us/step - loss: 0.1448 - accuracy: 0.9451\n",
      "Epoch 39/100\n",
      "3750/3750 [==============================] - 2s 613us/step - loss: 0.1436 - accuracy: 0.9459\n",
      "Epoch 40/100\n",
      "3750/3750 [==============================] - 2s 615us/step - loss: 0.1402 - accuracy: 0.9467\n",
      "Epoch 41/100\n",
      "3750/3750 [==============================] - 2s 621us/step - loss: 0.1373 - accuracy: 0.9482\n",
      "Epoch 42/100\n",
      "3750/3750 [==============================] - 2s 657us/step - loss: 0.1363 - accuracy: 0.9486\n",
      "Epoch 43/100\n",
      "3750/3750 [==============================] - 2s 622us/step - loss: 0.1334 - accuracy: 0.9496\n",
      "Epoch 44/100\n",
      "3750/3750 [==============================] - 2s 639us/step - loss: 0.1319 - accuracy: 0.9504\n",
      "Epoch 45/100\n",
      "3750/3750 [==============================] - 3s 708us/step - loss: 0.1289 - accuracy: 0.9515\n",
      "Epoch 46/100\n",
      "3750/3750 [==============================] - 2s 656us/step - loss: 0.1273 - accuracy: 0.9517\n",
      "Epoch 47/100\n",
      "3750/3750 [==============================] - 3s 744us/step - loss: 0.1240 - accuracy: 0.9538\n",
      "Epoch 48/100\n",
      "3750/3750 [==============================] - 3s 700us/step - loss: 0.1252 - accuracy: 0.9530\n",
      "Epoch 49/100\n",
      "3750/3750 [==============================] - 2s 661us/step - loss: 0.1220 - accuracy: 0.9546\n",
      "Epoch 50/100\n",
      "3750/3750 [==============================] - 2s 663us/step - loss: 0.1197 - accuracy: 0.9554\n",
      "Epoch 51/100\n",
      "3750/3750 [==============================] - 2s 665us/step - loss: 0.1177 - accuracy: 0.9554\n",
      "Epoch 52/100\n",
      "3750/3750 [==============================] - 3s 689us/step - loss: 0.1148 - accuracy: 0.9567\n",
      "Epoch 53/100\n",
      "3750/3750 [==============================] - 3s 667us/step - loss: 0.1160 - accuracy: 0.9561\n",
      "Epoch 54/100\n",
      "3750/3750 [==============================] - 2s 650us/step - loss: 0.1145 - accuracy: 0.9569\n",
      "Epoch 55/100\n",
      "3750/3750 [==============================] - 2s 631us/step - loss: 0.1132 - accuracy: 0.9575\n",
      "Epoch 56/100\n",
      "3750/3750 [==============================] - 2s 652us/step - loss: 0.1108 - accuracy: 0.9583\n",
      "Epoch 57/100\n",
      "3750/3750 [==============================] - 2s 605us/step - loss: 0.1105 - accuracy: 0.9588\n",
      "Epoch 58/100\n",
      "3750/3750 [==============================] - 2s 620us/step - loss: 0.1097 - accuracy: 0.9590\n",
      "Epoch 59/100\n",
      "3750/3750 [==============================] - 2s 624us/step - loss: 0.1068 - accuracy: 0.9603\n",
      "Epoch 60/100\n",
      "3750/3750 [==============================] - 2s 639us/step - loss: 0.1079 - accuracy: 0.9601\n",
      "Epoch 61/100\n",
      "3750/3750 [==============================] - 2s 612us/step - loss: 0.1025 - accuracy: 0.9609\n",
      "Epoch 62/100\n",
      "3750/3750 [==============================] - 2s 626us/step - loss: 0.1035 - accuracy: 0.9610\n",
      "Epoch 63/100\n",
      "3750/3750 [==============================] - 2s 613us/step - loss: 0.1034 - accuracy: 0.9616\n",
      "Epoch 64/100\n",
      "3750/3750 [==============================] - 2s 638us/step - loss: 0.1028 - accuracy: 0.9608\n",
      "Epoch 65/100\n",
      "3750/3750 [==============================] - 2s 650us/step - loss: 0.1017 - accuracy: 0.9620\n",
      "Epoch 66/100\n",
      "3750/3750 [==============================] - 3s 727us/step - loss: 0.0980 - accuracy: 0.9636\n",
      "Epoch 67/100\n",
      "3750/3750 [==============================] - 3s 788us/step - loss: 0.1006 - accuracy: 0.9624\n",
      "Epoch 68/100\n",
      "3750/3750 [==============================] - 3s 740us/step - loss: 0.0963 - accuracy: 0.9639\n",
      "Epoch 69/100\n",
      "3750/3750 [==============================] - 2s 663us/step - loss: 0.0968 - accuracy: 0.9638\n",
      "Epoch 70/100\n",
      "3750/3750 [==============================] - 2s 630us/step - loss: 0.0958 - accuracy: 0.9645\n",
      "Epoch 71/100\n",
      "3750/3750 [==============================] - 2s 636us/step - loss: 0.0947 - accuracy: 0.9639\n",
      "Epoch 72/100\n",
      "3750/3750 [==============================] - 2s 644us/step - loss: 0.0932 - accuracy: 0.9656\n",
      "Epoch 73/100\n",
      "3750/3750 [==============================] - 2s 642us/step - loss: 0.0944 - accuracy: 0.9647\n",
      "Epoch 74/100\n",
      "3750/3750 [==============================] - 2s 613us/step - loss: 0.0919 - accuracy: 0.9657\n",
      "Epoch 75/100\n",
      "3750/3750 [==============================] - 2s 649us/step - loss: 0.0908 - accuracy: 0.9660\n",
      "Epoch 76/100\n",
      "3750/3750 [==============================] - 2s 613us/step - loss: 0.0917 - accuracy: 0.9659\n",
      "Epoch 77/100\n",
      "3750/3750 [==============================] - 2s 621us/step - loss: 0.0896 - accuracy: 0.9670\n",
      "Epoch 78/100\n",
      "3750/3750 [==============================] - 2s 654us/step - loss: 0.0911 - accuracy: 0.9661\n",
      "Epoch 79/100\n",
      "3750/3750 [==============================] - 2s 637us/step - loss: 0.0881 - accuracy: 0.9672\n",
      "Epoch 80/100\n",
      "3750/3750 [==============================] - 2s 605us/step - loss: 0.0899 - accuracy: 0.9662\n",
      "Epoch 81/100\n",
      "3750/3750 [==============================] - 2s 643us/step - loss: 0.0887 - accuracy: 0.9674\n",
      "Epoch 82/100\n",
      "3750/3750 [==============================] - 2s 642us/step - loss: 0.0874 - accuracy: 0.9678\n",
      "Epoch 83/100\n",
      "3750/3750 [==============================] - 2s 615us/step - loss: 0.0855 - accuracy: 0.9679\n",
      "Epoch 84/100\n",
      "3750/3750 [==============================] - 2s 599us/step - loss: 0.0857 - accuracy: 0.9684\n",
      "Epoch 85/100\n",
      "3750/3750 [==============================] - 2s 638us/step - loss: 0.0857 - accuracy: 0.9680\n",
      "Epoch 86/100\n",
      "3750/3750 [==============================] - 2s 611us/step - loss: 0.0835 - accuracy: 0.9690\n",
      "Epoch 87/100\n",
      "3750/3750 [==============================] - 3s 711us/step - loss: 0.0851 - accuracy: 0.9689\n",
      "Epoch 88/100\n",
      "3750/3750 [==============================] - 3s 779us/step - loss: 0.0826 - accuracy: 0.9693\n",
      "Epoch 89/100\n",
      "3750/3750 [==============================] - 2s 661us/step - loss: 0.0838 - accuracy: 0.9696\n",
      "Epoch 90/100\n",
      "3750/3750 [==============================] - 2s 666us/step - loss: 0.0812 - accuracy: 0.9692\n",
      "Epoch 91/100\n",
      "3750/3750 [==============================] - 2s 666us/step - loss: 0.0815 - accuracy: 0.9695\n",
      "Epoch 92/100\n",
      "3750/3750 [==============================] - 2s 662us/step - loss: 0.0801 - accuracy: 0.9701\n",
      "Epoch 93/100\n",
      "3750/3750 [==============================] - 3s 695us/step - loss: 0.0802 - accuracy: 0.9704\n",
      "Epoch 94/100\n",
      "3750/3750 [==============================] - 3s 678us/step - loss: 0.0809 - accuracy: 0.9697\n",
      "Epoch 95/100\n",
      "3750/3750 [==============================] - 3s 821us/step - loss: 0.0778 - accuracy: 0.9710\n",
      "Epoch 96/100\n",
      "3750/3750 [==============================] - 3s 694us/step - loss: 0.0797 - accuracy: 0.9708\n",
      "Epoch 97/100\n",
      "3750/3750 [==============================] - 3s 696us/step - loss: 0.0779 - accuracy: 0.9705\n",
      "Epoch 98/100\n",
      "3750/3750 [==============================] - 2s 648us/step - loss: 0.0767 - accuracy: 0.9710\n",
      "Epoch 99/100\n",
      "3750/3750 [==============================] - 3s 739us/step - loss: 0.0751 - accuracy: 0.9717\n",
      "Epoch 100/100\n",
      "3750/3750 [==============================] - 3s 823us/step - loss: 0.0789 - accuracy: 0.9712\n"
     ]
    }
   ],
   "source": [
    "# Training the neural network\n",
    "history7 = neural_network_7.fit(x_train_tf_flat, y_train_tf, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 1s 530us/step - loss: 6.6856 - accuracy: 0.5260\n",
      "Test accuracy: 0.526033341884613\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the neural network on the test set\n",
    "test_loss, test_acc = neural_network_7.evaluate(X_test_tf_flat, y_test_tf)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Table[12].append(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNN Using Features extracted from Custom Concatenated Word2Vec Model For Ternary Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the Feedforward Neural Network is used for the Ternary Classification, where the feature extracter is the Custom Word2Vec model and the vector for a review is the concatenation of the vectors for each word in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 80-20 train-test\n",
    "x_train, x_test, y_train, y_test = train_test_split(terframes['concvectors'], terframes['Labels'], test_size=0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting NumPy arrays to TensorFlow tensors\n",
    "X_train_tf = tf.convert_to_tensor(x_train.to_list(), dtype=tf.float32)\n",
    "y_train_tf = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "X_test_tf = tf.convert_to_tensor(x_test.to_list(), dtype=tf.float32)\n",
    "y_test_tf = tf.convert_to_tensor(y_test, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening the tensor into a single feature vector\n",
    "x_train_tf_flat = tf.reshape(X_train_tf, (X_train_tf.shape[0],-1))\n",
    "X_test_tf_flat = tf.reshape(X_test_tf, (X_test_tf.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network_8 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation='relu', input_shape=((3000),)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the neural network\n",
    "neural_network_8.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3750/3750 [==============================] - 3s 718us/step - loss: 0.8425 - accuracy: 0.6041\n",
      "Epoch 2/100\n",
      "3750/3750 [==============================] - 2s 651us/step - loss: 0.7878 - accuracy: 0.6377\n",
      "Epoch 3/100\n",
      "3750/3750 [==============================] - 3s 694us/step - loss: 0.7412 - accuracy: 0.6631\n",
      "Epoch 4/100\n",
      "3750/3750 [==============================] - 3s 713us/step - loss: 0.6828 - accuracy: 0.6966\n",
      "Epoch 5/100\n",
      "3750/3750 [==============================] - 3s 705us/step - loss: 0.6206 - accuracy: 0.7305\n",
      "Epoch 6/100\n",
      "3750/3750 [==============================] - 3s 737us/step - loss: 0.5612 - accuracy: 0.7601\n",
      "Epoch 7/100\n",
      "3750/3750 [==============================] - 3s 713us/step - loss: 0.5063 - accuracy: 0.7871\n",
      "Epoch 8/100\n",
      "3750/3750 [==============================] - 3s 670us/step - loss: 0.4588 - accuracy: 0.8099\n",
      "Epoch 9/100\n",
      "3750/3750 [==============================] - 3s 770us/step - loss: 0.4176 - accuracy: 0.8284\n",
      "Epoch 10/100\n",
      "3750/3750 [==============================] - 3s 783us/step - loss: 0.3816 - accuracy: 0.8443\n",
      "Epoch 11/100\n",
      "3750/3750 [==============================] - 3s 714us/step - loss: 0.3512 - accuracy: 0.8584\n",
      "Epoch 12/100\n",
      "3750/3750 [==============================] - 3s 717us/step - loss: 0.3242 - accuracy: 0.8685\n",
      "Epoch 13/100\n",
      "3750/3750 [==============================] - 3s 708us/step - loss: 0.3019 - accuracy: 0.8801\n",
      "Epoch 14/100\n",
      "3750/3750 [==============================] - 3s 673us/step - loss: 0.2794 - accuracy: 0.8887\n",
      "Epoch 15/100\n",
      "3750/3750 [==============================] - 2s 656us/step - loss: 0.2646 - accuracy: 0.8957\n",
      "Epoch 16/100\n",
      "3750/3750 [==============================] - 3s 835us/step - loss: 0.2478 - accuracy: 0.9032\n",
      "Epoch 17/100\n",
      "3750/3750 [==============================] - 3s 682us/step - loss: 0.2356 - accuracy: 0.9087\n",
      "Epoch 18/100\n",
      "3750/3750 [==============================] - 3s 692us/step - loss: 0.2226 - accuracy: 0.9132\n",
      "Epoch 19/100\n",
      "3750/3750 [==============================] - 2s 662us/step - loss: 0.2146 - accuracy: 0.9165\n",
      "Epoch 20/100\n",
      "3750/3750 [==============================] - 3s 690us/step - loss: 0.2018 - accuracy: 0.9228\n",
      "Epoch 21/100\n",
      "3750/3750 [==============================] - 3s 806us/step - loss: 0.1951 - accuracy: 0.9250\n",
      "Epoch 22/100\n",
      "3750/3750 [==============================] - 3s 709us/step - loss: 0.1862 - accuracy: 0.9281\n",
      "Epoch 23/100\n",
      "3750/3750 [==============================] - 3s 733us/step - loss: 0.1785 - accuracy: 0.9322\n",
      "Epoch 24/100\n",
      "3750/3750 [==============================] - 3s 690us/step - loss: 0.1755 - accuracy: 0.9327\n",
      "Epoch 25/100\n",
      "3750/3750 [==============================] - 3s 691us/step - loss: 0.1675 - accuracy: 0.9359\n",
      "Epoch 26/100\n",
      "3750/3750 [==============================] - 3s 676us/step - loss: 0.1618 - accuracy: 0.9382\n",
      "Epoch 27/100\n",
      "3750/3750 [==============================] - 2s 655us/step - loss: 0.1585 - accuracy: 0.9401\n",
      "Epoch 28/100\n",
      "3750/3750 [==============================] - 3s 677us/step - loss: 0.1517 - accuracy: 0.9428\n",
      "Epoch 29/100\n",
      "3750/3750 [==============================] - 3s 722us/step - loss: 0.1498 - accuracy: 0.9432\n",
      "Epoch 30/100\n",
      "3750/3750 [==============================] - 3s 750us/step - loss: 0.1439 - accuracy: 0.9459\n",
      "Epoch 31/100\n",
      "3750/3750 [==============================] - 3s 675us/step - loss: 0.1413 - accuracy: 0.9470\n",
      "Epoch 32/100\n",
      "3750/3750 [==============================] - 3s 702us/step - loss: 0.1400 - accuracy: 0.9478\n",
      "Epoch 33/100\n",
      "3750/3750 [==============================] - 3s 719us/step - loss: 0.1365 - accuracy: 0.9490\n",
      "Epoch 34/100\n",
      "3750/3750 [==============================] - 3s 706us/step - loss: 0.1312 - accuracy: 0.9518\n",
      "Epoch 35/100\n",
      "3750/3750 [==============================] - 3s 672us/step - loss: 0.1290 - accuracy: 0.9517\n",
      "Epoch 36/100\n",
      "3750/3750 [==============================] - 3s 815us/step - loss: 0.1267 - accuracy: 0.9532\n",
      "Epoch 37/100\n",
      "3750/3750 [==============================] - 3s 683us/step - loss: 0.1241 - accuracy: 0.9541\n",
      "Epoch 38/100\n",
      "3750/3750 [==============================] - 2s 658us/step - loss: 0.1243 - accuracy: 0.9542\n",
      "Epoch 39/100\n",
      "3750/3750 [==============================] - 3s 698us/step - loss: 0.1198 - accuracy: 0.9561\n",
      "Epoch 40/100\n",
      "3750/3750 [==============================] - 2s 653us/step - loss: 0.1178 - accuracy: 0.9569\n",
      "Epoch 41/100\n",
      "3750/3750 [==============================] - 2s 644us/step - loss: 0.1167 - accuracy: 0.9575\n",
      "Epoch 42/100\n",
      "3750/3750 [==============================] - 3s 676us/step - loss: 0.1145 - accuracy: 0.9580\n",
      "Epoch 43/100\n",
      "3750/3750 [==============================] - 3s 676us/step - loss: 0.1105 - accuracy: 0.9594\n",
      "Epoch 44/100\n",
      "3750/3750 [==============================] - 3s 691us/step - loss: 0.1102 - accuracy: 0.9596\n",
      "Epoch 45/100\n",
      "3750/3750 [==============================] - 3s 791us/step - loss: 0.1086 - accuracy: 0.9606\n",
      "Epoch 46/100\n",
      "3750/3750 [==============================] - 3s 684us/step - loss: 0.1057 - accuracy: 0.9617\n",
      "Epoch 47/100\n",
      "3750/3750 [==============================] - 3s 813us/step - loss: 0.1056 - accuracy: 0.9612\n",
      "Epoch 48/100\n",
      "3750/3750 [==============================] - 3s 756us/step - loss: 0.1033 - accuracy: 0.9618\n",
      "Epoch 49/100\n",
      "3750/3750 [==============================] - 3s 679us/step - loss: 0.1023 - accuracy: 0.9621\n",
      "Epoch 50/100\n",
      "3750/3750 [==============================] - 3s 670us/step - loss: 0.0991 - accuracy: 0.9636\n",
      "Epoch 51/100\n",
      "3750/3750 [==============================] - 3s 683us/step - loss: 0.1017 - accuracy: 0.9634\n",
      "Epoch 52/100\n",
      "3750/3750 [==============================] - 3s 683us/step - loss: 0.0979 - accuracy: 0.9646\n",
      "Epoch 53/100\n",
      "3750/3750 [==============================] - 3s 688us/step - loss: 0.0976 - accuracy: 0.9649\n",
      "Epoch 54/100\n",
      "3750/3750 [==============================] - 3s 736us/step - loss: 0.0973 - accuracy: 0.9642\n",
      "Epoch 55/100\n",
      "3750/3750 [==============================] - 3s 736us/step - loss: 0.0941 - accuracy: 0.9656\n",
      "Epoch 56/100\n",
      "3750/3750 [==============================] - 3s 669us/step - loss: 0.0944 - accuracy: 0.9661\n",
      "Epoch 57/100\n",
      "3750/3750 [==============================] - 3s 838us/step - loss: 0.0919 - accuracy: 0.9668\n",
      "Epoch 58/100\n",
      "3750/3750 [==============================] - 3s 696us/step - loss: 0.0919 - accuracy: 0.9667\n",
      "Epoch 59/100\n",
      "3750/3750 [==============================] - 3s 704us/step - loss: 0.0910 - accuracy: 0.9674\n",
      "Epoch 60/100\n",
      "3750/3750 [==============================] - 2s 638us/step - loss: 0.0886 - accuracy: 0.9683\n",
      "Epoch 61/100\n",
      "3750/3750 [==============================] - 2s 632us/step - loss: 0.0897 - accuracy: 0.9673\n",
      "Epoch 62/100\n",
      "3750/3750 [==============================] - 2s 635us/step - loss: 0.0877 - accuracy: 0.9684\n",
      "Epoch 63/100\n",
      "3750/3750 [==============================] - 3s 671us/step - loss: 0.0853 - accuracy: 0.9692\n",
      "Epoch 64/100\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0855 - accuracy: 0.9691\n",
      "Epoch 65/100\n",
      "3750/3750 [==============================] - 4s 969us/step - loss: 0.0856 - accuracy: 0.9690\n",
      "Epoch 66/100\n",
      "3750/3750 [==============================] - 3s 866us/step - loss: 0.0845 - accuracy: 0.9692\n",
      "Epoch 67/100\n",
      "3750/3750 [==============================] - 3s 869us/step - loss: 0.0825 - accuracy: 0.9704\n",
      "Epoch 68/100\n",
      "3750/3750 [==============================] - 3s 707us/step - loss: 0.0827 - accuracy: 0.9699\n",
      "Epoch 69/100\n",
      "3750/3750 [==============================] - 3s 751us/step - loss: 0.0820 - accuracy: 0.9707\n",
      "Epoch 70/100\n",
      "3750/3750 [==============================] - 3s 694us/step - loss: 0.0826 - accuracy: 0.9701\n",
      "Epoch 71/100\n",
      "3750/3750 [==============================] - 3s 706us/step - loss: 0.0800 - accuracy: 0.9710\n",
      "Epoch 72/100\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0824 - accuracy: 0.9703\n",
      "Epoch 73/100\n",
      "3750/3750 [==============================] - 3s 688us/step - loss: 0.0791 - accuracy: 0.9713\n",
      "Epoch 74/100\n",
      "3750/3750 [==============================] - 3s 846us/step - loss: 0.0788 - accuracy: 0.9718\n",
      "Epoch 75/100\n",
      "3750/3750 [==============================] - 3s 715us/step - loss: 0.0780 - accuracy: 0.9719\n",
      "Epoch 76/100\n",
      "3750/3750 [==============================] - 3s 746us/step - loss: 0.0775 - accuracy: 0.9714\n",
      "Epoch 77/100\n",
      "3750/3750 [==============================] - 3s 716us/step - loss: 0.0764 - accuracy: 0.9721\n",
      "Epoch 78/100\n",
      "3750/3750 [==============================] - 3s 719us/step - loss: 0.0779 - accuracy: 0.9717\n",
      "Epoch 79/100\n",
      "3750/3750 [==============================] - 3s 823us/step - loss: 0.0751 - accuracy: 0.9726\n",
      "Epoch 80/100\n",
      "3750/3750 [==============================] - 3s 736us/step - loss: 0.0758 - accuracy: 0.9729\n",
      "Epoch 81/100\n",
      "3750/3750 [==============================] - 3s 778us/step - loss: 0.0737 - accuracy: 0.9736\n",
      "Epoch 82/100\n",
      "3750/3750 [==============================] - 3s 741us/step - loss: 0.0728 - accuracy: 0.9736\n",
      "Epoch 83/100\n",
      "3750/3750 [==============================] - 3s 749us/step - loss: 0.0749 - accuracy: 0.9730\n",
      "Epoch 84/100\n",
      "3750/3750 [==============================] - 3s 785us/step - loss: 0.0705 - accuracy: 0.9745\n",
      "Epoch 85/100\n",
      "3750/3750 [==============================] - 3s 734us/step - loss: 0.0741 - accuracy: 0.9732\n",
      "Epoch 86/100\n",
      "3750/3750 [==============================] - 3s 680us/step - loss: 0.0725 - accuracy: 0.9738\n",
      "Epoch 87/100\n",
      "3750/3750 [==============================] - 3s 718us/step - loss: 0.0724 - accuracy: 0.9737\n",
      "Epoch 88/100\n",
      "3750/3750 [==============================] - 3s 676us/step - loss: 0.0722 - accuracy: 0.9739\n",
      "Epoch 89/100\n",
      "3750/3750 [==============================] - 3s 692us/step - loss: 0.0730 - accuracy: 0.9741\n",
      "Epoch 90/100\n",
      "3750/3750 [==============================] - 3s 697us/step - loss: 0.0734 - accuracy: 0.9738\n",
      "Epoch 91/100\n",
      "3750/3750 [==============================] - 3s 681us/step - loss: 0.0693 - accuracy: 0.9746\n",
      "Epoch 92/100\n",
      "3750/3750 [==============================] - 3s 706us/step - loss: 0.0721 - accuracy: 0.9748\n",
      "Epoch 93/100\n",
      "3750/3750 [==============================] - 3s 708us/step - loss: 0.0670 - accuracy: 0.9756\n",
      "Epoch 94/100\n",
      "3750/3750 [==============================] - 2s 657us/step - loss: 0.0681 - accuracy: 0.9757\n",
      "Epoch 95/100\n",
      "3750/3750 [==============================] - 3s 707us/step - loss: 0.0686 - accuracy: 0.9750\n",
      "Epoch 96/100\n",
      "3750/3750 [==============================] - 3s 683us/step - loss: 0.0682 - accuracy: 0.9753\n",
      "Epoch 97/100\n",
      "3750/3750 [==============================] - 3s 704us/step - loss: 0.0678 - accuracy: 0.9755\n",
      "Epoch 98/100\n",
      "3750/3750 [==============================] - 3s 693us/step - loss: 0.0680 - accuracy: 0.9754\n",
      "Epoch 99/100\n",
      "3750/3750 [==============================] - 2s 662us/step - loss: 0.0669 - accuracy: 0.9755\n",
      "Epoch 100/100\n",
      "3750/3750 [==============================] - 3s 687us/step - loss: 0.0657 - accuracy: 0.9758\n"
     ]
    }
   ],
   "source": [
    "# Training the neural network\n",
    "history8 = neural_network_8.fit(x_train_tf_flat, y_train_tf, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 0s 424us/step - loss: 7.5096 - accuracy: 0.5455\n",
      "Test accuracy: 0.5455333590507507\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the neural network on the test set\n",
    "test_loss, test_acc = neural_network_8.evaluate(X_test_tf_flat, y_test_tf)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Table[13].append(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do you conclude by comparing accuracy values you obtain with those obtained in the â€œâ€™Simple Modelsâ€ section (note you can compare the accuracy values for binary classification).\n",
    "\n",
    "A. From the results, it can be observed that the accuracy scores for the feed forward neural network is better than that of the svm or the percepton model. This can mean that the feed forward neural network gives a better result due to the backpropagation and helps the machine to learn the classification beter than the previously used 'simple models'. However, these performances can have varied answers if we change parameters such as sample size of the data set, hyperparameters of the FNN, hyperparameters in the custom Word2Vec model or change the dataset in itself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN for Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Labels</th>\n",
       "      <th>MyReviews</th>\n",
       "      <th>gvectors</th>\n",
       "      <th>cvectors</th>\n",
       "      <th>congvectors</th>\n",
       "      <th>concvectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1921057</th>\n",
       "      <td>item came home made bubble wrap labeled new ou...</td>\n",
       "      <td>1</td>\n",
       "      <td>[item, came, home, made, bubble, wrap, labeled...</td>\n",
       "      <td>[0.027547836303710938, 0.09846019744873047, 0....</td>\n",
       "      <td>[0.027547836303710938, 0.09846019744873047, 0....</td>\n",
       "      <td>[[0.024291992, 0.010803223, -0.107421875, 0.30...</td>\n",
       "      <td>[[0.035866924, -0.01820376, 0.17473365, 0.0287...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032152</th>\n",
       "      <td>work hope continues working perhaps get discou...</td>\n",
       "      <td>0</td>\n",
       "      <td>[work, hope, continues, working, perhaps, get,...</td>\n",
       "      <td>[0.05845424107142857, 0.016178676060267856, -0...</td>\n",
       "      <td>[0.05845424107142857, 0.016178676060267856, -0...</td>\n",
       "      <td>[[-0.075683594, 0.033691406, -0.064941406, 0.1...</td>\n",
       "      <td>[[0.04482966, -0.032019116, 0.06074907, 0.0353...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590977</th>\n",
       "      <td>software come printer support newer version ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>[software, come, printer, support, newer, vers...</td>\n",
       "      <td>[0.06760212912488339, -0.03568415855293843, -0...</td>\n",
       "      <td>[0.06760212912488339, -0.03568415855293843, -0...</td>\n",
       "      <td>[[0.20410156, -0.30078125, -0.013916016, 0.119...</td>\n",
       "      <td>[[0.047153026, -0.038383402, -0.02039575, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685277</th>\n",
       "      <td>arrived time came huge box expecting big pictu...</td>\n",
       "      <td>0</td>\n",
       "      <td>[arrived, time, came, huge, box, expecting, bi...</td>\n",
       "      <td>[0.03836669921875, 0.05717875162760417, -0.008...</td>\n",
       "      <td>[0.03836669921875, 0.05717875162760417, -0.008...</td>\n",
       "      <td>[[0.15429688, 0.26757812, 0.09326172, -0.15234...</td>\n",
       "      <td>[[0.0069977418, -0.1542149, 0.39981222, 0.0632...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29865</th>\n",
       "      <td>work well canon toner</td>\n",
       "      <td>0</td>\n",
       "      <td>[work, well, canon, toner]</td>\n",
       "      <td>[0.0806640625, 0.07841796875, -0.0003662109375...</td>\n",
       "      <td>[0.0806640625, 0.07841796875, -0.0003662109375...</td>\n",
       "      <td>[[-0.07568359375, 0.03369140625, -0.0649414062...</td>\n",
       "      <td>[[0.044829659163951874, -0.03201911598443985, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reviews  Labels  \\\n",
       "1921057  item came home made bubble wrap labeled new ou...       1   \n",
       "2032152  work hope continues working perhaps get discou...       0   \n",
       "2590977  software come printer support newer version ma...       1   \n",
       "1685277  arrived time came huge box expecting big pictu...       0   \n",
       "29865                                work well canon toner       0   \n",
       "\n",
       "                                                 MyReviews  \\\n",
       "1921057  [item, came, home, made, bubble, wrap, labeled...   \n",
       "2032152  [work, hope, continues, working, perhaps, get,...   \n",
       "2590977  [software, come, printer, support, newer, vers...   \n",
       "1685277  [arrived, time, came, huge, box, expecting, bi...   \n",
       "29865                           [work, well, canon, toner]   \n",
       "\n",
       "                                                  gvectors  \\\n",
       "1921057  [0.027547836303710938, 0.09846019744873047, 0....   \n",
       "2032152  [0.05845424107142857, 0.016178676060267856, -0...   \n",
       "2590977  [0.06760212912488339, -0.03568415855293843, -0...   \n",
       "1685277  [0.03836669921875, 0.05717875162760417, -0.008...   \n",
       "29865    [0.0806640625, 0.07841796875, -0.0003662109375...   \n",
       "\n",
       "                                                  cvectors  \\\n",
       "1921057  [0.027547836303710938, 0.09846019744873047, 0....   \n",
       "2032152  [0.05845424107142857, 0.016178676060267856, -0...   \n",
       "2590977  [0.06760212912488339, -0.03568415855293843, -0...   \n",
       "1685277  [0.03836669921875, 0.05717875162760417, -0.008...   \n",
       "29865    [0.0806640625, 0.07841796875, -0.0003662109375...   \n",
       "\n",
       "                                               congvectors  \\\n",
       "1921057  [[0.024291992, 0.010803223, -0.107421875, 0.30...   \n",
       "2032152  [[-0.075683594, 0.033691406, -0.064941406, 0.1...   \n",
       "2590977  [[0.20410156, -0.30078125, -0.013916016, 0.119...   \n",
       "1685277  [[0.15429688, 0.26757812, 0.09326172, -0.15234...   \n",
       "29865    [[-0.07568359375, 0.03369140625, -0.0649414062...   \n",
       "\n",
       "                                               concvectors  \n",
       "1921057  [[0.035866924, -0.01820376, 0.17473365, 0.0287...  \n",
       "2032152  [[0.04482966, -0.032019116, 0.06074907, 0.0353...  \n",
       "2590977  [[0.047153026, -0.038383402, -0.02039575, -0.1...  \n",
       "1685277  [[0.0069977418, -0.1542149, 0.39981222, 0.0632...  \n",
       "29865    [[0.044829659163951874, -0.03201911598443985, ...  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binframes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Using Features extracted from Pre-trained Word2Vec Model For Binary Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the Convolutional Neural Network is used for the Binary Classification, where the feature extracter is the Pre-trained Gensim Word2Vec model and the vector for a review is the average of the vectors for each word in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 80-20 train-test\n",
    "x_train, x_test, y_train, y_test = train_test_split(binframes['gvectors'], binframes['Labels'], test_size=0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting NumPy arrays to TensorFlow tensors\n",
    "X_train_tf = tf.convert_to_tensor(x_train.to_list(), dtype=tf.float32)\n",
    "y_train_tf = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "X_test_tf = tf.convert_to_tensor(x_test.to_list(), dtype=tf.float32)\n",
    "y_test_tf = tf.convert_to_tensor(y_test, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cnn architecture\n",
    "cnn_network = tf.keras.models.Sequential()\n",
    "cnn_network.add(tf.keras.layers.Conv1D(50, 3, activation='relu', input_shape=(300,1) ))\n",
    "cnn_network.add(tf.keras.layers.MaxPooling1D(3))\n",
    "cnn_network.add(tf.keras.layers.Conv1D(10, 3, activation='relu'))\n",
    "cnn_network.add(tf.keras.layers.MaxPooling1D(2))\n",
    "cnn_network.add(tf.keras.layers.Flatten())\n",
    "cnn_network.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the cnn\n",
    "cnn_network.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.4780 - accuracy: 0.7767\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4101 - accuracy: 0.8163\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.3947 - accuracy: 0.8256\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3851 - accuracy: 0.8303\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3783 - accuracy: 0.8344\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3744 - accuracy: 0.8350\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3704 - accuracy: 0.8382\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3673 - accuracy: 0.8399\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3650 - accuracy: 0.8416\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3632 - accuracy: 0.8418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x13807a400>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the cnn\n",
    "cnn_network.fit(X_train_tf, y_train_tf, epochs=10, batch_size=64, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.8415499925613403\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss_ternary_gavg_cnn, ternary_gavg_cnn = cnn_network.evaluate(X_test_tf, y_test_tf, verbose=0)\n",
    "print('Test Accuracy: ', ternary_gavg_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Table[14].append(ternary_gavg_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Using Features extracted from Custom Word2Vec Model For Binary Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the Convolutional Neural Network is used for the Binary Classification, where the feature extracter is the Custom Word2Vec model and the vector for a review is the average of the vectors for each word in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 80-20 train-test\n",
    "x_train, x_test, y_train, y_test = train_test_split(binframes['cvectors'], binframes['Labels'], test_size=0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting NumPy arrays to TensorFlow tensors\n",
    "X_train_tf = tf.convert_to_tensor(x_train.to_list(), dtype=tf.float32)\n",
    "y_train_tf = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "X_test_tf = tf.convert_to_tensor(x_test.to_list(), dtype=tf.float32)\n",
    "y_test_tf = tf.convert_to_tensor(y_test, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cnn architecture\n",
    "cnn_network = tf.keras.models.Sequential()\n",
    "cnn_network.add(tf.keras.layers.Conv1D(50, 3, activation='relu', input_shape=(300,1) ))\n",
    "cnn_network.add(tf.keras.layers.MaxPooling1D(3))\n",
    "cnn_network.add(tf.keras.layers.Conv1D(10, 3, activation='relu'))\n",
    "cnn_network.add(tf.keras.layers.MaxPooling1D(2))\n",
    "cnn_network.add(tf.keras.layers.Flatten())\n",
    "cnn_network.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the cnn\n",
    "cnn_network.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4825 - accuracy: 0.7719\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.4188 - accuracy: 0.8098\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.4032 - accuracy: 0.8211\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3930 - accuracy: 0.8257\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3855 - accuracy: 0.8303\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3803 - accuracy: 0.8328\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3757 - accuracy: 0.8348\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3716 - accuracy: 0.8364\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3684 - accuracy: 0.8393\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3665 - accuracy: 0.8396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1399c56d0>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the cnn\n",
    "cnn_network.fit(X_train_tf, y_train_tf, epochs=10, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.8417999744415283\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss_ternary_cavg_cnn, ternary_cavg_cnn = cnn_network.evaluate(X_test_tf, y_test_tf, verbose=0)\n",
    "print('Test Accuracy: ', ternary_cavg_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Table[15].append(ternary_cavg_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN for Ternary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Labels</th>\n",
       "      <th>MyReviews</th>\n",
       "      <th>gvectors</th>\n",
       "      <th>cvectors</th>\n",
       "      <th>congvectors</th>\n",
       "      <th>concvectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1163606</th>\n",
       "      <td>excellent pen actually pen like use write anyt...</td>\n",
       "      <td>0</td>\n",
       "      <td>[excellent, pen, actually, pen, like, use, wri...</td>\n",
       "      <td>[0.013108995225694444, -0.015750461154513888, ...</td>\n",
       "      <td>[0.013108995225694444, -0.015750461154513888, ...</td>\n",
       "      <td>[[-0.212890625, -0.004302978515625, -0.1806640...</td>\n",
       "      <td>[[0.1381412297487259, -0.06316769868135452, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069284</th>\n",
       "      <td>fresh set battery nice strong beam unfortunate...</td>\n",
       "      <td>2</td>\n",
       "      <td>[fresh, set, battery, nice, strong, beam, unfo...</td>\n",
       "      <td>[0.035248976487379804, 0.09482046274038461, 0....</td>\n",
       "      <td>[0.035248976487379804, 0.09482046274038461, 0....</td>\n",
       "      <td>[[-0.042236328, 0.018066406, 0.22070312, -0.01...</td>\n",
       "      <td>[[0.120346084, 0.057084102, -0.09761257, -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338411</th>\n",
       "      <td>file folder label great use folder</td>\n",
       "      <td>0</td>\n",
       "      <td>[file, folder, label, great, use, folder]</td>\n",
       "      <td>[0.11321149553571429, 0.029767717633928572, -0...</td>\n",
       "      <td>[0.11321149553571429, 0.029767717633928572, -0...</td>\n",
       "      <td>[[0.28515625, 0.023193359375, -0.03173828125, ...</td>\n",
       "      <td>[[-0.12393734604120255, 0.06283459812402725, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37088</th>\n",
       "      <td>work 's well heavy duty steel original stapler...</td>\n",
       "      <td>2</td>\n",
       "      <td>[work, 's, well, heavy, duty, steel, original,...</td>\n",
       "      <td>[0.07191051136363637, 0.07883522727272728, -0....</td>\n",
       "      <td>[0.07191051136363637, 0.07883522727272728, -0....</td>\n",
       "      <td>[[-0.075683594, 0.033691406, -0.064941406, 0.1...</td>\n",
       "      <td>[[0.04482966, -0.032019116, 0.06074907, 0.0353...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752649</th>\n",
       "      <td>great quality great value</td>\n",
       "      <td>0</td>\n",
       "      <td>[great, quality, great, value]</td>\n",
       "      <td>[-0.00732421875, 0.141259765625, 0.03442382812...</td>\n",
       "      <td>[-0.00732421875, 0.141259765625, 0.03442382812...</td>\n",
       "      <td>[[0.07177734375, 0.2080078125, -0.028442382812...</td>\n",
       "      <td>[[-0.006137721240520477, -0.06911127269268036,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reviews  Labels  \\\n",
       "1163606  excellent pen actually pen like use write anyt...       0   \n",
       "2069284  fresh set battery nice strong beam unfortunate...       2   \n",
       "338411                  file folder label great use folder       0   \n",
       "37088    work 's well heavy duty steel original stapler...       2   \n",
       "752649                           great quality great value       0   \n",
       "\n",
       "                                                 MyReviews  \\\n",
       "1163606  [excellent, pen, actually, pen, like, use, wri...   \n",
       "2069284  [fresh, set, battery, nice, strong, beam, unfo...   \n",
       "338411           [file, folder, label, great, use, folder]   \n",
       "37088    [work, 's, well, heavy, duty, steel, original,...   \n",
       "752649                      [great, quality, great, value]   \n",
       "\n",
       "                                                  gvectors  \\\n",
       "1163606  [0.013108995225694444, -0.015750461154513888, ...   \n",
       "2069284  [0.035248976487379804, 0.09482046274038461, 0....   \n",
       "338411   [0.11321149553571429, 0.029767717633928572, -0...   \n",
       "37088    [0.07191051136363637, 0.07883522727272728, -0....   \n",
       "752649   [-0.00732421875, 0.141259765625, 0.03442382812...   \n",
       "\n",
       "                                                  cvectors  \\\n",
       "1163606  [0.013108995225694444, -0.015750461154513888, ...   \n",
       "2069284  [0.035248976487379804, 0.09482046274038461, 0....   \n",
       "338411   [0.11321149553571429, 0.029767717633928572, -0...   \n",
       "37088    [0.07191051136363637, 0.07883522727272728, -0....   \n",
       "752649   [-0.00732421875, 0.141259765625, 0.03442382812...   \n",
       "\n",
       "                                               congvectors  \\\n",
       "1163606  [[-0.212890625, -0.004302978515625, -0.1806640...   \n",
       "2069284  [[-0.042236328, 0.018066406, 0.22070312, -0.01...   \n",
       "338411   [[0.28515625, 0.023193359375, -0.03173828125, ...   \n",
       "37088    [[-0.075683594, 0.033691406, -0.064941406, 0.1...   \n",
       "752649   [[0.07177734375, 0.2080078125, -0.028442382812...   \n",
       "\n",
       "                                               concvectors  \n",
       "1163606  [[0.1381412297487259, -0.06316769868135452, 0....  \n",
       "2069284  [[0.120346084, 0.057084102, -0.09761257, -0.03...  \n",
       "338411   [[-0.12393734604120255, 0.06283459812402725, -...  \n",
       "37088    [[0.04482966, -0.032019116, 0.06074907, 0.0353...  \n",
       "752649   [[-0.006137721240520477, -0.06911127269268036,...  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terframes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Using Features extracted from Pre-trained Word2Vec Model For Ternary Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the Convolutional Neural Network is used for the Ternary Classification, where the feature extracter is the Pre-trained Gensim Word2Vec model and the vector for a review is the average of the vectors for each word in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 80-20 train-test\n",
    "x_train, x_test, y_train, y_test = train_test_split(terframes['gvectors'], terframes['Labels'], test_size=0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting NumPy arrays to TensorFlow tensors\n",
    "X_train_tf = tf.convert_to_tensor(x_train.to_list(), dtype=tf.float32)\n",
    "y_train_tf = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "X_test_tf = tf.convert_to_tensor(x_test.to_list(), dtype=tf.float32)\n",
    "y_test_tf = tf.convert_to_tensor(y_test, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cnn architecture\n",
    "cnn_network = tf.keras.models.Sequential()\n",
    "cnn_network.add(tf.keras.layers.Conv1D(50, 3, activation='relu', input_shape=(300,1) ))\n",
    "cnn_network.add(tf.keras.layers.MaxPooling1D(3))\n",
    "cnn_network.add(tf.keras.layers.Conv1D(10, 3, activation='relu'))\n",
    "cnn_network.add(tf.keras.layers.MaxPooling1D(2))\n",
    "cnn_network.add(tf.keras.layers.Flatten())\n",
    "cnn_network.add(tf.keras.layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the cnn\n",
    "cnn_network.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8888 - accuracy: 0.5833\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8362 - accuracy: 0.6166\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8200 - accuracy: 0.6262\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8122 - accuracy: 0.6299\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.8066 - accuracy: 0.6341\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8034 - accuracy: 0.6355\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.8007 - accuracy: 0.6363\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.7982 - accuracy: 0.6374\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.7963 - accuracy: 0.6392\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.7947 - accuracy: 0.6387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x138245e50>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the cnn\n",
    "cnn_network.fit(X_train_tf, y_train_tf, epochs=10, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.635200023651123\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss_ternary_gavg_cnn, ternary_gavg_cnn = cnn_network.evaluate(X_test_tf, y_test_tf, verbose=0)\n",
    "print('Test Accuracy: ', ternary_gavg_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Table[16].append(ternary_gavg_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Using Features extracted from Custom Word2Vec Model For Ternary Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the Convolutional Neural Network is used for the Ternary Classification, where the feature extracter is the Custom Word2Vec model and the vector for a review is the average of the vectors for each word in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 80-20 train-test\n",
    "x_train, x_test, y_train, y_test = train_test_split(terframes['gvectors'], terframes['Labels'], test_size=0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting NumPy arrays to TensorFlow tensors\n",
    "X_train_tf = tf.convert_to_tensor(x_train.to_list(), dtype=tf.float32)\n",
    "y_train_tf = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "X_test_tf = tf.convert_to_tensor(x_test.to_list(), dtype=tf.float32)\n",
    "y_test_tf = tf.convert_to_tensor(y_test, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cnn architecture\n",
    "cnn_network = tf.keras.models.Sequential()\n",
    "cnn_network.add(tf.keras.layers.Conv1D(50, 3, activation='relu', input_shape=(300,1) ))\n",
    "cnn_network.add(tf.keras.layers.MaxPooling1D(3))\n",
    "cnn_network.add(tf.keras.layers.Conv1D(10, 3, activation='relu'))\n",
    "cnn_network.add(tf.keras.layers.MaxPooling1D(2))\n",
    "cnn_network.add(tf.keras.layers.Flatten())\n",
    "cnn_network.add(tf.keras.layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the cnn\n",
    "cnn_network.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8961 - accuracy: 0.5797\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8441 - accuracy: 0.6119\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8313 - accuracy: 0.6197\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.8227 - accuracy: 0.6244\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.8177 - accuracy: 0.6270\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.8144 - accuracy: 0.6272\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8110 - accuracy: 0.6297\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8082 - accuracy: 0.6317\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8065 - accuracy: 0.6320\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8050 - accuracy: 0.6341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x138376850>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the cnn\n",
    "cnn_network.fit(X_train_tf, y_train_tf, epochs=10, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.6302666664123535\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss_ternary_cavg_cnn, ternary_cavg_cnn = cnn_network.evaluate(X_test_tf, y_test_tf, verbose=0)\n",
    "print('Test Accuracy: ', ternary_cavg_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Table[17].append(ternary_cavg_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting Accuracy Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extracter Type    Neural Network Type    Classification Type      Accuracy Value\n",
      "------------------------  ---------------------  ---------------------  ----------------\n",
      "TFIDF                     Percepton              Binary                         0.84775\n",
      "TFIDF                     SVM                    Binary                         0.88845\n",
      "Avg Pre-trained W2V       Percepton              Binary                         0.7971\n",
      "Avg Pre-trained W2V       SVM                    Binary                         0.8487\n",
      "Avg Custom W2V            Percepton              Binary                         0.7971\n",
      "Avg Custom W2V            SVM                    Binary                         0.8487\n",
      "Avg Pre-trained W2V       FNN                    Binary                         0.84985\n",
      "Avg Custom W2V            FNN                    Binary                         0.851\n",
      "Con Pre-trained W2V       FNN                    Binary                         0.7652\n",
      "Con Custom W2V            FNN                    Binary                         0.79105\n",
      "Avg Pre-trained W2V       FNN                    Ternary                        0.6428\n",
      "Avg Custom W2V            FNN                    Ternary                        0.647633\n",
      "Con Pre-trained W2V       FNN                    Ternary                        0.526033\n",
      "Con Custom W2V            FNN                    Ternary                        0.545533\n",
      "Avg Pre-trained W2V       CNN                    Binary                         0.84155\n",
      "Avg Custom W2V            CNN                    Binary                         0.8418\n",
      "Avg Pre-trained W2V       CNN                    Ternary                        0.6352\n",
      "Avg Custom W2V            CNN                    Ternary                        0.630267\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(Accuracy_Table, headers=[\"Feature Extracter Type\", \"Neural Network Type\", \"Classification Type\", \"Accuracy Value\"]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN5EBMqYUoJEc3gcPAgIdi9",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
